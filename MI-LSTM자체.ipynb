{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nextgen/anaconda3/envs/tf/lib/python3.6/site-packages/pandas_datareader/compat/__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import data as d\n",
    "#import model\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas_datareader import data,wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"testLine\\nkospi = StockData('StockChart/SAMPLE','StockChart/KOSPI.csv',20,50,10,10,0.7)\\nprint(np.shape(kospi.trainSet))\\nprint(np.shape(kospi.testSet))\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class StockData():\n",
    "    \"\"\"\n",
    "        훈련용 데이터세트와 평가용 데이터세트를 만들기 위한 과정.\n",
    "\n",
    "        파라미터:\n",
    "            folderPath : 종목시장의 주가 csv가 저장되어있는 디렉토리 경로.\n",
    "            indexPath : 종목시장의 인덱스 주 csv파일의 경로.\n",
    "            timewindowsize : LSTM의 입력으로 들어가는 타임의 사이즈. 10일 경우 미래주가를 예측하기 위해 이전 10일 주가를 사용.\n",
    "            windowsizeForPCC : PCC를 계산하기 위해 사용되는 타임의 사이즈. 10일 경우 관계주를 구하기 위해 이전 10일 주가를 사용.\n",
    "            PositiveStockNumber : 긍정관계주 개수.\n",
    "            NegativeStockNumber : 부정관계주 개수.\n",
    "            train_test_rate : 훈련:평가 세트 비율. 0.7일 경우 생성된 데이터 세트중 70%는 훈련용, 30%는 평가용으로 사용.\n",
    "            batchSize : 세트를 나누는 배치 사이즈.\n",
    "\n",
    "        과정:\n",
    "            종목시장의 모든 종목의 시가와 인덱스 시가를 읽어옴.\n",
    "            minmax스케일러를 각 종목과 인덱스에 적용하고 저장.\n",
    "            PCC계산, 관계주 계산.\n",
    "            데이터세트 저장.\n",
    "               \n",
    "    \"\"\"\n",
    "    def __init__(self,folderPath,indexPath,timewindowsize,windowsizeForPCC,PostiveStockNumber,NegativeStockNumber,train_test_rate,batchSize):        \n",
    "               \n",
    "        if(train_test_rate<=0 or train_test_rate>=1):\n",
    "            raise ValueError('train_test_rate should be between 0 and 1')        \n",
    "        self.P=PostiveStockNumber\n",
    "        self.N=NegativeStockNumber        \n",
    "        self.T=timewindowsize\n",
    "        self.Tr=windowsizeForPCC\n",
    "        self.folderPath = folderPath      \n",
    "        self.indexPath=indexPath    \n",
    "        self.batchSize=batchSize\n",
    "        self.date_duration=3000\n",
    "        \n",
    "        self.train_test_rate=train_test_rate\n",
    "        self.scaler=MinMaxScaler(feature_range=(-1,1))  \n",
    "        self.indexScaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "        self.indexPrice = self.loadIndex()\n",
    "        self.stockPrice = self.loadCSV()\n",
    "\n",
    "        self.trainSet,self.testSet=self.make_dataset()\n",
    "\n",
    "        self.batchNum={}\n",
    "    \n",
    "    def getBatch(self,option):\n",
    "        \"\"\"\n",
    "        클래스에 저장된 세트를 y,xp,xn,xi,target으로 나누고 batch생성.\n",
    "\n",
    "        args:\n",
    "            option='training' or 'evaluation'\n",
    "\n",
    "        returns:\n",
    "            batch 제너레이터\n",
    "            batch={'y','xp','xn','xi','target'}\n",
    "        \"\"\"\n",
    "        if(option is not 'training' and option is not 'evaluation'):\n",
    "            raise ValueError('option should be \"training\" or \"evaluation\".')\n",
    "\n",
    "        if(option is 'training'):\n",
    "            returnSet = self.trainSet\n",
    "        else:\n",
    "            returnSet = self.testSet\n",
    "        \n",
    "        y=[]\n",
    "        xp=[]\n",
    "        xn=[]\n",
    "        xi=[]\n",
    "        target=[]\n",
    "\n",
    "        for d in returnSet:\n",
    "            y.append(d['target_history'])  \n",
    "            xp.append(d['pos_history'])       \n",
    "            xn.append(d['neg_history'])       \n",
    "            xi.append(d['index_history'])       \n",
    "            target.append(d['target_price'])             \n",
    "        y=np.reshape(y,(-1,self.T,1))\n",
    "        xp=np.reshape(xp,(-1,10,self.T,1))\n",
    "        xn=np.reshape(xn,(-1,10,self.T,1))\n",
    "        xi=np.reshape(xi,(-1,self.T,1))\n",
    "        target=np.reshape(target,(-1,1))\n",
    "\n",
    "        print(\"data1 : \" , y.shape,xp.shape,xn.shape,xi.shape,target.shape)     \n",
    "\n",
    "        batchNum=int(len(y)/self.batchSize)\n",
    "        self.batchNum[option]=batchNum\n",
    "\n",
    "        for i in range(batchNum):\n",
    "            yield {'y':y[i*self.batchSize:(i+1)*self.batchSize],\n",
    "                   'xp':xp[i*self.batchSize:(i+1)*self.batchSize],\n",
    "                   'xn':xn[i*self.batchSize:(i+1)*self.batchSize],\n",
    "                   'xi':xi[i*self.batchSize:(i+1)*self.batchSize],\n",
    "                   'target':target[i*self.batchSize:(i+1)*self.batchSize]}\n",
    "\n",
    "    def loadCSV(self):\n",
    "        \"\"\"\n",
    "        csv파일이 있는 폴더를 입력으로 받아 데이터를 읽어옴.\n",
    "        \"\"\"\n",
    "        csvList=os.listdir(self.folderPath)        \n",
    "        dataframe = pd.DataFrame([])\n",
    "        \n",
    "\n",
    "        for csv in csvList:\n",
    "            data=pd.read_csv(self.folderPath+'/'+csv,engine='python')\n",
    "            if(len(data)>self.date_duration):\n",
    "                data=data[-self.date_duration-1:-1]\n",
    "                data=data.reset_index()\n",
    "                data=data['open']\n",
    "\n",
    "                dataframe=dataframe.append(data,ignore_index=True)\n",
    "        dataT=np.array(dataframe).T\n",
    "        self.scaler.fit(dataT)\n",
    "        dataT=self.scaler.transform(dataT)\n",
    "        dataT=dataT.T\n",
    "        dataframe=pd.DataFrame(dataT)\n",
    "        dataframe=dataframe.transpose()\n",
    "        print('StockPrice shape: ',dataframe.shape)\n",
    "        return dataframe\n",
    "    \n",
    "    def loadIndex(self):\n",
    "        data=pd.read_csv(self.indexPath,engine='python')\n",
    "        data=data[-self.date_duration-1:-1]        \n",
    "        data=data.reset_index()\n",
    "        data=data.fillna(method='ffill')\n",
    "\n",
    "        data=np.array(data['Open'])\n",
    "        data=np.reshape(data,(-1,1))\n",
    "\n",
    "        data=self.indexScaler.fit_transform(data)\n",
    "\n",
    "        data=pd.DataFrame(np.squeeze(data))        \n",
    "\n",
    "        print('IndexPrice shape: ',data.shape)\n",
    "        return data \n",
    "\n",
    "\n",
    "    def make_dataset(self):\n",
    "        \"\"\"\n",
    "        예측모델에 사용되는 입력,타겟 데이터세트.\n",
    "        입력데이터의 shape는 (목표주식+관계주식+인덱스, 타임윈도우사이즈)\n",
    "        타겟데이터의 shape는 (1,1)\n",
    "        \"\"\"\n",
    "        maxday=max([self.T,self.Tr])\n",
    "        dataset=[]\n",
    "\n",
    "        for i in range(maxday,len(self.stockPrice)):\n",
    "            print('making dataset progress : {}/{}'.format(i,len(self.stockPrice)),end='\\r')\n",
    "            priceSet=self.stockPrice.loc[i-self.T:i-1]\n",
    "            targetSet=self.stockPrice.loc[i]\n",
    "            positiveSet,negativeSet=self.calculate_correlation(self.stockPrice.loc[i-maxday:i-1])\n",
    "            indexSet = self.indexPrice.loc[i-self.T:i-1]\n",
    "\n",
    "            for targetNum in priceSet.columns:\n",
    "                target_history=np.reshape(np.array(priceSet[targetNum]),(self.T,1))\n",
    "                pos_history=np.reshape(np.array(positiveSet[targetNum].T),(10,self.T,1))\n",
    "                neg_history=np.reshape(np.array(negativeSet[targetNum].T),(10,self.T,1))\n",
    "                index_history=np.reshape(np.array(indexSet),(self.T,1))\n",
    "                target_price=np.reshape(np.array(targetSet[targetNum]),(1,1))\n",
    "\n",
    "                dataset.append({'target_history':target_history,\n",
    "                                'pos_history':pos_history,\n",
    "                                'neg_history':neg_history,\n",
    "                                'index_history':index_history,\n",
    "                                'target_price':target_price\n",
    "                            })\n",
    "        print('making dataset progress : finished\\t')\n",
    "        \n",
    "        return dataset[:int(len(dataset)*self.train_test_rate)],dataset[int(len(dataset)*self.train_test_rate):]\n",
    "\n",
    "    def calculate_correlation(self,priceSet):\n",
    "        \"\"\"\n",
    "        Pearson Correlation Coefficient(PCC)를 계산하고,\n",
    "        높은순으로 긍정관계주, 낮은순으로 부정관계주를 설정한 개수만큼 생성하여 리스트에 저장한후, 리턴.\n",
    "        입력은 전체 종목의 타임윈도우간의 주가.\n",
    "\n",
    "        Returns:\n",
    "            #모든종목의 관계주. \n",
    "            긍정관계주 shape = (종목 수, dataframe(T*P))\n",
    "            부정관계주 shape = (종목 수, dataframe(T*N))\n",
    "        \"\"\"    \n",
    "        positive=[]\n",
    "        negative=[] \n",
    "        corr=priceSet[-self.Tr:].corr(method='pearson')\n",
    "\n",
    "        for i in corr.columns:\n",
    "            tempCorr=corr[i].sort_values(ascending=False)\n",
    "            index_P=tempCorr[1:self.P+1].index\n",
    "            index_N=tempCorr[-self.N:].index\n",
    "            \n",
    "            priceSet=priceSet[-self.T:]\n",
    "            posSet=priceSet[index_P]\n",
    "            negSet=priceSet[index_N]\n",
    "            posSet.columns=range(self.P)\n",
    "            negSet.columns=range(self.N)\n",
    "            \n",
    "            positive.append(posSet)\n",
    "            negative.append(negSet)\n",
    "        return positive,negative\n",
    "\n",
    "            \n",
    "\"\"\"testLine\n",
    "kospi = StockData('StockChart/SAMPLE','StockChart/KOSPI.csv',20,50,10,10,0.7)\n",
    "print(np.shape(kospi.trainSet))\n",
    "print(np.shape(kospi.testSet))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=20\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexPrice shape:  (5328, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by MinMaxScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-012bb078e262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnegative_correlation_sotck_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_test_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     batch_size)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-b9b47abeab84>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, folderPath, indexPath, timewindowsize, windowsizeForPCC, PostiveStockNumber, NegativeStockNumber, train_test_rate, batchSize)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexPrice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstockPrice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainSet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestSet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-b9b47abeab84>\u001b[0m in \u001b[0;36mloadCSV\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mdataframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mdataT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mdataT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mdataT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    371\u001b[0m         X = check_array(X,\n\u001b[1;32m    372\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                         force_all_finite=\"allow-nan\")\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    584\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[0;32m--> 586\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by MinMaxScaler."
     ]
    }
   ],
   "source": [
    "kospi=StockData(\n",
    "    'StockChart/SAMPLE',\n",
    "    'StockChart/KOSPI.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexPrice shape:  (40559, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by MinMaxScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-ad87f9b1bf6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnegative_correlation_sotck_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_test_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     batch_size)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-b9b47abeab84>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, folderPath, indexPath, timewindowsize, windowsizeForPCC, PostiveStockNumber, NegativeStockNumber, train_test_rate, batchSize)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexPrice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstockPrice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainSet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestSet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-b9b47abeab84>\u001b[0m in \u001b[0;36mloadCSV\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mdataframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mdataT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mdataT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mdataT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    371\u001b[0m         X = check_array(X,\n\u001b[1;32m    372\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                         force_all_finite=\"allow-nan\")\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    584\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[0;32m--> 586\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by MinMaxScaler."
     ]
    }
   ],
   "source": [
    "kospi=StockData(\n",
    "    'NASDAQ/Sample',\n",
    "    'NASDAQ/NDX.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rnn=tf.compat.v1.nn.rnn_cell\n",
    "class base_LSTMCell(rnn.BasicLSTMCell):\n",
    "    def __call__(self,inputs,state,scope=None):\n",
    "        \"\"\"Long short-term memory cell (LSTM).\"\"\"\n",
    "        with tf.variable_scope(scope or type(self).__name__):  # \"BasicLSTMCell\"\n",
    "        # Parameters of gates are concatenated into one multiply for efficiency.\n",
    "            if self._state_is_tuple:\n",
    "                c, h = state\n",
    "            else:\n",
    "                c, h = tf.split(1, 2, state)\n",
    "            concat = tf.layers.dense(tf.concat([inputs, h],axis=1), 4 * self._num_units)\n",
    "\n",
    "            # i = input_gate, j = new_input, f = forget_gate, o = output_gate\n",
    "            i, j, f, o = tf.split(concat, 4, 1)\n",
    "\n",
    "            new_c = (c * tf.sigmoid(f + self._forget_bias) + tf.sigmoid(i) *\n",
    "                    self._activation(j))\n",
    "            new_h = self._activation(new_c) * tf.sigmoid(o)\n",
    "\n",
    "            if self._state_is_tuple:\n",
    "                new_state = rnn.LSTMStateTuple(new_c, new_h)\n",
    "            else:\n",
    "                new_state = tf.concat(1, [new_c, new_h])\n",
    "        return new_h, new_state\n",
    "\n",
    "class MI_LSTMCell(rnn.BasicLSTMCell):\n",
    "    \"\"\"\n",
    "    Multi-Input LSTM proposed in the paper, Stock Price Prediction Using Attention-based Multi-Input LSTM.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "               num_units,\n",
    "               num_inputs,\n",
    "               forget_bias=1.0,\n",
    "               state_is_tuple=True,\n",
    "               activation=None,\n",
    "               reuse=None,\n",
    "               name=None,\n",
    "               dtype=None,\n",
    "               **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize the basic LSTM cell.\n",
    "        args:\n",
    "            num_inputs: MI-LSTM의 입력의 개수. \n",
    "                이 파라미터에 따라 입력 게이트의 어텐션 레이어를 설정.\n",
    "                최소 1개이상.\n",
    "                1개일 경우, 어텐션 레이어를 제외하고 기본 LSTM과 동일.\n",
    "        \"\"\"        \n",
    "        super(MI_LSTMCell,self).__init__(num_units,\n",
    "               forget_bias=1.0,\n",
    "               state_is_tuple=True,\n",
    "               activation=None,\n",
    "               reuse=None,\n",
    "               name=None,\n",
    "               dtype=None,\n",
    "               **kwargs)\n",
    "        \n",
    "        if(type(num_inputs) is not int):\n",
    "            raise ValueError(\"num_inputs should be integer\")\n",
    "        if(num_inputs < 1):\n",
    "            raise ValueError(\"num_inputs should not be less than 0\")\n",
    "        self.num_inputs = num_inputs\n",
    "        self.alpha_weight=self.add_variable('alpha_weight',shape=[self._num_units,self._num_units])\n",
    "        self.alpha_bias=[]\n",
    "        for i in range(self.num_inputs):\n",
    "            self.alpha_bias.append(self.add_variable('alpha_bias'+str(i),shape=[1],initializer=tf.zeros_initializer()))\n",
    "\n",
    "    def __call__(self,inputs,state,scope=None):\n",
    "        \"\"\"Long short-term memory cell (LSTM).\"\"\"\n",
    "        with tf.compat.v1.variable_scope(scope or type(self).__name__):  # \"BasicLSTMCell\"\n",
    "        # Parameters of gates are concatenated into one multiply for efficiency.\n",
    "            if self._state_is_tuple:\n",
    "                c, h = state\n",
    "            else:\n",
    "                c, h = tf.split(1, 2, state)\n",
    "            inputs_list = tf.split(inputs,self.num_inputs,1)\n",
    "            concat = tf.compat.v1.layers.dense(tf.concat([inputs_list[0], h],axis=1), (3+self.num_inputs) * self._num_units)\n",
    "                                 \n",
    "            # 0 = forget_gate, 1 = output_gate, 2= main_new_input, 3 = main_input_gate, 4~ = input_gate_for_auxiliary\n",
    "            main_list = tf.split(concat, 3+self.num_inputs, 1)\n",
    "                        \n",
    "            #new_input_gate= list of all new_input.\n",
    "            new_input_gate=[tf.tanh(main_list[2])]\n",
    "            #linear layer for auxiliary inputs.\n",
    "            for i in range(1,self.num_inputs):\n",
    "                new_input_gate.append(tf.compat.v1.layers.dense(tf.concat([inputs_list[i], h],axis=1),self._num_units,activation=tf.tanh))\n",
    "\n",
    "            #making list of l. l = sigmoid(input_gate) * tanh(new_input)\n",
    "            new_l=[]\n",
    "            for i,new_input in enumerate(new_input_gate,3):\n",
    "                new_l.append(tf.sigmoid(main_list[i]) * new_input)\n",
    "\n",
    "\n",
    "            #making list of u.            \n",
    "            u=[]\n",
    "            for i,l in enumerate(new_l):\n",
    "                #temp = transpos(l) X W X Cell_State.\n",
    "                temp1=tf.matmul(l,self.alpha_weight)\n",
    "                temp1=tf.expand_dims(temp1,1)\n",
    "                temp2=tf.matmul(temp1,tf.expand_dims(c,2))\n",
    "                u.append(tf.tanh(tf.squeeze(temp2+self.alpha_bias[i],axis=2)))\n",
    "\n",
    "            #making list of alpha.\n",
    "            alpha=tf.nn.softmax(u,axis=0)\n",
    "\n",
    "            #making L.\n",
    "            L=[]\n",
    "            for i,l in enumerate(new_l):\n",
    "                L.append(alpha[i]*l)\n",
    "            L=tf.reduce_sum(L,axis=0)\n",
    "\n",
    "\n",
    "            #new state = c(t-1) * f + L. new h = tanh(c) + sigmoid(o)\n",
    "            new_c = (c * tf.sigmoid(main_list[0] + self._forget_bias)+L)\n",
    "            new_h = self._activation(new_c) * tf.sigmoid(main_list[1])\n",
    "\n",
    "            if self._state_is_tuple:\n",
    "                new_state = rnn.LSTMStateTuple(new_c, new_h)\n",
    "            else:\n",
    "                new_state = tf.concat(1, [new_c, new_h])\n",
    "        return new_h, new_state\n",
    "\n",
    "\n",
    "class Attention_Layer():\n",
    "    \"\"\"\n",
    "    어텐션 레이어.\n",
    "    (None, TimeWindow, hidden_unit_size) shape의 LSTM 출력을 입력으로 받아 (None, 1, hidden_unit_size)의 텐서 출력.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        timewindow_size,\n",
    "        input_hidden_unit_size,\n",
    "        attention_size=None):\n",
    "        \"\"\"\n",
    "        Setting parameter for attention layer.\n",
    "        args:\n",
    "            timewindow_size = time window size of previous lstm layer.\n",
    "            input_hidden_unit_size = hidden unit number of previous lstm layer.\n",
    "            attention_size = size of this attention. \n",
    "                default = input_hidden_unit_size.\n",
    "        \"\"\"\n",
    "        if(attention_size is None):\n",
    "            attention_size=input_hidden_unit_size\n",
    "        self.o_size=attention_size\n",
    "        self.h_size=input_hidden_unit_size\n",
    "        self.t_size=timewindow_size\n",
    "\n",
    "        self.beta_weight=tf.Variable(tf.random.normal([self.h_size,self.o_size]), name='beta_weight')\n",
    "        self.beta_bias=tf.Variable(tf.zeros([self.o_size]),name='beta_bias')\n",
    "\n",
    "        self.v=tf.Variable(tf.random.normal([self.o_size,1]),name='beta_v')\n",
    "\n",
    "    def __call__(self,inputs):\n",
    "        \"\"\"\n",
    "        producing output with actual inputs.\n",
    "        shape of output will be (batch_size, 1, input_hidden_unit_size).\n",
    "        \"\"\"\n",
    "        #temp = tanh(Y X W + b) ->shape of result = (-1, self.o_size)\n",
    "        temp=tf.matmul(tf.reshape(inputs,[-1,self.h_size]),self.beta_weight)\n",
    "         \n",
    "        temp=tf.tanh(temp+self.beta_bias)\n",
    "        \n",
    "            \n",
    "        #j=temp X v\n",
    "        j=tf.reshape(tf.matmul(temp,self.v),[-1,self.t_size,1])\n",
    "\n",
    "        beta=tf.nn.softmax(j)\n",
    "        \n",
    "        \n",
    "\n",
    "        output=beta*inputs\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    \"\"\"\n",
    "    모든 예측모델들의 기본 클래스\n",
    "    \"\"\"\n",
    "    def __init__(self,sess,name,windowsize,Pos,Neg):\n",
    "        self.sess=sess\n",
    "        self.name=name\n",
    "        self.T=windowsize\n",
    "        self.P=Pos\n",
    "        self.N=Neg\n",
    "\n",
    "        \n",
    "        self._build_net()\n",
    "\n",
    "    def _build_net(self):\n",
    "        pass\n",
    "\n",
    "class LSTM_Model(Model):\n",
    "    \"\"\"\n",
    "    Basic LSTM list for test.\n",
    "    \"\"\"\n",
    "    def _build_net(self):\n",
    "        self.Y=tf.compat.v1.placeholder(tf.float32,[None,self.T,1])\n",
    "        self.Xp=tf.compat.v1.placeholder(tf.float32,[None,self.P,self.T,1])\n",
    "        self.Xn=tf.compat.v1.placeholder(tf.float32,[None,self.N,self.T,1])\n",
    "        self.Xi=tf.compat.v1.placeholder(tf.float32,[None,self.T,1])\n",
    "        self.Target=tf.compat.v1.placeholder(tf.float32,[None,1])\n",
    "\n",
    "\n",
    "        Xps=tf.split(self.Xp,self.P,1)\n",
    "        Xns=tf.split(self.Xn,self.N,1)\n",
    "        Xp_list=[]\n",
    "        Xn_list=[]\n",
    "\n",
    "    \n",
    "        LSTM=tf.compat.v1.nn.rnn_cell.LSTMCell(64,name='lstm1')\n",
    "        \n",
    "        Y_1,_=tf.compat.v1.nn.dynamic_rnn(LSTM,self.Y,dtype=tf.float32)\n",
    "        Xi_1,_=tf.compat.v1.nn.dynamic_rnn(LSTM,self.Xi,dtype=tf.float32)\n",
    "        for i in range(len(Xps)):\n",
    "            o,_=tf.compat.v1.nn.dynamic_rnn(LSTM,tf.squeeze(Xps[i],axis=1),dtype=tf.float32)\n",
    "            Xp_list.append(o)\n",
    "        for i in range(len(Xns)):\n",
    "            o,_=tf.compat.v1.nn.dynamic_rnn(LSTM,tf.squeeze(Xns[i],axis=1),dtype=tf.float32)\n",
    "            Xn_list.append(o)\n",
    "        Xp_1=tf.reduce_mean(Xp_list,0)\n",
    "        Xn_1=tf.reduce_mean(Xn_list,0)\n",
    "\n",
    "        result=tf.concat([Y_1,Xp_1,Xn_1,Xi_1],axis=2)\n",
    "       \n",
    "\n",
    "        #MI-LSTM\n",
    "        LSTM2=MI_LSTMCell(64,4,name='lstm2')\n",
    "       \n",
    "        Y_2,_ =tf.compat.v1.nn.dynamic_rnn(LSTM2,result,dtype=tf.float32)\n",
    "       \n",
    "\n",
    "        #Attention_Layer\n",
    "        attention_layer=Attention_Layer(self.T,64)\n",
    "        \n",
    "        Y_3=attention_layer(Y_2)\n",
    "        \n",
    "\n",
    "        #Non-linear units for producing final prediction.\n",
    "        R_1=tf.compat.v1.layers.dense(tf.compat.v1.layers.flatten(Y_3),64,tf.nn.relu)\n",
    "        \n",
    "        R_2=tf.compat.v1.layers.dense(R_1,64,tf.nn.relu)\n",
    "        \n",
    "        R_3=tf.compat.v1.layers.dense(R_2,64,tf.nn.relu)\n",
    "        \n",
    "        R_4=tf.compat.v1.layers.dense(R_3,64,tf.nn.relu)\n",
    "        \n",
    "        R_5=tf.compat.v1.layers.dense(R_4,64,tf.nn.relu)\n",
    "        \n",
    "        R_6=tf.compat.v1.layers.dense(R_5,1)\n",
    "       \n",
    "        self.out=R_6\n",
    "        \n",
    "        self.cost=tf.compat.v1.losses.mean_squared_error(labels=self.Target,predictions=self.out)\n",
    "        self.optimizer=tf.compat.v1.train.AdamOptimizer(0.001).minimize(self.cost)\n",
    "\n",
    "    def outputs(self,y,xp,xn,xi,target):\n",
    "        fd={self.Y:y,self.Xp:xp,self.Xn:xn,self.Xi:xi,self.Target:target}\n",
    "        return self.sess.run(self.out,feed_dict=fd)\n",
    "\n",
    "    def training(self,y,xp,xn,xi,target):\n",
    "        fd={self.Y:y,self.Xp:xp,self.Xn:xn,self.Xi:xi,self.Target:target}\n",
    "        return self.sess.run([self.cost,self.optimizer],feed_dict=fd)\n",
    "\n",
    "    def returnCost(self,y,xp,xn,xi,target):\n",
    "        fd={self.Y:y,self.Xp:xp,self.Xn:xn,self.Xi:xi,self.Target:target}\n",
    "        return self.sess.run(self.cost,feed_dict=fd)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## date_duration=3000 & NASDAQ data사용 & epoch=100 & batch_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexPrice shape:  (3000, 1)\n",
      "StockPrice shape:  (3000, 26)\n",
      "making dataset progress : finished\t\n",
      "\n",
      "#training#\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  5.237458671443164\n",
      "evalution_cost :  0.3748883716762066\n",
      "epoch : 0, t_cost : 0.050360, e_cost : 0.008520, elapsed time : 20.50sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  1.1653711509425193\n",
      "evalution_cost :  0.2531801275908947\n",
      "epoch : 1, t_cost : 0.011205, e_cost : 0.005754, elapsed time : 14.74sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.7974493517540395\n",
      "evalution_cost :  0.3047790043056011\n",
      "epoch : 2, t_cost : 0.007668, e_cost : 0.006927, elapsed time : 14.65sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.8255484555847943\n",
      "evalution_cost :  0.2120924056507647\n",
      "epoch : 3, t_cost : 0.007938, e_cost : 0.004820, elapsed time : 14.69sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.6087272095028311\n",
      "evalution_cost :  0.19883624545764178\n",
      "epoch : 4, t_cost : 0.005853, e_cost : 0.004519, elapsed time : 14.66sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.5106392157031223\n",
      "evalution_cost :  0.2028637167531997\n",
      "epoch : 5, t_cost : 0.004910, e_cost : 0.004611, elapsed time : 14.63sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.48425057623535395\n",
      "evalution_cost :  0.19866073271259665\n",
      "epoch : 6, t_cost : 0.004656, e_cost : 0.004515, elapsed time : 14.68sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.46384139463771135\n",
      "evalution_cost :  0.146806008531712\n",
      "epoch : 7, t_cost : 0.004460, e_cost : 0.003337, elapsed time : 14.73sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.41085222782567143\n",
      "evalution_cost :  0.14110887586139143\n",
      "epoch : 8, t_cost : 0.003951, e_cost : 0.003207, elapsed time : 14.69sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.38854675367474556\n",
      "evalution_cost :  0.14097467093961313\n",
      "epoch : 9, t_cost : 0.003736, e_cost : 0.003204, elapsed time : 14.72sec\n",
      "\n",
      "#Best result at epoch 9\n",
      "t_cost : 0.003736, e_cost : 0.003204\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "#parameter list\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=16\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "#\n",
    "kospi=StockData(\n",
    "    'StockChart/SAMPLE',\n",
    "    'StockChart/KOSPI.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "\n",
    "print('\\n#training#')\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "result_dic={}\n",
    "\n",
    "for i in range(10):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "\n",
    "    #training batch\n",
    "    for batch in kospi.getBatch('training'):\n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(\"traning_cost : \" , training_cost)\n",
    "    print(\"evalution_cost : \" , evalution_cost)\n",
    "   \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "        i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53690,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(kospi.trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23010,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(kospi.testSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_duration=40560 & NASDAQ data 사용 & epoch=100 & batch_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#training#\n",
      "IndexPrice shape:  (40559, 1)\n",
      "StockPrice shape:  (40559, 81)\n",
      "making dataset progress : finished\t59\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  8.41795479972643\n",
      "evalution_cost :  568.7187625253828\n",
      "epoch : 0, t_cost : 0.000938, e_cost : 0.147911, elapsed time : 1224.36sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  2.104333292263618\n",
      "evalution_cost :  303.60862822203853\n",
      "epoch : 1, t_cost : 0.000235, e_cost : 0.078962, elapsed time : 1219.76sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.7521878472907702\n",
      "evalution_cost :  112.48313071288067\n",
      "epoch : 2, t_cost : 0.000195, e_cost : 0.029254, elapsed time : 1220.23sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.4279438180292345\n",
      "evalution_cost :  106.02107808685832\n",
      "epoch : 3, t_cost : 0.000159, e_cost : 0.027574, elapsed time : 1219.76sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.3928213707740724\n",
      "evalution_cost :  90.08890977869123\n",
      "epoch : 4, t_cost : 0.000155, e_cost : 0.023430, elapsed time : 1219.92sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.3308113836046687\n",
      "evalution_cost :  106.42215150739685\n",
      "epoch : 5, t_cost : 0.000148, e_cost : 0.027678, elapsed time : 1219.66sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.3208292822964722\n",
      "evalution_cost :  120.86800584688353\n",
      "epoch : 6, t_cost : 0.000147, e_cost : 0.031435, elapsed time : 1219.91sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.3490852580957835\n",
      "evalution_cost :  126.12017654847477\n",
      "epoch : 7, t_cost : 0.000150, e_cost : 0.032801, elapsed time : 1219.98sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.3209642436922877\n",
      "evalution_cost :  117.82333022013518\n",
      "epoch : 8, t_cost : 0.000147, e_cost : 0.030643, elapsed time : 1219.97sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.2559241771105008\n",
      "evalution_cost :  128.7880592681031\n",
      "epoch : 9, t_cost : 0.000140, e_cost : 0.033495, elapsed time : 1219.90sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.2550406163823027\n",
      "evalution_cost :  128.78748691006513\n",
      "epoch : 10, t_cost : 0.000140, e_cost : 0.033495, elapsed time : 1219.78sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.2000914231857678\n",
      "evalution_cost :  126.94823259653458\n",
      "epoch : 11, t_cost : 0.000134, e_cost : 0.033016, elapsed time : 1219.87sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.147886878393365\n",
      "evalution_cost :  132.05130867735716\n",
      "epoch : 12, t_cost : 0.000128, e_cost : 0.034344, elapsed time : 1219.88sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.116349639490636\n",
      "evalution_cost :  138.19629241127404\n",
      "epoch : 13, t_cost : 0.000124, e_cost : 0.035942, elapsed time : 1219.97sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.1145415207097358\n",
      "evalution_cost :  143.63178377746226\n",
      "epoch : 14, t_cost : 0.000124, e_cost : 0.037355, elapsed time : 1219.79sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.0901723719321126\n",
      "evalution_cost :  145.2144475065361\n",
      "epoch : 15, t_cost : 0.000122, e_cost : 0.037767, elapsed time : 1220.24sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.0680588605810044\n",
      "evalution_cost :  152.88090852059395\n",
      "epoch : 16, t_cost : 0.000119, e_cost : 0.039761, elapsed time : 1219.91sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.0466983990518202\n",
      "evalution_cost :  152.64657145864112\n",
      "epoch : 17, t_cost : 0.000117, e_cost : 0.039700, elapsed time : 1219.84sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.0224369182410555\n",
      "evalution_cost :  153.96365455485648\n",
      "epoch : 18, t_cost : 0.000114, e_cost : 0.040043, elapsed time : 1220.16sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9993949928025359\n",
      "evalution_cost :  161.84585500319372\n",
      "epoch : 19, t_cost : 0.000111, e_cost : 0.042093, elapsed time : 1219.88sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.0043250941357655\n",
      "evalution_cost :  158.98046379416155\n",
      "epoch : 20, t_cost : 0.000112, e_cost : 0.041347, elapsed time : 1219.89sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9919914533215888\n",
      "evalution_cost :  158.89617305586398\n",
      "epoch : 21, t_cost : 0.000111, e_cost : 0.041325, elapsed time : 1219.84sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.0083503791661315\n",
      "evalution_cost :  164.95547407488812\n",
      "epoch : 22, t_cost : 0.000112, e_cost : 0.042901, elapsed time : 1219.86sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.999299298603546\n",
      "evalution_cost :  168.3569295422094\n",
      "epoch : 23, t_cost : 0.000111, e_cost : 0.043786, elapsed time : 1219.91sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.0204778575462115\n",
      "evalution_cost :  168.43559724850093\n",
      "epoch : 24, t_cost : 0.000114, e_cost : 0.043806, elapsed time : 1220.16sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.0234521317802319\n",
      "evalution_cost :  168.79209531523884\n",
      "epoch : 25, t_cost : 0.000114, e_cost : 0.043899, elapsed time : 1219.84sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.005651818500155\n",
      "evalution_cost :  167.1788903430006\n",
      "epoch : 26, t_cost : 0.000112, e_cost : 0.043480, elapsed time : 1219.82sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.0157855512948117\n",
      "evalution_cost :  167.4238635606289\n",
      "epoch : 27, t_cost : 0.000113, e_cost : 0.043543, elapsed time : 1219.74sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9977314374855268\n",
      "evalution_cost :  169.61759975179302\n",
      "epoch : 28, t_cost : 0.000111, e_cost : 0.044114, elapsed time : 1219.85sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9892276753344049\n",
      "evalution_cost :  168.0440199323075\n",
      "epoch : 29, t_cost : 0.000110, e_cost : 0.043705, elapsed time : 1220.05sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9938788805443437\n",
      "evalution_cost :  169.64937946534337\n",
      "epoch : 30, t_cost : 0.000111, e_cost : 0.044122, elapsed time : 1219.71sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9814931257151329\n",
      "evalution_cost :  168.780494840119\n",
      "epoch : 31, t_cost : 0.000109, e_cost : 0.043896, elapsed time : 1219.68sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9841811601163499\n",
      "evalution_cost :  171.65057048958442\n",
      "epoch : 32, t_cost : 0.000110, e_cost : 0.044643, elapsed time : 1219.70sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9733630886157698\n",
      "evalution_cost :  172.44319947591976\n",
      "epoch : 33, t_cost : 0.000108, e_cost : 0.044849, elapsed time : 1219.92sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9790341969542169\n",
      "evalution_cost :  180.23520456039296\n",
      "epoch : 34, t_cost : 0.000109, e_cost : 0.046875, elapsed time : 1219.97sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9829229813130951\n",
      "evalution_cost :  174.87266344328418\n",
      "epoch : 35, t_cost : 0.000110, e_cost : 0.045481, elapsed time : 1219.86sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9768869917643315\n",
      "evalution_cost :  180.80756716958786\n",
      "epoch : 36, t_cost : 0.000109, e_cost : 0.047024, elapsed time : 1220.01sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9630212120182478\n",
      "evalution_cost :  178.11426174477674\n",
      "epoch : 37, t_cost : 0.000107, e_cost : 0.046324, elapsed time : 1219.81sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.962300659030916\n",
      "evalution_cost :  180.6888967479772\n",
      "epoch : 38, t_cost : 0.000107, e_cost : 0.046993, elapsed time : 1219.67sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9416717111789694\n",
      "evalution_cost :  177.87823993136772\n",
      "epoch : 39, t_cost : 0.000105, e_cost : 0.046262, elapsed time : 1220.06sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9628520863352605\n",
      "evalution_cost :  175.67294874265644\n",
      "epoch : 40, t_cost : 0.000107, e_cost : 0.045689, elapsed time : 1219.92sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9514783771637667\n",
      "evalution_cost :  176.48458139855757\n",
      "epoch : 41, t_cost : 0.000106, e_cost : 0.045900, elapsed time : 1219.98sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9416498553741803\n",
      "evalution_cost :  181.30094802841813\n",
      "epoch : 42, t_cost : 0.000105, e_cost : 0.047152, elapsed time : 1219.96sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9488111491918971\n",
      "evalution_cost :  183.73260608437704\n",
      "epoch : 43, t_cost : 0.000106, e_cost : 0.047785, elapsed time : 1220.04sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9391222088001996\n",
      "evalution_cost :  177.38630967245808\n",
      "epoch : 44, t_cost : 0.000105, e_cost : 0.046134, elapsed time : 1219.85sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9374563439437225\n",
      "evalution_cost :  184.01326864760085\n",
      "epoch : 45, t_cost : 0.000104, e_cost : 0.047858, elapsed time : 1220.06sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9320676651368558\n",
      "evalution_cost :  180.5490827001595\n",
      "epoch : 46, t_cost : 0.000104, e_cost : 0.046957, elapsed time : 1220.03sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9365351063574963\n",
      "evalution_cost :  179.85583958139796\n",
      "epoch : 47, t_cost : 0.000104, e_cost : 0.046777, elapsed time : 1219.81sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9281553460182295\n",
      "evalution_cost :  172.59171290512677\n",
      "epoch : 48, t_cost : 0.000103, e_cost : 0.044887, elapsed time : 1219.70sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8978304833362927\n",
      "evalution_cost :  174.8418985025146\n",
      "epoch : 49, t_cost : 0.000100, e_cost : 0.045473, elapsed time : 1219.90sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9194726915161482\n",
      "evalution_cost :  176.87693804361334\n",
      "epoch : 50, t_cost : 0.000102, e_cost : 0.046002, elapsed time : 1219.65sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9112415518829948\n",
      "evalution_cost :  172.37543282338993\n",
      "epoch : 51, t_cost : 0.000102, e_cost : 0.044831, elapsed time : 1219.88sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9056296379280866\n",
      "evalution_cost :  169.05740643658464\n",
      "epoch : 52, t_cost : 0.000101, e_cost : 0.043968, elapsed time : 1220.20sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8849899147953693\n",
      "evalution_cost :  174.69848928805186\n",
      "epoch : 53, t_cost : 0.000099, e_cost : 0.045435, elapsed time : 1219.80sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8935257331868343\n",
      "evalution_cost :  171.55494879444268\n",
      "epoch : 54, t_cost : 0.000100, e_cost : 0.044618, elapsed time : 1220.02sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9031483767694226\n",
      "evalution_cost :  164.31395928705933\n",
      "epoch : 55, t_cost : 0.000101, e_cost : 0.042734, elapsed time : 1220.08sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8892209636005646\n",
      "evalution_cost :  164.3303542282065\n",
      "epoch : 56, t_cost : 0.000099, e_cost : 0.042739, elapsed time : 1219.91sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8774474287060912\n",
      "evalution_cost :  158.84961626968106\n",
      "epoch : 57, t_cost : 0.000098, e_cost : 0.041313, elapsed time : 1219.86sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8719380528450529\n",
      "evalution_cost :  159.4288798397847\n",
      "epoch : 58, t_cost : 0.000097, e_cost : 0.041464, elapsed time : 1219.92sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8682537056324691\n",
      "evalution_cost :  153.9251008424908\n",
      "epoch : 59, t_cost : 0.000097, e_cost : 0.040033, elapsed time : 1219.80sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8563412751668693\n",
      "evalution_cost :  158.0929836152245\n",
      "epoch : 60, t_cost : 0.000095, e_cost : 0.041117, elapsed time : 1219.76sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8535679521005477\n",
      "evalution_cost :  156.77877319468644\n",
      "epoch : 61, t_cost : 0.000095, e_cost : 0.040775, elapsed time : 1219.87sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8517274400260249\n",
      "evalution_cost :  158.67534354817508\n",
      "epoch : 62, t_cost : 0.000095, e_cost : 0.041268, elapsed time : 1219.89sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8628317467764646\n",
      "evalution_cost :  154.75965904262375\n",
      "epoch : 63, t_cost : 0.000096, e_cost : 0.040250, elapsed time : 1219.63sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8453493984961824\n",
      "evalution_cost :  156.48258522400465\n",
      "epoch : 64, t_cost : 0.000094, e_cost : 0.040698, elapsed time : 1219.88sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8399232613246568\n",
      "evalution_cost :  156.67992005132146\n",
      "epoch : 65, t_cost : 0.000094, e_cost : 0.040749, elapsed time : 1219.74sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.840290862972779\n",
      "evalution_cost :  160.14836087093863\n",
      "epoch : 66, t_cost : 0.000094, e_cost : 0.041651, elapsed time : 1219.93sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8484604227096497\n",
      "evalution_cost :  152.87770872545843\n",
      "epoch : 67, t_cost : 0.000095, e_cost : 0.039760, elapsed time : 1219.88sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8452062431242666\n",
      "evalution_cost :  160.48840581094737\n",
      "epoch : 68, t_cost : 0.000094, e_cost : 0.041740, elapsed time : 1219.82sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8390642006879716\n",
      "evalution_cost :  153.78934553639374\n",
      "epoch : 69, t_cost : 0.000094, e_cost : 0.039997, elapsed time : 1219.91sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8362307243601208\n",
      "evalution_cost :  157.09938634023274\n",
      "epoch : 70, t_cost : 0.000093, e_cost : 0.040858, elapsed time : 1220.00sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8374888074736191\n",
      "evalution_cost :  151.8699193559496\n",
      "epoch : 71, t_cost : 0.000093, e_cost : 0.039498, elapsed time : 1219.87sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traning_cost :  0.8311184860554022\n",
      "evalution_cost :  156.7732402355632\n",
      "epoch : 72, t_cost : 0.000093, e_cost : 0.040773, elapsed time : 1219.59sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8383389254836402\n",
      "evalution_cost :  154.85801175663255\n",
      "epoch : 73, t_cost : 0.000093, e_cost : 0.040275, elapsed time : 1219.78sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8242161296493578\n",
      "evalution_cost :  155.52892991053886\n",
      "epoch : 74, t_cost : 0.000092, e_cost : 0.040450, elapsed time : 1219.91sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8345354014618351\n",
      "evalution_cost :  153.54184470053224\n",
      "epoch : 75, t_cost : 0.000093, e_cost : 0.039933, elapsed time : 1219.75sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8188946725622372\n",
      "evalution_cost :  154.3945314915436\n",
      "epoch : 76, t_cost : 0.000091, e_cost : 0.040155, elapsed time : 1219.63sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8274968045338937\n",
      "evalution_cost :  158.91076851686194\n",
      "epoch : 77, t_cost : 0.000092, e_cost : 0.041329, elapsed time : 1219.90sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8249396254295789\n",
      "evalution_cost :  156.12082565337005\n",
      "epoch : 78, t_cost : 0.000092, e_cost : 0.040604, elapsed time : 1219.89sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8356273012245765\n",
      "evalution_cost :  155.84046393271092\n",
      "epoch : 79, t_cost : 0.000093, e_cost : 0.040531, elapsed time : 1220.07sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8214750513448053\n",
      "evalution_cost :  152.85321811713766\n",
      "epoch : 80, t_cost : 0.000092, e_cost : 0.039754, elapsed time : 1219.79sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8257523579522967\n",
      "evalution_cost :  157.3242202655747\n",
      "epoch : 81, t_cost : 0.000092, e_cost : 0.040917, elapsed time : 1219.51sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8237572661437298\n",
      "evalution_cost :  157.24934150586705\n",
      "epoch : 82, t_cost : 0.000092, e_cost : 0.040897, elapsed time : 1219.81sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8282288205045916\n",
      "evalution_cost :  155.15963230149828\n",
      "epoch : 83, t_cost : 0.000092, e_cost : 0.040354, elapsed time : 1219.88sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8169135331891084\n",
      "evalution_cost :  152.0731804033312\n",
      "epoch : 84, t_cost : 0.000091, e_cost : 0.039551, elapsed time : 1220.14sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8135583233315629\n",
      "evalution_cost :  155.85778473341088\n",
      "epoch : 85, t_cost : 0.000091, e_cost : 0.040535, elapsed time : 1220.10sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8204472389479633\n",
      "evalution_cost :  156.78842574968985\n",
      "epoch : 86, t_cost : 0.000091, e_cost : 0.040777, elapsed time : 1219.95sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8256991574148742\n",
      "evalution_cost :  156.6026295541851\n",
      "epoch : 87, t_cost : 0.000092, e_cost : 0.040729, elapsed time : 1219.69sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8174229437217946\n",
      "evalution_cost :  153.45104460428593\n",
      "epoch : 88, t_cost : 0.000091, e_cost : 0.039909, elapsed time : 1219.92sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8150423208362554\n",
      "evalution_cost :  157.42367338032636\n",
      "epoch : 89, t_cost : 0.000091, e_cost : 0.040942, elapsed time : 1219.95sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8215144060345665\n",
      "evalution_cost :  159.51426476756023\n",
      "epoch : 90, t_cost : 0.000092, e_cost : 0.041486, elapsed time : 1219.93sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8132119109895939\n",
      "evalution_cost :  157.1809618774405\n",
      "epoch : 91, t_cost : 0.000091, e_cost : 0.040879, elapsed time : 1219.77sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8173593500637253\n",
      "evalution_cost :  158.2409089518278\n",
      "epoch : 92, t_cost : 0.000091, e_cost : 0.041155, elapsed time : 1219.69sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8180448905272897\n",
      "evalution_cost :  155.93319152162985\n",
      "epoch : 93, t_cost : 0.000091, e_cost : 0.040555, elapsed time : 1219.69sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8172884072855595\n",
      "evalution_cost :  156.72666307927284\n",
      "epoch : 94, t_cost : 0.000091, e_cost : 0.040761, elapsed time : 1219.95sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8137075720733264\n",
      "evalution_cost :  157.34959274672474\n",
      "epoch : 95, t_cost : 0.000091, e_cost : 0.040923, elapsed time : 1220.47sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8116583490946141\n",
      "evalution_cost :  159.22523365049892\n",
      "epoch : 96, t_cost : 0.000090, e_cost : 0.041411, elapsed time : 1219.92sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8236596775591352\n",
      "evalution_cost :  156.52510166694083\n",
      "epoch : 97, t_cost : 0.000092, e_cost : 0.040709, elapsed time : 1220.08sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8179765247923569\n",
      "evalution_cost :  157.9454544334476\n",
      "epoch : 98, t_cost : 0.000091, e_cost : 0.041078, elapsed time : 1220.03sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.8216185518322163\n",
      "evalution_cost :  158.0398802705622\n",
      "epoch : 99, t_cost : 0.000092, e_cost : 0.041103, elapsed time : 1219.86sec\n",
      "\n",
      "#Best result at epoch 4\n",
      "t_cost : 0.000155, e_cost : 0.023430\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "#parameter list\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=16\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=256\n",
    "#\n",
    "\n",
    "print('\\n#training#')\n",
    "kospi=StockData(\n",
    "    'NASDAQ/Sample',\n",
    "    'NASDAQ/NDX.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "result_dic={}\n",
    "\n",
    "for i in range(100):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "\n",
    "    #training batch\n",
    "    for batch in kospi.getBatch('training'):\n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(\"traning_cost : \" , training_cost)\n",
    "    print(\"evalution_cost : \" , evalution_cost)\n",
    "   \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "        i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eopch : 10 , batchsize : 512 , timesize : 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexPrice shape:  (3000, 1)\n",
      "StockPrice shape:  (3000, 26)\n",
      "making dataset progress : finished\t\n",
      "\n",
      "#training#\n",
      "WARNING:tensorflow:From <ipython-input-4-17a179c18b7c>:36: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-4-17a179c18b7c>:38: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-3-924828131441>:55: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-3-924828131441>:76: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-17a179c18b7c>:65: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Flatten instead.\n",
      "data1 :  (53690, 4, 1) (53690, 10, 4, 1) (53690, 10, 4, 1) (53690, 4, 1) (53690, 1)\n",
      "data1 :  (23010, 4, 1) (23010, 10, 4, 1) (23010, 10, 4, 1) (23010, 4, 1) (23010, 1)\n",
      "traning_cost :  5.962402167264372\n",
      "evalution_cost :  0.11644078395329416\n",
      "epoch : 0, t_cost : 0.057331, e_cost : 0.002646, elapsed time : 9.26sec\n",
      "data1 :  (53690, 4, 1) (53690, 10, 4, 1) (53690, 10, 4, 1) (53690, 4, 1) (53690, 1)\n",
      "data1 :  (23010, 4, 1) (23010, 10, 4, 1) (23010, 10, 4, 1) (23010, 4, 1) (23010, 1)\n",
      "traning_cost :  0.36337794817518443\n",
      "evalution_cost :  0.14157951076049358\n",
      "epoch : 1, t_cost : 0.003494, e_cost : 0.003218, elapsed time : 4.16sec\n",
      "data1 :  (53690, 4, 1) (53690, 10, 4, 1) (53690, 10, 4, 1) (53690, 4, 1) (53690, 1)\n",
      "data1 :  (23010, 4, 1) (23010, 10, 4, 1) (23010, 10, 4, 1) (23010, 4, 1) (23010, 1)\n",
      "traning_cost :  0.37888617429416627\n",
      "evalution_cost :  0.15720446786144748\n",
      "epoch : 2, t_cost : 0.003643, e_cost : 0.003573, elapsed time : 4.15sec\n",
      "data1 :  (53690, 4, 1) (53690, 10, 4, 1) (53690, 10, 4, 1) (53690, 4, 1) (53690, 1)\n",
      "data1 :  (23010, 4, 1) (23010, 10, 4, 1) (23010, 10, 4, 1) (23010, 4, 1) (23010, 1)\n",
      "traning_cost :  0.37683432165067643\n",
      "evalution_cost :  0.18065413815202191\n",
      "epoch : 3, t_cost : 0.003623, e_cost : 0.004106, elapsed time : 4.16sec\n",
      "data1 :  (53690, 4, 1) (53690, 10, 4, 1) (53690, 10, 4, 1) (53690, 4, 1) (53690, 1)\n",
      "data1 :  (23010, 4, 1) (23010, 10, 4, 1) (23010, 10, 4, 1) (23010, 4, 1) (23010, 1)\n",
      "traning_cost :  0.4236544264713302\n",
      "evalution_cost :  0.24864511971827596\n",
      "epoch : 4, t_cost : 0.004074, e_cost : 0.005651, elapsed time : 4.14sec\n",
      "data1 :  (53690, 4, 1) (53690, 10, 4, 1) (53690, 10, 4, 1) (53690, 4, 1) (53690, 1)\n",
      "data1 :  (23010, 4, 1) (23010, 10, 4, 1) (23010, 10, 4, 1) (23010, 4, 1) (23010, 1)\n",
      "traning_cost :  0.536290246178396\n",
      "evalution_cost :  0.1854742558207363\n",
      "epoch : 5, t_cost : 0.005157, e_cost : 0.004215, elapsed time : 4.15sec\n",
      "data1 :  (53690, 4, 1) (53690, 10, 4, 1) (53690, 10, 4, 1) (53690, 4, 1) (53690, 1)\n",
      "data1 :  (23010, 4, 1) (23010, 10, 4, 1) (23010, 10, 4, 1) (23010, 4, 1) (23010, 1)\n",
      "traning_cost :  0.5240406722296029\n",
      "evalution_cost :  0.1384990398073569\n",
      "epoch : 6, t_cost : 0.005039, e_cost : 0.003148, elapsed time : 4.15sec\n",
      "data1 :  (53690, 4, 1) (53690, 10, 4, 1) (53690, 10, 4, 1) (53690, 4, 1) (53690, 1)\n",
      "data1 :  (23010, 4, 1) (23010, 10, 4, 1) (23010, 10, 4, 1) (23010, 4, 1) (23010, 1)\n",
      "traning_cost :  0.3701754518551752\n",
      "evalution_cost :  0.11600109376013279\n",
      "epoch : 7, t_cost : 0.003559, e_cost : 0.002636, elapsed time : 4.15sec\n",
      "data1 :  (53690, 4, 1) (53690, 10, 4, 1) (53690, 10, 4, 1) (53690, 4, 1) (53690, 1)\n",
      "data1 :  (23010, 4, 1) (23010, 10, 4, 1) (23010, 10, 4, 1) (23010, 4, 1) (23010, 1)\n",
      "traning_cost :  0.32776462007313967\n",
      "evalution_cost :  0.10869349032873288\n",
      "epoch : 8, t_cost : 0.003152, e_cost : 0.002470, elapsed time : 4.19sec\n",
      "data1 :  (53690, 4, 1) (53690, 10, 4, 1) (53690, 10, 4, 1) (53690, 4, 1) (53690, 1)\n",
      "data1 :  (23010, 4, 1) (23010, 10, 4, 1) (23010, 10, 4, 1) (23010, 4, 1) (23010, 1)\n",
      "traning_cost :  0.31040312082041055\n",
      "evalution_cost :  0.11105892749037594\n",
      "epoch : 9, t_cost : 0.002985, e_cost : 0.002524, elapsed time : 4.16sec\n",
      "\n",
      "#Best result at epoch 8\n",
      "t_cost : 0.003152, e_cost : 0.002470\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "#parameter list\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=4\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "#\n",
    "kospi=StockData(\n",
    "    'StockChart/SAMPLE',\n",
    "    'StockChart/KOSPI.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "\n",
    "print('\\n#training#')\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "result_dic={}\n",
    "\n",
    "for i in range(10):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "\n",
    "    #training batch\n",
    "    for batch in kospi.getBatch('training'):\n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(\"traning_cost : \" , training_cost)\n",
    "    print(\"evalution_cost : \" , evalution_cost)\n",
    "   \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "        i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eopch : 30 , batchsize : 512 , timesize : 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexPrice shape:  (3000, 1)\n",
      "StockPrice shape:  (3000, 26)\n",
      "making dataset progress : finished\t\n",
      "\n",
      "#training#\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  4.397981100715697\n",
      "evalution_cost :  0.29077428951859474\n",
      "epoch : 0, t_cost : 0.042288, e_cost : 0.006609, elapsed time : 19.31sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.8660098274704069\n",
      "evalution_cost :  0.3474391414783895\n",
      "epoch : 1, t_cost : 0.008327, e_cost : 0.007896, elapsed time : 14.31sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.8573140774387866\n",
      "evalution_cost :  0.3989060885505751\n",
      "epoch : 2, t_cost : 0.008243, e_cost : 0.009066, elapsed time : 14.31sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.8091267579002306\n",
      "evalution_cost :  0.4424528544768691\n",
      "epoch : 3, t_cost : 0.007780, e_cost : 0.010056, elapsed time : 14.29sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.5937124991323799\n",
      "evalution_cost :  0.22813560022041202\n",
      "epoch : 4, t_cost : 0.005709, e_cost : 0.005185, elapsed time : 14.29sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.5079121382441372\n",
      "evalution_cost :  0.2533651702105999\n",
      "epoch : 5, t_cost : 0.004884, e_cost : 0.005758, elapsed time : 14.38sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.49654006003402174\n",
      "evalution_cost :  0.20983862760476768\n",
      "epoch : 6, t_cost : 0.004774, e_cost : 0.004769, elapsed time : 14.33sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.45968434785027057\n",
      "evalution_cost :  0.18125841720029712\n",
      "epoch : 7, t_cost : 0.004420, e_cost : 0.004120, elapsed time : 14.41sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.41302320058457553\n",
      "evalution_cost :  0.1655523154186085\n",
      "epoch : 8, t_cost : 0.003971, e_cost : 0.003763, elapsed time : 14.43sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.38853481283877045\n",
      "evalution_cost :  0.15226285089738667\n",
      "epoch : 9, t_cost : 0.003736, e_cost : 0.003461, elapsed time : 14.41sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.36225719715002924\n",
      "evalution_cost :  0.14638075971743092\n",
      "epoch : 10, t_cost : 0.003483, e_cost : 0.003327, elapsed time : 14.33sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.35524818842532113\n",
      "evalution_cost :  0.14044973417185247\n",
      "epoch : 11, t_cost : 0.003416, e_cost : 0.003192, elapsed time : 14.31sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.33275905513437465\n",
      "evalution_cost :  0.1320629891124554\n",
      "epoch : 12, t_cost : 0.003200, e_cost : 0.003001, elapsed time : 14.32sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.3304340914473869\n",
      "evalution_cost :  0.12828965939115733\n",
      "epoch : 13, t_cost : 0.003177, e_cost : 0.002916, elapsed time : 14.33sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.3128655014443211\n",
      "evalution_cost :  0.11702228075591847\n",
      "epoch : 14, t_cost : 0.003008, e_cost : 0.002660, elapsed time : 14.34sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.2944056160049513\n",
      "evalution_cost :  0.11103554256260395\n",
      "epoch : 15, t_cost : 0.002831, e_cost : 0.002524, elapsed time : 14.36sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.2920185292023234\n",
      "evalution_cost :  0.11163885536370799\n",
      "epoch : 16, t_cost : 0.002808, e_cost : 0.002537, elapsed time : 14.37sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.2858670299174264\n",
      "evalution_cost :  0.11679983249632642\n",
      "epoch : 17, t_cost : 0.002749, e_cost : 0.002655, elapsed time : 14.35sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.3002683856175281\n",
      "evalution_cost :  0.10229981952579692\n",
      "epoch : 18, t_cost : 0.002887, e_cost : 0.002325, elapsed time : 14.40sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.2725693097454496\n",
      "evalution_cost :  0.09726445347769186\n",
      "epoch : 19, t_cost : 0.002621, e_cost : 0.002211, elapsed time : 14.41sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.26480516738956794\n",
      "evalution_cost :  0.09268630720907822\n",
      "epoch : 20, t_cost : 0.002546, e_cost : 0.002107, elapsed time : 14.42sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.24857752455864102\n",
      "evalution_cost :  0.08935708680655807\n",
      "epoch : 21, t_cost : 0.002390, e_cost : 0.002031, elapsed time : 14.45sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.24356090009678155\n",
      "evalution_cost :  0.08838342747185379\n",
      "epoch : 22, t_cost : 0.002342, e_cost : 0.002009, elapsed time : 14.42sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.2403619833639823\n",
      "evalution_cost :  0.08361371804494411\n",
      "epoch : 23, t_cost : 0.002311, e_cost : 0.001900, elapsed time : 14.43sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.22775857796659693\n",
      "evalution_cost :  0.08277940331026912\n",
      "epoch : 24, t_cost : 0.002190, e_cost : 0.001881, elapsed time : 14.41sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.21721531567163765\n",
      "evalution_cost :  0.08275402092840523\n",
      "epoch : 25, t_cost : 0.002089, e_cost : 0.001881, elapsed time : 14.43sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.21648004226153716\n",
      "evalution_cost :  0.08283119078259915\n",
      "epoch : 26, t_cost : 0.002082, e_cost : 0.001883, elapsed time : 14.35sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.2185226451838389\n",
      "evalution_cost :  0.08572887562331744\n",
      "epoch : 27, t_cost : 0.002101, e_cost : 0.001948, elapsed time : 14.49sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.21727834298508242\n",
      "evalution_cost :  0.0898333142104093\n",
      "epoch : 28, t_cost : 0.002089, e_cost : 0.002042, elapsed time : 14.43sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.22136623470578343\n",
      "evalution_cost :  0.09289511910174042\n",
      "epoch : 29, t_cost : 0.002129, e_cost : 0.002111, elapsed time : 14.43sec\n",
      "\n",
      "#Best result at epoch 25\n",
      "t_cost : 0.002089, e_cost : 0.001881\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "#parameter list\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=16\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "#\n",
    "kospi=StockData(\n",
    "    'StockChart/SAMPLE',\n",
    "    'StockChart/KOSPI.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "\n",
    "print('\\n#training#')\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "result_dic={}\n",
    "\n",
    "for i in range(30):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "\n",
    "    #training batch\n",
    "    for batch in kospi.getBatch('training'):\n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(\"traning_cost : \" , training_cost)\n",
    "    print(\"evalution_cost : \" , evalution_cost)\n",
    "   \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "        i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eopch : 100 , batchsize : 256 , timesize : 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexPrice shape:  (3000, 1)\n",
      "StockPrice shape:  (3000, 26)\n",
      "making dataset progress : finished\t\n",
      "\n",
      "#training#\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  7.292597506660968\n",
      "evalution_cost :  0.3700101098511368\n",
      "epoch : 0, t_cost : 0.034893, e_cost : 0.004157, elapsed time : 19.99sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  1.1710608782013878\n",
      "evalution_cost :  0.5209772535599768\n",
      "epoch : 1, t_cost : 0.005603, e_cost : 0.005854, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  1.2526973487110808\n",
      "evalution_cost :  0.6881660227663815\n",
      "epoch : 2, t_cost : 0.005994, e_cost : 0.007732, elapsed time : 15.02sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  1.1067402343032882\n",
      "evalution_cost :  0.6004736210452393\n",
      "epoch : 3, t_cost : 0.005295, e_cost : 0.006747, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.9040068893227726\n",
      "evalution_cost :  0.4490058767842129\n",
      "epoch : 4, t_cost : 0.004325, e_cost : 0.005045, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.7777825247030705\n",
      "evalution_cost :  0.3485232458333485\n",
      "epoch : 5, t_cost : 0.003721, e_cost : 0.003916, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.7241732740658335\n",
      "evalution_cost :  0.4400038866442628\n",
      "epoch : 6, t_cost : 0.003465, e_cost : 0.004944, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.7015733700245619\n",
      "evalution_cost :  0.4077300860080868\n",
      "epoch : 7, t_cost : 0.003357, e_cost : 0.004581, elapsed time : 15.06sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.6614947316120379\n",
      "evalution_cost :  0.44959705806104466\n",
      "epoch : 8, t_cost : 0.003165, e_cost : 0.005052, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.6522447259631008\n",
      "evalution_cost :  0.4756811432307586\n",
      "epoch : 9, t_cost : 0.003121, e_cost : 0.005345, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.6382514162105508\n",
      "evalution_cost :  0.3822585926973261\n",
      "epoch : 10, t_cost : 0.003054, e_cost : 0.004295, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.588726015703287\n",
      "evalution_cost :  0.26180591629236005\n",
      "epoch : 11, t_cost : 0.002817, e_cost : 0.002942, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.47649012491456233\n",
      "evalution_cost :  0.21047886152518913\n",
      "epoch : 12, t_cost : 0.002280, e_cost : 0.002365, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.40010643276036717\n",
      "evalution_cost :  0.18445584771689028\n",
      "epoch : 13, t_cost : 0.001914, e_cost : 0.002073, elapsed time : 15.02sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3770659458532464\n",
      "evalution_cost :  0.1738327315542847\n",
      "epoch : 14, t_cost : 0.001804, e_cost : 0.001953, elapsed time : 15.02sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.37015365611296147\n",
      "evalution_cost :  0.176470042031724\n",
      "epoch : 15, t_cost : 0.001771, e_cost : 0.001983, elapsed time : 15.07sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.36264962487621233\n",
      "evalution_cost :  0.1723367962113116\n",
      "epoch : 16, t_cost : 0.001735, e_cost : 0.001936, elapsed time : 15.02sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.35565735172713175\n",
      "evalution_cost :  0.1950400788045954\n",
      "epoch : 17, t_cost : 0.001702, e_cost : 0.002191, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3883910456788726\n",
      "evalution_cost :  0.1824320941523183\n",
      "epoch : 18, t_cost : 0.001858, e_cost : 0.002050, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3910527460393496\n",
      "evalution_cost :  0.16792578884633258\n",
      "epoch : 19, t_cost : 0.001871, e_cost : 0.001887, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3807100959238596\n",
      "evalution_cost :  0.1583458287641406\n",
      "epoch : 20, t_cost : 0.001822, e_cost : 0.001779, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.36896284634713084\n",
      "evalution_cost :  0.14522242068778723\n",
      "epoch : 21, t_cost : 0.001765, e_cost : 0.001632, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3586310586833861\n",
      "evalution_cost :  0.13942621301976033\n",
      "epoch : 22, t_cost : 0.001716, e_cost : 0.001567, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3504053932556417\n",
      "evalution_cost :  0.13514471956295893\n",
      "epoch : 23, t_cost : 0.001677, e_cost : 0.001518, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.34435602839221247\n",
      "evalution_cost :  0.133331261749845\n",
      "epoch : 24, t_cost : 0.001648, e_cost : 0.001498, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3408501627855003\n",
      "evalution_cost :  0.1328523519623559\n",
      "epoch : 25, t_cost : 0.001631, e_cost : 0.001493, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3388351756730117\n",
      "evalution_cost :  0.13254845290794037\n",
      "epoch : 26, t_cost : 0.001621, e_cost : 0.001489, elapsed time : 15.02sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3361312987108249\n",
      "evalution_cost :  0.13135324316681363\n",
      "epoch : 27, t_cost : 0.001608, e_cost : 0.001476, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.33205106362584047\n",
      "evalution_cost :  0.13021673006005585\n",
      "epoch : 28, t_cost : 0.001589, e_cost : 0.001463, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3374885036610067\n",
      "evalution_cost :  0.1309645516157616\n",
      "epoch : 29, t_cost : 0.001615, e_cost : 0.001472, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.339180860290071\n",
      "evalution_cost :  0.12850636534858495\n",
      "epoch : 30, t_cost : 0.001623, e_cost : 0.001444, elapsed time : 15.02sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.33585640011006035\n",
      "evalution_cost :  0.12636722932802513\n",
      "epoch : 31, t_cost : 0.001607, e_cost : 0.001420, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3353053276659921\n",
      "evalution_cost :  0.12421582624665461\n",
      "epoch : 32, t_cost : 0.001604, e_cost : 0.001396, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3313413646246772\n",
      "evalution_cost :  0.1199085409170948\n",
      "epoch : 33, t_cost : 0.001585, e_cost : 0.001347, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.322858258994529\n",
      "evalution_cost :  0.11937487486284226\n",
      "epoch : 34, t_cost : 0.001545, e_cost : 0.001341, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3241689183341805\n",
      "evalution_cost :  0.11551030830014497\n",
      "epoch : 35, t_cost : 0.001551, e_cost : 0.001298, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.31887652797740884\n",
      "evalution_cost :  0.11395674501545727\n",
      "epoch : 36, t_cost : 0.001526, e_cost : 0.001280, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3162769305636175\n",
      "evalution_cost :  0.11467935601831414\n",
      "epoch : 37, t_cost : 0.001513, e_cost : 0.001289, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3148741323966533\n",
      "evalution_cost :  0.11322390465647914\n",
      "epoch : 38, t_cost : 0.001507, e_cost : 0.001272, elapsed time : 15.02sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3143675167520996\n",
      "evalution_cost :  0.11330060407635756\n",
      "epoch : 39, t_cost : 0.001504, e_cost : 0.001273, elapsed time : 15.07sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.31557098199846223\n",
      "evalution_cost :  0.11094380615395494\n",
      "epoch : 40, t_cost : 0.001510, e_cost : 0.001247, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3142060392710846\n",
      "evalution_cost :  0.11339051279355772\n",
      "epoch : 41, t_cost : 0.001503, e_cost : 0.001274, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.315144653985044\n",
      "evalution_cost :  0.11148009513271973\n",
      "epoch : 42, t_cost : 0.001508, e_cost : 0.001253, elapsed time : 15.06sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3133064476714935\n",
      "evalution_cost :  0.11005740100517869\n",
      "epoch : 43, t_cost : 0.001499, e_cost : 0.001237, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3106875776720699\n",
      "evalution_cost :  0.1079478102910798\n",
      "epoch : 44, t_cost : 0.001487, e_cost : 0.001213, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3080403539352119\n",
      "evalution_cost :  0.10737996673560701\n",
      "epoch : 45, t_cost : 0.001474, e_cost : 0.001207, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.30735542901675217\n",
      "evalution_cost :  0.1060456498817075\n",
      "epoch : 46, t_cost : 0.001471, e_cost : 0.001192, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3057462165306788\n",
      "evalution_cost :  0.10621130766230635\n",
      "epoch : 47, t_cost : 0.001463, e_cost : 0.001193, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3045948446379043\n",
      "evalution_cost :  0.10580710973590612\n",
      "epoch : 48, t_cost : 0.001457, e_cost : 0.001189, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3021565292146988\n",
      "evalution_cost :  0.10650673971395008\n",
      "epoch : 49, t_cost : 0.001446, e_cost : 0.001197, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3064750899502542\n",
      "evalution_cost :  0.10505403418210335\n",
      "epoch : 50, t_cost : 0.001466, e_cost : 0.001180, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3040368185029365\n",
      "evalution_cost :  0.10389778509852476\n",
      "epoch : 51, t_cost : 0.001455, e_cost : 0.001167, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traning_cost :  0.30129198177019134\n",
      "evalution_cost :  0.10217295071925037\n",
      "epoch : 52, t_cost : 0.001442, e_cost : 0.001148, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.29878516669850796\n",
      "evalution_cost :  0.10211376714869402\n",
      "epoch : 53, t_cost : 0.001430, e_cost : 0.001147, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2980701925116591\n",
      "evalution_cost :  0.10227026368374936\n",
      "epoch : 54, t_cost : 0.001426, e_cost : 0.001149, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.29695893698954023\n",
      "evalution_cost :  0.10357770277187228\n",
      "epoch : 55, t_cost : 0.001421, e_cost : 0.001164, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2977963453740813\n",
      "evalution_cost :  0.10219437492196448\n",
      "epoch : 56, t_cost : 0.001425, e_cost : 0.001148, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.29519013524986804\n",
      "evalution_cost :  0.10179222724400461\n",
      "epoch : 57, t_cost : 0.001412, e_cost : 0.001144, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.29346129682380706\n",
      "evalution_cost :  0.10187159167253412\n",
      "epoch : 58, t_cost : 0.001404, e_cost : 0.001145, elapsed time : 15.06sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2937444132694509\n",
      "evalution_cost :  0.10263859730912372\n",
      "epoch : 59, t_cost : 0.001405, e_cost : 0.001153, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2930017959442921\n",
      "evalution_cost :  0.10112111430498771\n",
      "epoch : 60, t_cost : 0.001402, e_cost : 0.001136, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.29144694400019944\n",
      "evalution_cost :  0.1009689134079963\n",
      "epoch : 61, t_cost : 0.001394, e_cost : 0.001134, elapsed time : 15.02sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2897123975562863\n",
      "evalution_cost :  0.10109035728964955\n",
      "epoch : 62, t_cost : 0.001386, e_cost : 0.001136, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2886813117947895\n",
      "evalution_cost :  0.10059761497541331\n",
      "epoch : 63, t_cost : 0.001381, e_cost : 0.001130, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2870892698701937\n",
      "evalution_cost :  0.10071105105453171\n",
      "epoch : 64, t_cost : 0.001374, e_cost : 0.001132, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.28696320456219837\n",
      "evalution_cost :  0.10182075345073827\n",
      "epoch : 65, t_cost : 0.001373, e_cost : 0.001144, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2864727670676075\n",
      "evalution_cost :  0.10053956482443027\n",
      "epoch : 66, t_cost : 0.001371, e_cost : 0.001130, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.28531892705359496\n",
      "evalution_cost :  0.10189209907548502\n",
      "epoch : 67, t_cost : 0.001365, e_cost : 0.001145, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2887652601348236\n",
      "evalution_cost :  0.1009075058682356\n",
      "epoch : 68, t_cost : 0.001382, e_cost : 0.001134, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2876504345040303\n",
      "evalution_cost :  0.09953136087278835\n",
      "epoch : 69, t_cost : 0.001376, e_cost : 0.001118, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.28583174938103184\n",
      "evalution_cost :  0.09735954320058227\n",
      "epoch : 70, t_cost : 0.001368, e_cost : 0.001094, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.28392460217582993\n",
      "evalution_cost :  0.09824030788149685\n",
      "epoch : 71, t_cost : 0.001358, e_cost : 0.001104, elapsed time : 15.06sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.28231731668347493\n",
      "evalution_cost :  0.0971779445244465\n",
      "epoch : 72, t_cost : 0.001351, e_cost : 0.001092, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.28016174060758203\n",
      "evalution_cost :  0.09708053912618198\n",
      "epoch : 73, t_cost : 0.001340, e_cost : 0.001091, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2801353808317799\n",
      "evalution_cost :  0.09752747110906057\n",
      "epoch : 74, t_cost : 0.001340, e_cost : 0.001096, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.28169408909161575\n",
      "evalution_cost :  0.09914676946937107\n",
      "epoch : 75, t_cost : 0.001348, e_cost : 0.001114, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2812198275933042\n",
      "evalution_cost :  0.0976210032531526\n",
      "epoch : 76, t_cost : 0.001346, e_cost : 0.001097, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2804705763410311\n",
      "evalution_cost :  0.09903784928610548\n",
      "epoch : 77, t_cost : 0.001342, e_cost : 0.001113, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traning_cost :  0.2803121214383282\n",
      "evalution_cost :  0.09700144320959225\n",
      "epoch : 78, t_cost : 0.001341, e_cost : 0.001090, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.27680695822346024\n",
      "evalution_cost :  0.09620141561026685\n",
      "epoch : 79, t_cost : 0.001324, e_cost : 0.001081, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.27325359656242654\n",
      "evalution_cost :  0.09713814599672332\n",
      "epoch : 80, t_cost : 0.001307, e_cost : 0.001091, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2784076761745382\n",
      "evalution_cost :  0.09884553926531225\n",
      "epoch : 81, t_cost : 0.001332, e_cost : 0.001111, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.27629559554043226\n",
      "evalution_cost :  0.09959662330220453\n",
      "epoch : 82, t_cost : 0.001322, e_cost : 0.001119, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.27785568448598497\n",
      "evalution_cost :  0.09840294628520496\n",
      "epoch : 83, t_cost : 0.001329, e_cost : 0.001106, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2778499395644758\n",
      "evalution_cost :  0.09845551746548153\n",
      "epoch : 84, t_cost : 0.001329, e_cost : 0.001106, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.27827939242706634\n",
      "evalution_cost :  0.09621679718839005\n",
      "epoch : 85, t_cost : 0.001331, e_cost : 0.001081, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.27415127225685865\n",
      "evalution_cost :  0.09664865653030574\n",
      "epoch : 86, t_cost : 0.001312, e_cost : 0.001086, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2734522256942\n",
      "evalution_cost :  0.09650276796310209\n",
      "epoch : 87, t_cost : 0.001308, e_cost : 0.001084, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.27138848273898475\n",
      "evalution_cost :  0.0964814021717757\n",
      "epoch : 88, t_cost : 0.001299, e_cost : 0.001084, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2693839263229165\n",
      "evalution_cost :  0.09928684099577367\n",
      "epoch : 89, t_cost : 0.001289, e_cost : 0.001116, elapsed time : 15.06sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.26968104363186285\n",
      "evalution_cost :  0.09845195588422939\n",
      "epoch : 90, t_cost : 0.001290, e_cost : 0.001106, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.27142706580343656\n",
      "evalution_cost :  0.10025734669761732\n",
      "epoch : 91, t_cost : 0.001299, e_cost : 0.001126, elapsed time : 15.03sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.27066276656114496\n",
      "evalution_cost :  0.10149444287526421\n",
      "epoch : 92, t_cost : 0.001295, e_cost : 0.001140, elapsed time : 15.02sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2749800437595695\n",
      "evalution_cost :  0.10022448093513958\n",
      "epoch : 93, t_cost : 0.001316, e_cost : 0.001126, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.27545205160276964\n",
      "evalution_cost :  0.10009022013400681\n",
      "epoch : 94, t_cost : 0.001318, e_cost : 0.001125, elapsed time : 15.04sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.27385182288708165\n",
      "evalution_cost :  0.09714485766016878\n",
      "epoch : 95, t_cost : 0.001310, e_cost : 0.001092, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.26866562431678176\n",
      "evalution_cost :  0.09604153971304186\n",
      "epoch : 96, t_cost : 0.001285, e_cost : 0.001079, elapsed time : 15.02sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2653248588030692\n",
      "evalution_cost :  0.09663495363201946\n",
      "epoch : 97, t_cost : 0.001269, e_cost : 0.001086, elapsed time : 15.02sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2647216776094865\n",
      "evalution_cost :  0.09842124624992721\n",
      "epoch : 98, t_cost : 0.001267, e_cost : 0.001106, elapsed time : 15.05sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.26690396439516917\n",
      "evalution_cost :  0.1001878049573861\n",
      "epoch : 99, t_cost : 0.001277, e_cost : 0.001126, elapsed time : 15.04sec\n",
      "\n",
      "#Best result at epoch 96\n",
      "t_cost : 0.001285, e_cost : 0.001079\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "#parameter list\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=8\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=256\n",
    "#\n",
    "kospi=StockData(\n",
    "    'StockChart/SAMPLE',\n",
    "    'StockChart/KOSPI.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "\n",
    "print('\\n#training#')\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "result_dic={}\n",
    "\n",
    "for i in range(100):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "\n",
    "    #training batch\n",
    "    for batch in kospi.getBatch('training'):\n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(\"traning_cost : \" , training_cost)\n",
    "    print(\"evalution_cost : \" , evalution_cost)\n",
    "   \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "        i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eopch : 100 , batchsize : 512 , timesize : 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexPrice shape:  (3000, 1)\n",
      "StockPrice shape:  (3000, 26)\n",
      "making dataset progress : finished\t\n",
      "\n",
      "#training#\n",
      "WARNING:tensorflow:From <ipython-input-4-17a179c18b7c>:36: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-4-17a179c18b7c>:38: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-3-924828131441>:55: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-3-924828131441>:76: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-17a179c18b7c>:65: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Flatten instead.\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  5.595243300776929\n",
      "evalution_cost :  0.44788643484935164\n",
      "epoch : 0, t_cost : 0.053800, e_cost : 0.010179, elapsed time : 12.31sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.8335438938811421\n",
      "evalution_cost :  0.1845004492206499\n",
      "epoch : 1, t_cost : 0.008015, e_cost : 0.004193, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.5350101251387969\n",
      "evalution_cost :  0.1745422772364691\n",
      "epoch : 2, t_cost : 0.005144, e_cost : 0.003967, elapsed time : 7.32sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.5350565359694883\n",
      "evalution_cost :  0.18931739346589893\n",
      "epoch : 3, t_cost : 0.005145, e_cost : 0.004303, elapsed time : 7.32sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.5536896012490615\n",
      "evalution_cost :  0.17329160403460264\n",
      "epoch : 4, t_cost : 0.005324, e_cost : 0.003938, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.5001859897747636\n",
      "evalution_cost :  0.15359658282250166\n",
      "epoch : 5, t_cost : 0.004809, e_cost : 0.003491, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.45233173901215196\n",
      "evalution_cost :  0.14027579163666815\n",
      "epoch : 6, t_cost : 0.004349, e_cost : 0.003188, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.4299265369772911\n",
      "evalution_cost :  0.1791106965392828\n",
      "epoch : 7, t_cost : 0.004134, e_cost : 0.004071, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.4800646073417738\n",
      "evalution_cost :  0.1849932698532939\n",
      "epoch : 8, t_cost : 0.004616, e_cost : 0.004204, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.4350279571954161\n",
      "evalution_cost :  0.16243061539717019\n",
      "epoch : 9, t_cost : 0.004183, e_cost : 0.003692, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3864974956959486\n",
      "evalution_cost :  0.1573129897005856\n",
      "epoch : 10, t_cost : 0.003716, e_cost : 0.003575, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.39074429974425584\n",
      "evalution_cost :  0.15909071284113452\n",
      "epoch : 11, t_cost : 0.003757, e_cost : 0.003616, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.36937474145088345\n",
      "evalution_cost :  0.14283631090074778\n",
      "epoch : 12, t_cost : 0.003552, e_cost : 0.003246, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3509845233638771\n",
      "evalution_cost :  0.1255826153792441\n",
      "epoch : 13, t_cost : 0.003375, e_cost : 0.002854, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3337516119936481\n",
      "evalution_cost :  0.1258777179173194\n",
      "epoch : 14, t_cost : 0.003209, e_cost : 0.002861, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.33340366545598954\n",
      "evalution_cost :  0.10439202084671706\n",
      "epoch : 15, t_cost : 0.003206, e_cost : 0.002373, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.31281061825575307\n",
      "evalution_cost :  0.09695391292916611\n",
      "epoch : 16, t_cost : 0.003008, e_cost : 0.002203, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.30370877333916724\n",
      "evalution_cost :  0.09182775270892307\n",
      "epoch : 17, t_cost : 0.002920, e_cost : 0.002087, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2915881389635615\n",
      "evalution_cost :  0.08696647151373327\n",
      "epoch : 18, t_cost : 0.002804, e_cost : 0.001977, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.28197835735045373\n",
      "evalution_cost :  0.0888836164958775\n",
      "epoch : 19, t_cost : 0.002711, e_cost : 0.002020, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.27401846926659346\n",
      "evalution_cost :  0.08721411600708961\n",
      "epoch : 20, t_cost : 0.002635, e_cost : 0.001982, elapsed time : 7.36sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.26865123939933255\n",
      "evalution_cost :  0.08555950527079403\n",
      "epoch : 21, t_cost : 0.002583, e_cost : 0.001945, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.26407017483143136\n",
      "evalution_cost :  0.08598523470573127\n",
      "epoch : 22, t_cost : 0.002539, e_cost : 0.001954, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.26129846496041864\n",
      "evalution_cost :  0.08525884640403092\n",
      "epoch : 23, t_cost : 0.002512, e_cost : 0.001938, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2560210608644411\n",
      "evalution_cost :  0.08434850661433302\n",
      "epoch : 24, t_cost : 0.002462, e_cost : 0.001917, elapsed time : 7.36sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2496031495393254\n",
      "evalution_cost :  0.08342180767795071\n",
      "epoch : 25, t_cost : 0.002400, e_cost : 0.001896, elapsed time : 7.43sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.24144600477302447\n",
      "evalution_cost :  0.07921045483089983\n",
      "epoch : 26, t_cost : 0.002322, e_cost : 0.001800, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.22458007687237114\n",
      "evalution_cost :  0.07793391833547503\n",
      "epoch : 27, t_cost : 0.002159, e_cost : 0.001771, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.22245411766925827\n",
      "evalution_cost :  0.0751433465629816\n",
      "epoch : 28, t_cost : 0.002139, e_cost : 0.001708, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.21734233223833144\n",
      "evalution_cost :  0.07285423501161858\n",
      "epoch : 29, t_cost : 0.002090, e_cost : 0.001656, elapsed time : 7.38sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.21231948462082073\n",
      "evalution_cost :  0.07082566391909495\n",
      "epoch : 30, t_cost : 0.002042, e_cost : 0.001610, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.20694329467369244\n",
      "evalution_cost :  0.0682823670504149\n",
      "epoch : 31, t_cost : 0.001990, e_cost : 0.001552, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.20149880653480068\n",
      "evalution_cost :  0.06664791659568436\n",
      "epoch : 32, t_cost : 0.001937, e_cost : 0.001515, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.19829949084669352\n",
      "evalution_cost :  0.06593887266353704\n",
      "epoch : 33, t_cost : 0.001907, e_cost : 0.001499, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.19741999509278685\n",
      "evalution_cost :  0.06605013652006164\n",
      "epoch : 34, t_cost : 0.001898, e_cost : 0.001501, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.19731171312741935\n",
      "evalution_cost :  0.06635100863059051\n",
      "epoch : 35, t_cost : 0.001897, e_cost : 0.001508, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.19831579230958596\n",
      "evalution_cost :  0.06962709233630449\n",
      "epoch : 36, t_cost : 0.001907, e_cost : 0.001582, elapsed time : 7.36sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2035502852522768\n",
      "evalution_cost :  0.07004252381739207\n",
      "epoch : 37, t_cost : 0.001957, e_cost : 0.001592, elapsed time : 7.39sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.20636538841063157\n",
      "evalution_cost :  0.06887121582985856\n",
      "epoch : 38, t_cost : 0.001984, e_cost : 0.001565, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.20568518416257575\n",
      "evalution_cost :  0.0676615199772641\n",
      "epoch : 39, t_cost : 0.001978, e_cost : 0.001538, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.20415634365053847\n",
      "evalution_cost :  0.06676864722976461\n",
      "epoch : 40, t_cost : 0.001963, e_cost : 0.001517, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.20293459488311782\n",
      "evalution_cost :  0.06692947848932818\n",
      "epoch : 41, t_cost : 0.001951, e_cost : 0.001521, elapsed time : 7.36sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.20425127184716985\n",
      "evalution_cost :  0.06734297642833553\n",
      "epoch : 42, t_cost : 0.001964, e_cost : 0.001531, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traning_cost :  0.20747731201117858\n",
      "evalution_cost :  0.06766320980386809\n",
      "epoch : 43, t_cost : 0.001995, e_cost : 0.001538, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.21165378001751378\n",
      "evalution_cost :  0.06808021507458761\n",
      "epoch : 44, t_cost : 0.002035, e_cost : 0.001547, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2193387860315852\n",
      "evalution_cost :  0.06952744704904035\n",
      "epoch : 45, t_cost : 0.002109, e_cost : 0.001580, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.23439424368552864\n",
      "evalution_cost :  0.07020390871912241\n",
      "epoch : 46, t_cost : 0.002254, e_cost : 0.001596, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.260627098090481\n",
      "evalution_cost :  0.07002520753303543\n",
      "epoch : 47, t_cost : 0.002506, e_cost : 0.001591, elapsed time : 7.36sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.29903374199057\n",
      "evalution_cost :  0.07292831543600187\n",
      "epoch : 48, t_cost : 0.002875, e_cost : 0.001657, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.34918143262621015\n",
      "evalution_cost :  0.07913888897746801\n",
      "epoch : 49, t_cost : 0.003358, e_cost : 0.001799, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.35402596805943176\n",
      "evalution_cost :  0.15517620445461944\n",
      "epoch : 50, t_cost : 0.003404, e_cost : 0.003527, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.445127954648342\n",
      "evalution_cost :  0.15065028693061322\n",
      "epoch : 51, t_cost : 0.004280, e_cost : 0.003424, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.489292302634567\n",
      "evalution_cost :  0.1392147260485217\n",
      "epoch : 52, t_cost : 0.004705, e_cost : 0.003164, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.4871378183597699\n",
      "evalution_cost :  0.1097572385915555\n",
      "epoch : 53, t_cost : 0.004684, e_cost : 0.002494, elapsed time : 7.36sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.44287671841448173\n",
      "evalution_cost :  0.11203965253662318\n",
      "epoch : 54, t_cost : 0.004258, e_cost : 0.002546, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.44948437419952825\n",
      "evalution_cost :  0.09959954308578745\n",
      "epoch : 55, t_cost : 0.004322, e_cost : 0.002264, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.576128801505547\n",
      "evalution_cost :  0.0936966494191438\n",
      "epoch : 56, t_cost : 0.005540, e_cost : 0.002129, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.5501192271476611\n",
      "evalution_cost :  0.10465388634474948\n",
      "epoch : 57, t_cost : 0.005290, e_cost : 0.002378, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.5567078211461194\n",
      "evalution_cost :  0.1282084594713524\n",
      "epoch : 58, t_cost : 0.005353, e_cost : 0.002914, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.5762025110889226\n",
      "evalution_cost :  0.1147656311513856\n",
      "epoch : 59, t_cost : 0.005540, e_cost : 0.002608, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.6675203142222017\n",
      "evalution_cost :  0.07549413427477702\n",
      "epoch : 60, t_cost : 0.006418, e_cost : 0.001716, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.5613559658522718\n",
      "evalution_cost :  0.05949359672376886\n",
      "epoch : 61, t_cost : 0.005398, e_cost : 0.001352, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.40422126156045124\n",
      "evalution_cost :  0.054832811147207394\n",
      "epoch : 62, t_cost : 0.003887, e_cost : 0.001246, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.3143865526653826\n",
      "evalution_cost :  0.051475328335072845\n",
      "epoch : 63, t_cost : 0.003023, e_cost : 0.001170, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.26906483428319916\n",
      "evalution_cost :  0.05019307628390379\n",
      "epoch : 64, t_cost : 0.002587, e_cost : 0.001141, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.24558419635286555\n",
      "evalution_cost :  0.0494518366176635\n",
      "epoch : 65, t_cost : 0.002361, e_cost : 0.001124, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2309766112593934\n",
      "evalution_cost :  0.04924671119078994\n",
      "epoch : 66, t_cost : 0.002221, e_cost : 0.001119, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.22271483711665496\n",
      "evalution_cost :  0.049316022952552885\n",
      "epoch : 67, t_cost : 0.002141, e_cost : 0.001121, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.21903182624373585\n",
      "evalution_cost :  0.04952026280807331\n",
      "epoch : 68, t_cost : 0.002106, e_cost : 0.001125, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.21750922169303522\n",
      "evalution_cost :  0.049981775344349444\n",
      "epoch : 69, t_cost : 0.002091, e_cost : 0.001136, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.21831519162515178\n",
      "evalution_cost :  0.050655779778026044\n",
      "epoch : 70, t_cost : 0.002099, e_cost : 0.001151, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.21981365123065189\n",
      "evalution_cost :  0.05123206117423251\n",
      "epoch : 71, t_cost : 0.002114, e_cost : 0.001164, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2235554859507829\n",
      "evalution_cost :  0.052158753911498934\n",
      "epoch : 72, t_cost : 0.002150, e_cost : 0.001185, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.22808958287350833\n",
      "evalution_cost :  0.05248500275774859\n",
      "epoch : 73, t_cost : 0.002193, e_cost : 0.001193, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.23274910636246204\n",
      "evalution_cost :  0.053216994943795726\n",
      "epoch : 74, t_cost : 0.002238, e_cost : 0.001209, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2371040997095406\n",
      "evalution_cost :  0.05361858432297595\n",
      "epoch : 75, t_cost : 0.002280, e_cost : 0.001219, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2386917978292331\n",
      "evalution_cost :  0.05433610378531739\n",
      "epoch : 76, t_cost : 0.002295, e_cost : 0.001235, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.23935599625110626\n",
      "evalution_cost :  0.0537695748207625\n",
      "epoch : 77, t_cost : 0.002301, e_cost : 0.001222, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2363531377632171\n",
      "evalution_cost :  0.05344723057351075\n",
      "epoch : 78, t_cost : 0.002273, e_cost : 0.001215, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.23281988996313885\n",
      "evalution_cost :  0.053109210275579244\n",
      "epoch : 79, t_cost : 0.002239, e_cost : 0.001207, elapsed time : 7.36sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.22317365242633969\n",
      "evalution_cost :  0.053499693429330364\n",
      "epoch : 80, t_cost : 0.002146, e_cost : 0.001216, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2266103260917589\n",
      "evalution_cost :  0.05276641444652341\n",
      "epoch : 81, t_cost : 0.002179, e_cost : 0.001199, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.21884194936137646\n",
      "evalution_cost :  0.05295558072975837\n",
      "epoch : 82, t_cost : 0.002104, e_cost : 0.001204, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.21982819674303755\n",
      "evalution_cost :  0.052273579785833135\n",
      "epoch : 83, t_cost : 0.002114, e_cost : 0.001188, elapsed time : 7.36sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2108243335969746\n",
      "evalution_cost :  0.05240613597561605\n",
      "epoch : 84, t_cost : 0.002027, e_cost : 0.001191, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2114321849658154\n",
      "evalution_cost :  0.05197425649384968\n",
      "epoch : 85, t_cost : 0.002033, e_cost : 0.001181, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.20473246573237702\n",
      "evalution_cost :  0.052843510755337775\n",
      "epoch : 86, t_cost : 0.001969, e_cost : 0.001201, elapsed time : 7.36sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.20731055876240134\n",
      "evalution_cost :  0.05228572624037042\n",
      "epoch : 87, t_cost : 0.001993, e_cost : 0.001188, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.19846838427474722\n",
      "evalution_cost :  0.05673153093084693\n",
      "epoch : 88, t_cost : 0.001908, e_cost : 0.001289, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.20224068185780197\n",
      "evalution_cost :  0.05519113544141874\n",
      "epoch : 89, t_cost : 0.001945, e_cost : 0.001254, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.20181683410191908\n",
      "evalution_cost :  0.05757715000072494\n",
      "epoch : 90, t_cost : 0.001941, e_cost : 0.001309, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.22456458391388878\n",
      "evalution_cost :  0.054722907312680036\n",
      "epoch : 91, t_cost : 0.002159, e_cost : 0.001244, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.20598472614074126\n",
      "evalution_cost :  0.05722875572973862\n",
      "epoch : 92, t_cost : 0.001981, e_cost : 0.001301, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.2236470088828355\n",
      "evalution_cost :  0.05454639994422905\n",
      "epoch : 93, t_cost : 0.002150, e_cost : 0.001240, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.20373558113351464\n",
      "evalution_cost :  0.056858448893763125\n",
      "epoch : 94, t_cost : 0.001959, e_cost : 0.001292, elapsed time : 7.35sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.22022947785444558\n",
      "evalution_cost :  0.05433396474109031\n",
      "epoch : 95, t_cost : 0.002118, e_cost : 0.001235, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traning_cost :  0.19977687776554376\n",
      "evalution_cost :  0.05531679274281487\n",
      "epoch : 96, t_cost : 0.001921, e_cost : 0.001257, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.21153832011623308\n",
      "evalution_cost :  0.05470294185215607\n",
      "epoch : 97, t_cost : 0.002034, e_cost : 0.001243, elapsed time : 7.33sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.19434519647620618\n",
      "evalution_cost :  0.05514282686635852\n",
      "epoch : 98, t_cost : 0.001869, e_cost : 0.001253, elapsed time : 7.34sec\n",
      "data1 :  (53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "data1 :  (23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "traning_cost :  0.19813650043215603\n",
      "evalution_cost :  0.05419807811267674\n",
      "epoch : 99, t_cost : 0.001905, e_cost : 0.001232, elapsed time : 7.33sec\n",
      "\n",
      "#Best result at epoch 66\n",
      "t_cost : 0.002221, e_cost : 0.001119\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "#parameter list\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=8\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "#\n",
    "kospi=StockData(\n",
    "    'StockChart/SAMPLE',\n",
    "    'StockChart/KOSPI.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "\n",
    "print('\\n#training#')\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "result_dic={}\n",
    "\n",
    "for i in range(100):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "\n",
    "    #training batch\n",
    "    for batch in kospi.getBatch('training'):\n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(\"traning_cost : \" , training_cost)\n",
    "    print(\"evalution_cost : \" , evalution_cost)\n",
    "   \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "        i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexPrice shape:  (40559, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by MinMaxScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-86444781dc74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mnegative_correlation_sotck_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtrain_test_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     batch_size) \n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n#training#'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-b9b47abeab84>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, folderPath, indexPath, timewindowsize, windowsizeForPCC, PostiveStockNumber, NegativeStockNumber, train_test_rate, batchSize)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexPrice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstockPrice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainSet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestSet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-b9b47abeab84>\u001b[0m in \u001b[0;36mloadCSV\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mdataframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mdataT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mdataT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mdataT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    371\u001b[0m         X = check_array(X,\n\u001b[1;32m    372\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                         force_all_finite=\"allow-nan\")\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    584\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[0;32m--> 586\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by MinMaxScaler."
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "#parameter list\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=16\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=256\n",
    "#\n",
    "kospi=StockData(\n",
    "    'NASDAQ/Sample',\n",
    "    'NASDAQ/NDX.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size) \n",
    "\n",
    "print('\\n#training#')\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "result_dic={}\n",
    "\n",
    "for i in range(100):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "\n",
    "    #training batch\n",
    "    for batch in kospi.getBatch('training'):\n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(training_cost)\n",
    "    print(evalution_cost)\n",
    "   \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "        i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eopch : 100 , batchsize : 512 , timesize : 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexPrice shape:  (40559, 1)\n",
      "StockPrice shape:  (40559, 81)\n",
      "making dataset progress : finished\t59\n",
      "\n",
      "#training#\n",
      "WARNING:tensorflow:From <ipython-input-4-17a179c18b7c>:36: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-4-17a179c18b7c>:38: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/nextgen/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/nextgen/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-3-924828131441>:55: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-3-924828131441>:76: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/nextgen/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-17a179c18b7c>:65: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/nextgen/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  10.364907867187867\n",
      "evalution_cost :  650.7658365446114\n",
      "epoch : 0, t_cost : 0.002311, e_cost : 0.338588, elapsed time : 944.85sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  5.122064398125076\n",
      "evalution_cost :  344.79081083762867\n",
      "epoch : 1, t_cost : 0.001142, e_cost : 0.179392, elapsed time : 938.40sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  2.628714814542036\n",
      "evalution_cost :  249.27088571271088\n",
      "epoch : 2, t_cost : 0.000586, e_cost : 0.129693, elapsed time : 938.56sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  1.496305014798054\n",
      "evalution_cost :  123.67162536327669\n",
      "epoch : 3, t_cost : 0.000334, e_cost : 0.064345, elapsed time : 938.77sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.9236180579437132\n",
      "evalution_cost :  73.22368625037052\n",
      "epoch : 4, t_cost : 0.000206, e_cost : 0.038098, elapsed time : 938.55sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.7731823670601443\n",
      "evalution_cost :  61.41103159393242\n",
      "epoch : 5, t_cost : 0.000172, e_cost : 0.031952, elapsed time : 938.77sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.7100288288047523\n",
      "evalution_cost :  57.34391652474005\n",
      "epoch : 6, t_cost : 0.000158, e_cost : 0.029836, elapsed time : 938.91sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.6811145278015829\n",
      "evalution_cost :  53.883054866346356\n",
      "epoch : 7, t_cost : 0.000152, e_cost : 0.028035, elapsed time : 938.82sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.6586791525151057\n",
      "evalution_cost :  52.654577651570435\n",
      "epoch : 8, t_cost : 0.000147, e_cost : 0.027396, elapsed time : 938.66sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.6440829479142849\n",
      "evalution_cost :  54.83438758707416\n",
      "epoch : 9, t_cost : 0.000144, e_cost : 0.028530, elapsed time : 938.31sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.6278587497017725\n",
      "evalution_cost :  53.74932829877798\n",
      "epoch : 10, t_cost : 0.000140, e_cost : 0.027965, elapsed time : 938.43sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.6118367032258902\n",
      "evalution_cost :  52.653872037924884\n",
      "epoch : 11, t_cost : 0.000136, e_cost : 0.027395, elapsed time : 939.06sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.5917690665883129\n",
      "evalution_cost :  50.23099558238391\n",
      "epoch : 12, t_cost : 0.000132, e_cost : 0.026135, elapsed time : 938.53sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.5800520003786005\n",
      "evalution_cost :  48.74593192493194\n",
      "epoch : 13, t_cost : 0.000129, e_cost : 0.025362, elapsed time : 938.59sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.5667890928625638\n",
      "evalution_cost :  48.15584333838706\n",
      "epoch : 14, t_cost : 0.000126, e_cost : 0.025055, elapsed time : 938.65sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.55225581691775\n",
      "evalution_cost :  45.16293082045922\n",
      "epoch : 15, t_cost : 0.000123, e_cost : 0.023498, elapsed time : 938.78sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.5411523033990306\n",
      "evalution_cost :  45.5814146118737\n",
      "epoch : 16, t_cost : 0.000121, e_cost : 0.023716, elapsed time : 938.24sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.5366175952221965\n",
      "evalution_cost :  43.75581144885291\n",
      "epoch : 17, t_cost : 0.000120, e_cost : 0.022766, elapsed time : 938.26sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.5244766067489763\n",
      "evalution_cost :  42.13528471648533\n",
      "epoch : 18, t_cost : 0.000117, e_cost : 0.021923, elapsed time : 939.02sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.517323478520666\n",
      "evalution_cost :  41.42371187878234\n",
      "epoch : 19, t_cost : 0.000115, e_cost : 0.021552, elapsed time : 938.44sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.5133706357783012\n",
      "evalution_cost :  41.60906331684782\n",
      "epoch : 20, t_cost : 0.000114, e_cost : 0.021649, elapsed time : 939.53sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.5068098359834039\n",
      "evalution_cost :  39.817179362238676\n",
      "epoch : 21, t_cost : 0.000113, e_cost : 0.020717, elapsed time : 939.62sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.497783984961643\n",
      "evalution_cost :  39.80205763828235\n",
      "epoch : 22, t_cost : 0.000111, e_cost : 0.020709, elapsed time : 939.85sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.4920931211918287\n",
      "evalution_cost :  37.624701127677326\n",
      "epoch : 23, t_cost : 0.000110, e_cost : 0.019576, elapsed time : 939.58sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.4812077878505079\n",
      "evalution_cost :  38.530002651943505\n",
      "epoch : 24, t_cost : 0.000107, e_cost : 0.020047, elapsed time : 939.81sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.47927391144366993\n",
      "evalution_cost :  37.16265000209023\n",
      "epoch : 25, t_cost : 0.000107, e_cost : 0.019335, elapsed time : 939.83sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.47395367451281345\n",
      "evalution_cost :  36.06809457777672\n",
      "epoch : 26, t_cost : 0.000106, e_cost : 0.018766, elapsed time : 939.65sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.4661560268550602\n",
      "evalution_cost :  35.712800491823145\n",
      "epoch : 27, t_cost : 0.000104, e_cost : 0.018581, elapsed time : 939.82sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.46499458816651895\n",
      "evalution_cost :  35.6159453262444\n",
      "epoch : 28, t_cost : 0.000104, e_cost : 0.018531, elapsed time : 940.03sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.4588407740002367\n",
      "evalution_cost :  35.359860253367515\n",
      "epoch : 29, t_cost : 0.000102, e_cost : 0.018397, elapsed time : 939.40sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.4542814841170184\n",
      "evalution_cost :  33.41742242130749\n",
      "epoch : 30, t_cost : 0.000101, e_cost : 0.017387, elapsed time : 939.57sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.44811739401211526\n",
      "evalution_cost :  32.87530088016865\n",
      "epoch : 31, t_cost : 0.000100, e_cost : 0.017105, elapsed time : 939.70sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.4418293493135934\n",
      "evalution_cost :  31.802255163593145\n",
      "epoch : 32, t_cost : 0.000098, e_cost : 0.016546, elapsed time : 939.77sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.43449011203756527\n",
      "evalution_cost :  32.81986132532256\n",
      "epoch : 33, t_cost : 0.000097, e_cost : 0.017076, elapsed time : 939.63sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.4331154265673831\n",
      "evalution_cost :  31.70855040531751\n",
      "epoch : 34, t_cost : 0.000097, e_cost : 0.016498, elapsed time : 939.31sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.4284167484693171\n",
      "evalution_cost :  30.848775829223086\n",
      "epoch : 35, t_cost : 0.000096, e_cost : 0.016050, elapsed time : 943.19sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.42289546028041514\n",
      "evalution_cost :  30.877106191328494\n",
      "epoch : 36, t_cost : 0.000094, e_cost : 0.016065, elapsed time : 948.50sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.4187953069649666\n",
      "evalution_cost :  32.35376113736493\n",
      "epoch : 37, t_cost : 0.000093, e_cost : 0.016833, elapsed time : 944.14sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.420345508414357\n",
      "evalution_cost :  31.831227137998212\n",
      "epoch : 38, t_cost : 0.000094, e_cost : 0.016562, elapsed time : 942.79sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.41378122684727714\n",
      "evalution_cost :  30.94253713615217\n",
      "epoch : 39, t_cost : 0.000092, e_cost : 0.016099, elapsed time : 948.40sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.41068347101918334\n",
      "evalution_cost :  31.64592835706935\n",
      "epoch : 40, t_cost : 0.000092, e_cost : 0.016465, elapsed time : 948.22sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.40562980028425955\n",
      "evalution_cost :  30.819143404525676\n",
      "epoch : 41, t_cost : 0.000090, e_cost : 0.016035, elapsed time : 944.07sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3992421262537391\n",
      "evalution_cost :  31.239323041647367\n",
      "epoch : 42, t_cost : 0.000089, e_cost : 0.016254, elapsed time : 948.28sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.39750015563549823\n",
      "evalution_cost :  32.83285181240353\n",
      "epoch : 43, t_cost : 0.000089, e_cost : 0.017083, elapsed time : 947.83sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3975694294522327\n",
      "evalution_cost :  30.37326605373164\n",
      "epoch : 44, t_cost : 0.000089, e_cost : 0.015803, elapsed time : 951.46sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.39679599271948973\n",
      "evalution_cost :  31.38275878755121\n",
      "epoch : 45, t_cost : 0.000088, e_cost : 0.016328, elapsed time : 950.46sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.38309557960383245\n",
      "evalution_cost :  31.317740575163043\n",
      "epoch : 46, t_cost : 0.000085, e_cost : 0.016294, elapsed time : 950.22sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.39573541863501305\n",
      "evalution_cost :  31.642413441431927\n",
      "epoch : 47, t_cost : 0.000088, e_cost : 0.016463, elapsed time : 947.05sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.39241084381137625\n",
      "evalution_cost :  32.22633018543456\n",
      "epoch : 48, t_cost : 0.000087, e_cost : 0.016767, elapsed time : 955.87sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.39188855637166853\n",
      "evalution_cost :  32.16737917623141\n",
      "epoch : 49, t_cost : 0.000087, e_cost : 0.016736, elapsed time : 943.83sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3913387475813579\n",
      "evalution_cost :  31.36364273666186\n",
      "epoch : 50, t_cost : 0.000087, e_cost : 0.016318, elapsed time : 958.58sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3867820969016975\n",
      "evalution_cost :  31.598240607445405\n",
      "epoch : 51, t_cost : 0.000086, e_cost : 0.016440, elapsed time : 949.11sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.38534008955730314\n",
      "evalution_cost :  30.75682603579844\n",
      "epoch : 52, t_cost : 0.000086, e_cost : 0.016003, elapsed time : 989.88sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.38495178475750436\n",
      "evalution_cost :  30.75228257809431\n",
      "epoch : 53, t_cost : 0.000086, e_cost : 0.016000, elapsed time : 976.49sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.38032432086083645\n",
      "evalution_cost :  30.51632992130908\n",
      "epoch : 54, t_cost : 0.000085, e_cost : 0.015877, elapsed time : 962.84sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3809812737217726\n",
      "evalution_cost :  29.719019381725957\n",
      "epoch : 55, t_cost : 0.000085, e_cost : 0.015463, elapsed time : 960.31sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.38109325213645207\n",
      "evalution_cost :  29.463197260609377\n",
      "epoch : 56, t_cost : 0.000085, e_cost : 0.015329, elapsed time : 947.10sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.37655015873087905\n",
      "evalution_cost :  28.605614592665006\n",
      "epoch : 57, t_cost : 0.000084, e_cost : 0.014883, elapsed time : 946.92sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.374303488449641\n",
      "evalution_cost :  29.60684298754677\n",
      "epoch : 58, t_cost : 0.000083, e_cost : 0.015404, elapsed time : 946.65sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.37360146142054873\n",
      "evalution_cost :  29.498453578631597\n",
      "epoch : 59, t_cost : 0.000083, e_cost : 0.015348, elapsed time : 946.92sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.37322928703724756\n",
      "evalution_cost :  27.91616385760426\n",
      "epoch : 60, t_cost : 0.000083, e_cost : 0.014525, elapsed time : 945.49sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3718648917847531\n",
      "evalution_cost :  28.66848832443793\n",
      "epoch : 61, t_cost : 0.000083, e_cost : 0.014916, elapsed time : 945.53sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3701517264235008\n",
      "evalution_cost :  28.731823950409307\n",
      "epoch : 62, t_cost : 0.000083, e_cost : 0.014949, elapsed time : 947.79sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.37102196779642327\n",
      "evalution_cost :  28.31685589817789\n",
      "epoch : 63, t_cost : 0.000083, e_cost : 0.014733, elapsed time : 942.21sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.36717625870551274\n",
      "evalution_cost :  28.148753260957164\n",
      "epoch : 64, t_cost : 0.000082, e_cost : 0.014646, elapsed time : 941.79sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3680208458481502\n",
      "evalution_cost :  28.650527871843224\n",
      "epoch : 65, t_cost : 0.000082, e_cost : 0.014907, elapsed time : 941.72sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.36694298398106184\n",
      "evalution_cost :  27.504465872434594\n",
      "epoch : 66, t_cost : 0.000082, e_cost : 0.014310, elapsed time : 942.06sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3662334145656132\n",
      "evalution_cost :  28.608262596757413\n",
      "epoch : 67, t_cost : 0.000082, e_cost : 0.014885, elapsed time : 943.41sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.36709920578232413\n",
      "evalution_cost :  28.108884131379455\n",
      "epoch : 68, t_cost : 0.000082, e_cost : 0.014625, elapsed time : 942.25sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3667618615218089\n",
      "evalution_cost :  28.789081776103558\n",
      "epoch : 69, t_cost : 0.000082, e_cost : 0.014979, elapsed time : 942.11sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.36378925351300495\n",
      "evalution_cost :  27.70261652177942\n",
      "epoch : 70, t_cost : 0.000081, e_cost : 0.014413, elapsed time : 942.12sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3632495965293856\n",
      "evalution_cost :  27.701200659757887\n",
      "epoch : 71, t_cost : 0.000081, e_cost : 0.014413, elapsed time : 941.49sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3628474063743852\n",
      "evalution_cost :  27.28185213587858\n",
      "epoch : 72, t_cost : 0.000081, e_cost : 0.014195, elapsed time : 941.72sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3607674741097071\n",
      "evalution_cost :  26.307225551312513\n",
      "epoch : 73, t_cost : 0.000080, e_cost : 0.013687, elapsed time : 941.54sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.35947096906511433\n",
      "evalution_cost :  27.699171620311972\n",
      "epoch : 74, t_cost : 0.000080, e_cost : 0.014412, elapsed time : 941.98sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.35738689862682804\n",
      "evalution_cost :  27.02735112829214\n",
      "epoch : 75, t_cost : 0.000080, e_cost : 0.014062, elapsed time : 945.44sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3547203673288095\n",
      "evalution_cost :  26.49791772998833\n",
      "epoch : 76, t_cost : 0.000079, e_cost : 0.013787, elapsed time : 941.87sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.35408884458820467\n",
      "evalution_cost :  28.07993384409565\n",
      "epoch : 77, t_cost : 0.000079, e_cost : 0.014610, elapsed time : 941.56sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.35588495409319876\n",
      "evalution_cost :  26.374067944441776\n",
      "epoch : 78, t_cost : 0.000079, e_cost : 0.013722, elapsed time : 956.21sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.35342313760747857\n",
      "evalution_cost :  26.661800989473704\n",
      "epoch : 79, t_cost : 0.000079, e_cost : 0.013872, elapsed time : 942.56sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3552606577509323\n",
      "evalution_cost :  25.652589459408773\n",
      "epoch : 80, t_cost : 0.000079, e_cost : 0.013347, elapsed time : 942.41sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.35651094348577317\n",
      "evalution_cost :  26.578873443013435\n",
      "epoch : 81, t_cost : 0.000079, e_cost : 0.013829, elapsed time : 946.60sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3529688601061025\n",
      "evalution_cost :  26.276222563103147\n",
      "epoch : 82, t_cost : 0.000079, e_cost : 0.013671, elapsed time : 956.80sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3533492414876491\n",
      "evalution_cost :  26.02139592272215\n",
      "epoch : 83, t_cost : 0.000079, e_cost : 0.013539, elapsed time : 949.90sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3522563904080016\n",
      "evalution_cost :  26.82900097032325\n",
      "epoch : 84, t_cost : 0.000079, e_cost : 0.013959, elapsed time : 949.32sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3538869059307217\n",
      "evalution_cost :  26.418902685267312\n",
      "epoch : 85, t_cost : 0.000079, e_cost : 0.013746, elapsed time : 949.31sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3507034103981823\n",
      "evalution_cost :  25.38622197242148\n",
      "epoch : 86, t_cost : 0.000078, e_cost : 0.013208, elapsed time : 943.04sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.34745841085896245\n",
      "evalution_cost :  26.021792082818138\n",
      "epoch : 87, t_cost : 0.000077, e_cost : 0.013539, elapsed time : 942.98sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.34830974125179637\n",
      "evalution_cost :  26.220773990606176\n",
      "epoch : 88, t_cost : 0.000078, e_cost : 0.013642, elapsed time : 942.82sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traning_cost :  0.34848637016557404\n",
      "evalution_cost :  25.245317456876364\n",
      "epoch : 89, t_cost : 0.000078, e_cost : 0.013135, elapsed time : 942.11sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3510448431034092\n",
      "evalution_cost :  24.55422373903457\n",
      "epoch : 90, t_cost : 0.000078, e_cost : 0.012775, elapsed time : 948.60sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.34728315611482685\n",
      "evalution_cost :  24.900901185228577\n",
      "epoch : 91, t_cost : 0.000077, e_cost : 0.012956, elapsed time : 949.47sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.34814485790866456\n",
      "evalution_cost :  23.889944171249226\n",
      "epoch : 92, t_cost : 0.000078, e_cost : 0.012430, elapsed time : 949.44sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.34657191620635786\n",
      "evalution_cost :  23.91691326516593\n",
      "epoch : 93, t_cost : 0.000077, e_cost : 0.012444, elapsed time : 949.39sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3448238191767814\n",
      "evalution_cost :  24.203361795816818\n",
      "epoch : 94, t_cost : 0.000077, e_cost : 0.012593, elapsed time : 951.85sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.34214376562886173\n",
      "evalution_cost :  23.415810909991706\n",
      "epoch : 95, t_cost : 0.000076, e_cost : 0.012183, elapsed time : 949.15sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3409508321233261\n",
      "evalution_cost :  23.540628617605762\n",
      "epoch : 96, t_cost : 0.000076, e_cost : 0.012248, elapsed time : 949.60sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.34546449875006147\n",
      "evalution_cost :  22.758525547204044\n",
      "epoch : 97, t_cost : 0.000077, e_cost : 0.011841, elapsed time : 949.52sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.3430767118120457\n",
      "evalution_cost :  23.97634269025366\n",
      "epoch : 98, t_cost : 0.000076, e_cost : 0.012475, elapsed time : 949.15sec\n",
      "data1 :  (2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "data1 :  (984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "traning_cost :  0.34137922637091833\n",
      "evalution_cost :  23.166835450190774\n",
      "epoch : 99, t_cost : 0.000076, e_cost : 0.012054, elapsed time : 949.16sec\n",
      "\n",
      "#Best result at epoch 97\n",
      "t_cost : 0.000077, e_cost : 0.011841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f56e0beac88>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "#parameter list\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=16\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "#\n",
    "kospi=StockData(\n",
    "    'DARNNdata/NASDAQ',\n",
    "    'DARNNdata/NDX.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "\n",
    "print('\\n#training#')\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "result_dic={}\n",
    "evalution_costplt2=[]\n",
    "for i in range(100):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "\n",
    "    #training batch\n",
    "    for batch in kospi.getBatch('training'):\n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(\"traning_cost : \" , training_cost)\n",
    "    print(\"evalution_cost : \" , evalution_cost)\n",
    "   \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    evalution_costplt2.append(evalution_cost)\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "        i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))\n",
    "plt.plot(evalution_costplt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## epoch : 100 , batchsize : 512 , timesize : 16\n",
    "## timesize_for_calc_correlation=100\n",
    "## positive_correlation_stock_num=10\n",
    "## negative_correlation_sotck_num=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexPrice shape:  (3000, 1)\n",
      "StockPrice shape:  (3000, 26)\n",
      "making dataset progress : finished\t\n",
      "\n",
      "#training#\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  5.93792120879516\n",
      "evalution_cost :  0.34546382108237594\n",
      "epoch : 0, t_cost : 0.057095, e_cost : 0.007851, elapsed time : 26.29sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  1.122515910770744\n",
      "evalution_cost :  0.29940168443135917\n",
      "epoch : 1, t_cost : 0.010793, e_cost : 0.006805, elapsed time : 21.74sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.90451978915371\n",
      "evalution_cost :  0.30890198750421405\n",
      "epoch : 2, t_cost : 0.008697, e_cost : 0.007020, elapsed time : 21.77sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.7812199818436056\n",
      "evalution_cost :  0.2455589845776558\n",
      "epoch : 3, t_cost : 0.007512, e_cost : 0.005581, elapsed time : 21.71sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.5896192046348006\n",
      "evalution_cost :  0.22819572722073644\n",
      "epoch : 4, t_cost : 0.005669, e_cost : 0.005186, elapsed time : 21.81sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.5783779772464186\n",
      "evalution_cost :  0.20405261032283306\n",
      "epoch : 5, t_cost : 0.005561, e_cost : 0.004638, elapsed time : 21.73sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.5723076515132561\n",
      "evalution_cost :  0.21267183253075927\n",
      "epoch : 6, t_cost : 0.005503, e_cost : 0.004833, elapsed time : 21.86sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.5481621754588559\n",
      "evalution_cost :  0.1620661640772596\n",
      "epoch : 7, t_cost : 0.005271, e_cost : 0.003683, elapsed time : 21.80sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.46794962498825043\n",
      "evalution_cost :  0.16045463713817298\n",
      "epoch : 8, t_cost : 0.004500, e_cost : 0.003647, elapsed time : 21.77sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.45224436407443136\n",
      "evalution_cost :  0.15175269939936697\n",
      "epoch : 9, t_cost : 0.004349, e_cost : 0.003449, elapsed time : 21.89sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.45529614319093525\n",
      "evalution_cost :  0.1783241401426494\n",
      "epoch : 10, t_cost : 0.004378, e_cost : 0.004053, elapsed time : 21.85sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.4560172550845891\n",
      "evalution_cost :  0.13318613031879067\n",
      "epoch : 11, t_cost : 0.004385, e_cost : 0.003027, elapsed time : 21.86sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.37569468282163143\n",
      "evalution_cost :  0.12420194951118901\n",
      "epoch : 12, t_cost : 0.003612, e_cost : 0.002823, elapsed time : 21.77sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.3443214816506952\n",
      "evalution_cost :  0.15499201568309218\n",
      "epoch : 13, t_cost : 0.003311, e_cost : 0.003523, elapsed time : 21.86sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.3793759504915215\n",
      "evalution_cost :  0.1362728076055646\n",
      "epoch : 14, t_cost : 0.003648, e_cost : 0.003097, elapsed time : 21.81sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.36524219950661063\n",
      "evalution_cost :  0.12979985738638788\n",
      "epoch : 15, t_cost : 0.003512, e_cost : 0.002950, elapsed time : 21.82sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.3279415958095342\n",
      "evalution_cost :  0.12408224400132895\n",
      "epoch : 16, t_cost : 0.003153, e_cost : 0.002820, elapsed time : 21.79sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.289478276274167\n",
      "evalution_cost :  0.12095433275680989\n",
      "epoch : 17, t_cost : 0.002783, e_cost : 0.002749, elapsed time : 21.83sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.28068929724395275\n",
      "evalution_cost :  0.11608500184956938\n",
      "epoch : 18, t_cost : 0.002699, e_cost : 0.002638, elapsed time : 21.88sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.2784459425602108\n",
      "evalution_cost :  0.10019230179022998\n",
      "epoch : 19, t_cost : 0.002677, e_cost : 0.002277, elapsed time : 21.78sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.26350768335396424\n",
      "evalution_cost :  0.09575201070401818\n",
      "epoch : 20, t_cost : 0.002534, e_cost : 0.002176, elapsed time : 21.80sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.2474940355750732\n",
      "evalution_cost :  0.08708818338345736\n",
      "epoch : 21, t_cost : 0.002380, e_cost : 0.001979, elapsed time : 21.84sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.23222738719778135\n",
      "evalution_cost :  0.09839638334233314\n",
      "epoch : 22, t_cost : 0.002233, e_cost : 0.002236, elapsed time : 21.85sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.22987708798609674\n",
      "evalution_cost :  0.08952067443169653\n",
      "epoch : 23, t_cost : 0.002210, e_cost : 0.002035, elapsed time : 21.79sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.22415849671233445\n",
      "evalution_cost :  0.08795100741554052\n",
      "epoch : 24, t_cost : 0.002155, e_cost : 0.001999, elapsed time : 21.76sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.21598666987847537\n",
      "evalution_cost :  0.08136032742913812\n",
      "epoch : 25, t_cost : 0.002077, e_cost : 0.001849, elapsed time : 21.78sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.21193036035401747\n",
      "evalution_cost :  0.08174653112655506\n",
      "epoch : 26, t_cost : 0.002038, e_cost : 0.001858, elapsed time : 21.81sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.20607261161785573\n",
      "evalution_cost :  0.07386284647509456\n",
      "epoch : 27, t_cost : 0.001981, e_cost : 0.001679, elapsed time : 21.79sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.19302256224909797\n",
      "evalution_cost :  0.0757493813871406\n",
      "epoch : 28, t_cost : 0.001856, e_cost : 0.001722, elapsed time : 21.79sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.185522839310579\n",
      "evalution_cost :  0.07241729530505836\n",
      "epoch : 29, t_cost : 0.001784, e_cost : 0.001646, elapsed time : 21.78sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.18098932737484574\n",
      "evalution_cost :  0.06836254749214277\n",
      "epoch : 30, t_cost : 0.001740, e_cost : 0.001554, elapsed time : 21.77sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.17370300891343504\n",
      "evalution_cost :  0.06634183917776681\n",
      "epoch : 31, t_cost : 0.001670, e_cost : 0.001508, elapsed time : 21.82sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.1681754274177365\n",
      "evalution_cost :  0.06504036727710627\n",
      "epoch : 32, t_cost : 0.001617, e_cost : 0.001478, elapsed time : 21.99sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.1655026341904886\n",
      "evalution_cost :  0.06305979477474466\n",
      "epoch : 33, t_cost : 0.001591, e_cost : 0.001433, elapsed time : 21.86sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.16140830743825063\n",
      "evalution_cost :  0.06189755778177641\n",
      "epoch : 34, t_cost : 0.001552, e_cost : 0.001407, elapsed time : 21.77sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.1591791515238583\n",
      "evalution_cost :  0.06019482697593048\n",
      "epoch : 35, t_cost : 0.001531, e_cost : 0.001368, elapsed time : 21.82sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.15974457567790523\n",
      "evalution_cost :  0.06126224811305292\n",
      "epoch : 36, t_cost : 0.001536, e_cost : 0.001392, elapsed time : 21.79sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.1635635526617989\n",
      "evalution_cost :  0.05878579680575058\n",
      "epoch : 37, t_cost : 0.001573, e_cost : 0.001336, elapsed time : 21.79sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.16305374313378707\n",
      "evalution_cost :  0.056805424770573154\n",
      "epoch : 38, t_cost : 0.001568, e_cost : 0.001291, elapsed time : 21.78sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.16072830723715015\n",
      "evalution_cost :  0.054888426733668894\n",
      "epoch : 39, t_cost : 0.001545, e_cost : 0.001247, elapsed time : 21.83sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.15750745526747778\n",
      "evalution_cost :  0.05440533917862922\n",
      "epoch : 40, t_cost : 0.001514, e_cost : 0.001236, elapsed time : 21.83sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.15539760471438058\n",
      "evalution_cost :  0.05443924554856494\n",
      "epoch : 41, t_cost : 0.001494, e_cost : 0.001237, elapsed time : 21.84sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.154687620815821\n",
      "evalution_cost :  0.05354108187020756\n",
      "epoch : 42, t_cost : 0.001487, e_cost : 0.001217, elapsed time : 21.78sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.1546098974358756\n",
      "evalution_cost :  0.05231444304808974\n",
      "epoch : 43, t_cost : 0.001487, e_cost : 0.001189, elapsed time : 21.81sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.15317916206549853\n",
      "evalution_cost :  0.04974362120265141\n",
      "epoch : 44, t_cost : 0.001473, e_cost : 0.001131, elapsed time : 21.82sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.15161008917493746\n",
      "evalution_cost :  0.04968330974224955\n",
      "epoch : 45, t_cost : 0.001458, e_cost : 0.001129, elapsed time : 21.82sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.15021191941923462\n",
      "evalution_cost :  0.048565114178927615\n",
      "epoch : 46, t_cost : 0.001444, e_cost : 0.001104, elapsed time : 21.77sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.14933372460654937\n",
      "evalution_cost :  0.04785182265914045\n",
      "epoch : 47, t_cost : 0.001436, e_cost : 0.001088, elapsed time : 21.79sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.14992674396489747\n",
      "evalution_cost :  0.047660748386988416\n",
      "epoch : 48, t_cost : 0.001442, e_cost : 0.001083, elapsed time : 21.79sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.1506186302867718\n",
      "evalution_cost :  0.04836232162779197\n",
      "epoch : 49, t_cost : 0.001448, e_cost : 0.001099, elapsed time : 21.80sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.1510850919294171\n",
      "evalution_cost :  0.04806400946108624\n",
      "epoch : 50, t_cost : 0.001453, e_cost : 0.001092, elapsed time : 21.88sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.15056030068080872\n",
      "evalution_cost :  0.04778144205920398\n",
      "epoch : 51, t_cost : 0.001448, e_cost : 0.001086, elapsed time : 21.79sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.1501336062210612\n",
      "evalution_cost :  0.0479630644840654\n",
      "epoch : 52, t_cost : 0.001444, e_cost : 0.001090, elapsed time : 21.79sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.14981864433502778\n",
      "evalution_cost :  0.0478867242927663\n",
      "epoch : 53, t_cost : 0.001441, e_cost : 0.001088, elapsed time : 21.78sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.14927733014337718\n",
      "evalution_cost :  0.04801773320650682\n",
      "epoch : 54, t_cost : 0.001435, e_cost : 0.001091, elapsed time : 21.76sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.14943775546271354\n",
      "evalution_cost :  0.04832229865132831\n",
      "epoch : 55, t_cost : 0.001437, e_cost : 0.001098, elapsed time : 21.81sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.15133256430272013\n",
      "evalution_cost :  0.049301457504043356\n",
      "epoch : 56, t_cost : 0.001455, e_cost : 0.001120, elapsed time : 21.84sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.1523358923732303\n",
      "evalution_cost :  0.04927019806928001\n",
      "epoch : 57, t_cost : 0.001465, e_cost : 0.001120, elapsed time : 21.76sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.15251269529107958\n",
      "evalution_cost :  0.05059144730330445\n",
      "epoch : 58, t_cost : 0.001466, e_cost : 0.001150, elapsed time : 21.80sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.15597117197467014\n",
      "evalution_cost :  0.05188616208033636\n",
      "epoch : 59, t_cost : 0.001500, e_cost : 0.001179, elapsed time : 21.86sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.15571917145280167\n",
      "evalution_cost :  0.05453561042668298\n",
      "epoch : 60, t_cost : 0.001497, e_cost : 0.001239, elapsed time : 21.81sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.1553657089243643\n",
      "evalution_cost :  0.057951787137426436\n",
      "epoch : 61, t_cost : 0.001494, e_cost : 0.001317, elapsed time : 21.80sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.152184798149392\n",
      "evalution_cost :  0.059370952571043745\n",
      "epoch : 62, t_cost : 0.001463, e_cost : 0.001349, elapsed time : 21.78sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.15663666184991598\n",
      "evalution_cost :  0.05966278808773495\n",
      "epoch : 63, t_cost : 0.001506, e_cost : 0.001356, elapsed time : 21.82sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.153998127032537\n",
      "evalution_cost :  0.060653647407889366\n",
      "epoch : 64, t_cost : 0.001481, e_cost : 0.001378, elapsed time : 21.80sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.15726380835985765\n",
      "evalution_cost :  0.06291430597775616\n",
      "epoch : 65, t_cost : 0.001512, e_cost : 0.001430, elapsed time : 21.83sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.15301960770739242\n",
      "evalution_cost :  0.06585344826453365\n",
      "epoch : 66, t_cost : 0.001471, e_cost : 0.001497, elapsed time : 21.79sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.14849104749737307\n",
      "evalution_cost :  0.06196661852300167\n",
      "epoch : 67, t_cost : 0.001428, e_cost : 0.001408, elapsed time : 21.76sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.14974393625743687\n",
      "evalution_cost :  0.0636984491138719\n",
      "epoch : 68, t_cost : 0.001440, e_cost : 0.001448, elapsed time : 21.76sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.14774771983502433\n",
      "evalution_cost :  0.06574420479591936\n",
      "epoch : 69, t_cost : 0.001421, e_cost : 0.001494, elapsed time : 21.83sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.14500493253581226\n",
      "evalution_cost :  0.06528838371741585\n",
      "epoch : 70, t_cost : 0.001394, e_cost : 0.001484, elapsed time : 21.80sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.14571524638449773\n",
      "evalution_cost :  0.062118972244206816\n",
      "epoch : 71, t_cost : 0.001401, e_cost : 0.001412, elapsed time : 21.78sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.14592111919773743\n",
      "evalution_cost :  0.06446702923858538\n",
      "epoch : 72, t_cost : 0.001403, e_cost : 0.001465, elapsed time : 21.81sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.14580274128820747\n",
      "evalution_cost :  0.06604515042272396\n",
      "epoch : 73, t_cost : 0.001402, e_cost : 0.001501, elapsed time : 21.93sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.14582105947192758\n",
      "evalution_cost :  0.06628338719019666\n",
      "epoch : 74, t_cost : 0.001402, e_cost : 0.001506, elapsed time : 21.89sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.14550775953102857\n",
      "evalution_cost :  0.06837150693172589\n",
      "epoch : 75, t_cost : 0.001399, e_cost : 0.001554, elapsed time : 21.80sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traning_cost :  0.14458400604780763\n",
      "evalution_cost :  0.0661278368497733\n",
      "epoch : 76, t_cost : 0.001390, e_cost : 0.001503, elapsed time : 21.77sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.14679070451529697\n",
      "evalution_cost :  0.0640555729623884\n",
      "epoch : 77, t_cost : 0.001411, e_cost : 0.001456, elapsed time : 21.75sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.1451322848442942\n",
      "evalution_cost :  0.06488403838011436\n",
      "epoch : 78, t_cost : 0.001396, e_cost : 0.001475, elapsed time : 21.81sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.14671881851973012\n",
      "evalution_cost :  0.05350250119226985\n",
      "epoch : 79, t_cost : 0.001411, e_cost : 0.001216, elapsed time : 21.75sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.1428468092053663\n",
      "evalution_cost :  0.06286396720679477\n",
      "epoch : 80, t_cost : 0.001374, e_cost : 0.001429, elapsed time : 21.77sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.14323571522254497\n",
      "evalution_cost :  0.07139062718488276\n",
      "epoch : 81, t_cost : 0.001377, e_cost : 0.001623, elapsed time : 21.76sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.1437019039876759\n",
      "evalution_cost :  0.06760639220010489\n",
      "epoch : 82, t_cost : 0.001382, e_cost : 0.001537, elapsed time : 21.78sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.1443586022942327\n",
      "evalution_cost :  0.06775264709722251\n",
      "epoch : 83, t_cost : 0.001388, e_cost : 0.001540, elapsed time : 21.79sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.14490859978832304\n",
      "evalution_cost :  0.07216827719821595\n",
      "epoch : 84, t_cost : 0.001393, e_cost : 0.001640, elapsed time : 21.79sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.14373946649720892\n",
      "evalution_cost :  0.06843123864382505\n",
      "epoch : 85, t_cost : 0.001382, e_cost : 0.001555, elapsed time : 21.80sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.14525424502789974\n",
      "evalution_cost :  0.06717803725041449\n",
      "epoch : 86, t_cost : 0.001397, e_cost : 0.001527, elapsed time : 21.81sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.1405834614415653\n",
      "evalution_cost :  0.05740128454635851\n",
      "epoch : 87, t_cost : 0.001352, e_cost : 0.001305, elapsed time : 21.84sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.14020920934854075\n",
      "evalution_cost :  0.06898142921272665\n",
      "epoch : 88, t_cost : 0.001348, e_cost : 0.001568, elapsed time : 21.80sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.1402849611476995\n",
      "evalution_cost :  0.07159950130153447\n",
      "epoch : 89, t_cost : 0.001349, e_cost : 0.001627, elapsed time : 21.83sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.13927634386345744\n",
      "evalution_cost :  0.049680829426506534\n",
      "epoch : 90, t_cost : 0.001339, e_cost : 0.001129, elapsed time : 21.79sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.13509538758080453\n",
      "evalution_cost :  0.06416774922399782\n",
      "epoch : 91, t_cost : 0.001299, e_cost : 0.001458, elapsed time : 21.78sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.1390050722984597\n",
      "evalution_cost :  0.06347230664687231\n",
      "epoch : 92, t_cost : 0.001337, e_cost : 0.001443, elapsed time : 21.80sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.13478095387108624\n",
      "evalution_cost :  0.06325609481427819\n",
      "epoch : 93, t_cost : 0.001296, e_cost : 0.001438, elapsed time : 21.71sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.1387903177528642\n",
      "evalution_cost :  0.0675306998891756\n",
      "epoch : 94, t_cost : 0.001335, e_cost : 0.001535, elapsed time : 21.82sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.13728667108807713\n",
      "evalution_cost :  0.06660460386774503\n",
      "epoch : 95, t_cost : 0.001320, e_cost : 0.001514, elapsed time : 21.79sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.1364145524566993\n",
      "evalution_cost :  0.0658441647537984\n",
      "epoch : 96, t_cost : 0.001312, e_cost : 0.001496, elapsed time : 21.78sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.13522496190853417\n",
      "evalution_cost :  0.06301813462050632\n",
      "epoch : 97, t_cost : 0.001300, e_cost : 0.001432, elapsed time : 21.77sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.13684660999570042\n",
      "evalution_cost :  0.06584263365948573\n",
      "epoch : 98, t_cost : 0.001316, e_cost : 0.001496, elapsed time : 21.80sec\n",
      "data1 :  (53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "data1 :  (23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "traning_cost :  0.13240504037821665\n",
      "evalution_cost :  0.062153160863090307\n",
      "epoch : 99, t_cost : 0.001273, e_cost : 0.001413, elapsed time : 21.78sec\n",
      "\n",
      "#Best result at epoch 48\n",
      "t_cost : 0.001442, e_cost : 0.001083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f58847b77b8>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "#parameter list\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=16\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "#\n",
    "kospi=StockData(\n",
    "    'StockChart/SAMPLE',\n",
    "    'StockChart/KOSPI.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "\n",
    "print('\\n#training#')\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "result_dic={}\n",
    "evalution_costplt2=[]\n",
    "for i in range(100):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "\n",
    "    #training batch\n",
    "    for batch in kospi.getBatch('training'):\n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(\"traning_cost : \" , training_cost)\n",
    "    print(\"evalution_cost : \" , evalution_cost)\n",
    "   \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    evalution_costplt2.append(evalution_cost)\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "        i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))\n",
    "plt.plot(evalution_costplt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## epoch : 100 , batchsize : 512 , timesize : 32\n",
    "## timesize_for_calc_correlation=50\n",
    "## positive_correlation_stock_num=10\n",
    "## negative_correlation_sotck_num=10\n",
    "# date_duration=3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexPrice shape:  (3000, 1)\n",
      "StockPrice shape:  (3000, 26)\n",
      "making dataset progress : finished\t\n",
      "\n",
      "#training#\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  4.8309927058871835\n",
      "evalution_cost :  0.5716920723207295\n",
      "epoch : 0, t_cost : 0.046452, e_cost : 0.012993, elapsed time : 51.89sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  1.5614599350374192\n",
      "evalution_cost :  0.40709672519005835\n",
      "epoch : 1, t_cost : 0.015014, e_cost : 0.009252, elapsed time : 46.93sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.9510280813556165\n",
      "evalution_cost :  0.3251543550286442\n",
      "epoch : 2, t_cost : 0.009145, e_cost : 0.007390, elapsed time : 46.93sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.7644539324101061\n",
      "evalution_cost :  0.27437028114218265\n",
      "epoch : 3, t_cost : 0.007351, e_cost : 0.006236, elapsed time : 46.71sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.6843529567122459\n",
      "evalution_cost :  0.23149624688085169\n",
      "epoch : 4, t_cost : 0.006580, e_cost : 0.005261, elapsed time : 46.74sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.5753942348528653\n",
      "evalution_cost :  0.2568925820523873\n",
      "epoch : 5, t_cost : 0.005533, e_cost : 0.005838, elapsed time : 46.78sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.5983360678656027\n",
      "evalution_cost :  0.2812630756525323\n",
      "epoch : 6, t_cost : 0.005753, e_cost : 0.006392, elapsed time : 46.57sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.5697897989302874\n",
      "evalution_cost :  0.23276833619456738\n",
      "epoch : 7, t_cost : 0.005479, e_cost : 0.005290, elapsed time : 46.60sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.5447954797418788\n",
      "evalution_cost :  0.24255550594534725\n",
      "epoch : 8, t_cost : 0.005238, e_cost : 0.005513, elapsed time : 46.65sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.5129174451576546\n",
      "evalution_cost :  0.1735833432758227\n",
      "epoch : 9, t_cost : 0.004932, e_cost : 0.003945, elapsed time : 46.47sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.49284768174402416\n",
      "evalution_cost :  0.15102366055361927\n",
      "epoch : 10, t_cost : 0.004739, e_cost : 0.003432, elapsed time : 46.66sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.5377188960555941\n",
      "evalution_cost :  0.15499484015163034\n",
      "epoch : 11, t_cost : 0.005170, e_cost : 0.003523, elapsed time : 46.43sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.4775454334449023\n",
      "evalution_cost :  0.1287695844657719\n",
      "epoch : 12, t_cost : 0.004592, e_cost : 0.002927, elapsed time : 46.51sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.536433674627915\n",
      "evalution_cost :  0.20527970499824733\n",
      "epoch : 13, t_cost : 0.005158, e_cost : 0.004665, elapsed time : 46.38sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.532205255003646\n",
      "evalution_cost :  0.22585611033719033\n",
      "epoch : 14, t_cost : 0.005117, e_cost : 0.005133, elapsed time : 46.40sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.5914738971041515\n",
      "evalution_cost :  0.25193599390331656\n",
      "epoch : 15, t_cost : 0.005687, e_cost : 0.005726, elapsed time : 46.53sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.704003167222254\n",
      "evalution_cost :  0.244253633543849\n",
      "epoch : 16, t_cost : 0.006769, e_cost : 0.005551, elapsed time : 46.36sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.7816900884499773\n",
      "evalution_cost :  0.3448086763964966\n",
      "epoch : 17, t_cost : 0.007516, e_cost : 0.007837, elapsed time : 46.32sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  1.0870129764080048\n",
      "evalution_cost :  0.1435717121930793\n",
      "epoch : 18, t_cost : 0.010452, e_cost : 0.003263, elapsed time : 46.45sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  1.0076264103408903\n",
      "evalution_cost :  0.3340364370960742\n",
      "epoch : 19, t_cost : 0.009689, e_cost : 0.007592, elapsed time : 46.58sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  1.4709190018475056\n",
      "evalution_cost :  0.21914145298069343\n",
      "epoch : 20, t_cost : 0.014143, e_cost : 0.004980, elapsed time : 46.77sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  1.0453059747815132\n",
      "evalution_cost :  0.17552033357787877\n",
      "epoch : 21, t_cost : 0.010051, e_cost : 0.003989, elapsed time : 46.32sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.8195189345860854\n",
      "evalution_cost :  0.10802607180085033\n",
      "epoch : 22, t_cost : 0.007880, e_cost : 0.002455, elapsed time : 46.58sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.6388314981013536\n",
      "evalution_cost :  0.09091277123661712\n",
      "epoch : 23, t_cost : 0.006143, e_cost : 0.002066, elapsed time : 46.51sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.3984426024835557\n",
      "evalution_cost :  0.08344245300395414\n",
      "epoch : 24, t_cost : 0.003831, e_cost : 0.001896, elapsed time : 46.67sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.3024271781905554\n",
      "evalution_cost :  0.07636156614171341\n",
      "epoch : 25, t_cost : 0.002908, e_cost : 0.001735, elapsed time : 46.61sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.24309383728541434\n",
      "evalution_cost :  0.06963073869701475\n",
      "epoch : 26, t_cost : 0.002337, e_cost : 0.001583, elapsed time : 46.68sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.20956537476740777\n",
      "evalution_cost :  0.06192055332940072\n",
      "epoch : 27, t_cost : 0.002015, e_cost : 0.001407, elapsed time : 46.60sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.190778570715338\n",
      "evalution_cost :  0.05624254123540595\n",
      "epoch : 28, t_cost : 0.001834, e_cost : 0.001278, elapsed time : 46.67sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.1827704677125439\n",
      "evalution_cost :  0.05440989072667435\n",
      "epoch : 29, t_cost : 0.001757, e_cost : 0.001237, elapsed time : 46.54sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.1848786001210101\n",
      "evalution_cost :  0.055395619769115\n",
      "epoch : 30, t_cost : 0.001778, e_cost : 0.001259, elapsed time : 46.58sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.19760256068548188\n",
      "evalution_cost :  0.06065397887141444\n",
      "epoch : 31, t_cost : 0.001900, e_cost : 0.001378, elapsed time : 46.15sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.21778046333929524\n",
      "evalution_cost :  0.0754613425815478\n",
      "epoch : 32, t_cost : 0.002094, e_cost : 0.001715, elapsed time : 46.60sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.23140049952780828\n",
      "evalution_cost :  0.09444929682649672\n",
      "epoch : 33, t_cost : 0.002225, e_cost : 0.002147, elapsed time : 46.61sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.22876896074740216\n",
      "evalution_cost :  0.1020762313855812\n",
      "epoch : 34, t_cost : 0.002200, e_cost : 0.002320, elapsed time : 46.54sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.21796942793298513\n",
      "evalution_cost :  0.10018585115903988\n",
      "epoch : 35, t_cost : 0.002096, e_cost : 0.002277, elapsed time : 46.57sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2103239280404523\n",
      "evalution_cost :  0.09769058343954384\n",
      "epoch : 36, t_cost : 0.002022, e_cost : 0.002220, elapsed time : 46.59sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.20332315395353362\n",
      "evalution_cost :  0.09311884467024356\n",
      "epoch : 37, t_cost : 0.001955, e_cost : 0.002116, elapsed time : 46.78sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.19848987745353952\n",
      "evalution_cost :  0.09063846449134871\n",
      "epoch : 38, t_cost : 0.001909, e_cost : 0.002060, elapsed time : 46.60sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.19524602964520454\n",
      "evalution_cost :  0.08675177034456283\n",
      "epoch : 39, t_cost : 0.001877, e_cost : 0.001972, elapsed time : 46.77sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.19264860573457554\n",
      "evalution_cost :  0.08549367659725249\n",
      "epoch : 40, t_cost : 0.001852, e_cost : 0.001943, elapsed time : 46.59sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.18959510733839124\n",
      "evalution_cost :  0.08275896345730871\n",
      "epoch : 41, t_cost : 0.001823, e_cost : 0.001881, elapsed time : 46.57sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.18736826005624607\n",
      "evalution_cost :  0.08102284779306501\n",
      "epoch : 42, t_cost : 0.001802, e_cost : 0.001841, elapsed time : 46.63sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.18575380806578323\n",
      "evalution_cost :  0.07811907446011901\n",
      "epoch : 43, t_cost : 0.001786, e_cost : 0.001775, elapsed time : 46.58sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.18406067427713424\n",
      "evalution_cost :  0.07615029308362864\n",
      "epoch : 44, t_cost : 0.001770, e_cost : 0.001731, elapsed time : 46.70sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.18198873120127246\n",
      "evalution_cost :  0.07228038893663324\n",
      "epoch : 45, t_cost : 0.001750, e_cost : 0.001643, elapsed time : 46.92sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.18068328185472637\n",
      "evalution_cost :  0.0701410009060055\n",
      "epoch : 46, t_cost : 0.001737, e_cost : 0.001594, elapsed time : 46.59sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.17983767535770312\n",
      "evalution_cost :  0.06748977903043851\n",
      "epoch : 47, t_cost : 0.001729, e_cost : 0.001534, elapsed time : 46.54sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.18146543786861002\n",
      "evalution_cost :  0.06511285458691418\n",
      "epoch : 48, t_cost : 0.001745, e_cost : 0.001480, elapsed time : 46.46sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.1826603245572187\n",
      "evalution_cost :  0.06268134422134608\n",
      "epoch : 49, t_cost : 0.001756, e_cost : 0.001425, elapsed time : 46.80sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.18538605666253716\n",
      "evalution_cost :  0.060589311469811946\n",
      "epoch : 50, t_cost : 0.001783, e_cost : 0.001377, elapsed time : 46.65sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.19004152051638812\n",
      "evalution_cost :  0.058541583246551454\n",
      "epoch : 51, t_cost : 0.001827, e_cost : 0.001330, elapsed time : 46.89sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.19643010810250416\n",
      "evalution_cost :  0.05689824992441572\n",
      "epoch : 52, t_cost : 0.001889, e_cost : 0.001293, elapsed time : 46.69sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.20246403286000714\n",
      "evalution_cost :  0.05613224988337606\n",
      "epoch : 53, t_cost : 0.001947, e_cost : 0.001276, elapsed time : 46.39sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.20545318408403546\n",
      "evalution_cost :  0.0553742487099953\n",
      "epoch : 54, t_cost : 0.001976, e_cost : 0.001259, elapsed time : 46.45sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.20223687880206853\n",
      "evalution_cost :  0.05433211589115672\n",
      "epoch : 55, t_cost : 0.001945, e_cost : 0.001235, elapsed time : 46.65sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.19381226156838238\n",
      "evalution_cost :  0.05442240129923448\n",
      "epoch : 56, t_cost : 0.001864, e_cost : 0.001237, elapsed time : 46.58sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.18568022205727175\n",
      "evalution_cost :  0.053941580903483555\n",
      "epoch : 57, t_cost : 0.001785, e_cost : 0.001226, elapsed time : 46.58sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.17750736779998988\n",
      "evalution_cost :  0.05326931574381888\n",
      "epoch : 58, t_cost : 0.001707, e_cost : 0.001211, elapsed time : 46.31sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.16803069523302838\n",
      "evalution_cost :  0.05163519160123542\n",
      "epoch : 59, t_cost : 0.001616, e_cost : 0.001174, elapsed time : 46.77sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.16861101216636598\n",
      "evalution_cost :  0.050353560131043196\n",
      "epoch : 60, t_cost : 0.001621, e_cost : 0.001144, elapsed time : 46.44sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.17025162826757878\n",
      "evalution_cost :  0.047893165465211496\n",
      "epoch : 61, t_cost : 0.001637, e_cost : 0.001088, elapsed time : 46.83sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.17291886819293723\n",
      "evalution_cost :  0.04686847547418438\n",
      "epoch : 62, t_cost : 0.001663, e_cost : 0.001065, elapsed time : 46.73sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.16927126562222838\n",
      "evalution_cost :  0.04633372972602956\n",
      "epoch : 63, t_cost : 0.001628, e_cost : 0.001053, elapsed time : 46.79sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.16289773379685357\n",
      "evalution_cost :  0.047999030590290204\n",
      "epoch : 64, t_cost : 0.001566, e_cost : 0.001091, elapsed time : 46.53sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.1743555658031255\n",
      "evalution_cost :  0.050744615553412586\n",
      "epoch : 65, t_cost : 0.001676, e_cost : 0.001153, elapsed time : 46.71sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.15859607176389545\n",
      "evalution_cost :  0.04880229427362792\n",
      "epoch : 66, t_cost : 0.001525, e_cost : 0.001109, elapsed time : 46.70sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.17812033859081566\n",
      "evalution_cost :  0.04994922465994023\n",
      "epoch : 67, t_cost : 0.001713, e_cost : 0.001135, elapsed time : 46.77sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.1879539471701719\n",
      "evalution_cost :  0.06268771749455482\n",
      "epoch : 68, t_cost : 0.001807, e_cost : 0.001425, elapsed time : 46.54sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.23113163671223447\n",
      "evalution_cost :  0.06263547754497267\n",
      "epoch : 69, t_cost : 0.002222, e_cost : 0.001424, elapsed time : 46.48sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.19942724448628724\n",
      "evalution_cost :  0.060566723317606375\n",
      "epoch : 70, t_cost : 0.001918, e_cost : 0.001377, elapsed time : 46.13sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.24476515431888402\n",
      "evalution_cost :  0.05702679371461272\n",
      "epoch : 71, t_cost : 0.002354, e_cost : 0.001296, elapsed time : 46.30sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.23633693158626556\n",
      "evalution_cost :  0.05703981191618368\n",
      "epoch : 72, t_cost : 0.002272, e_cost : 0.001296, elapsed time : 46.54sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.22303901822306216\n",
      "evalution_cost :  0.06007669685641304\n",
      "epoch : 73, t_cost : 0.002145, e_cost : 0.001365, elapsed time : 46.37sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.19695442082593217\n",
      "evalution_cost :  0.06001955573447049\n",
      "epoch : 74, t_cost : 0.001894, e_cost : 0.001364, elapsed time : 46.52sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.1846438252250664\n",
      "evalution_cost :  0.05744313765899278\n",
      "epoch : 75, t_cost : 0.001775, e_cost : 0.001306, elapsed time : 46.64sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traning_cost :  0.18197437113849446\n",
      "evalution_cost :  0.05550680254236795\n",
      "epoch : 76, t_cost : 0.001750, e_cost : 0.001262, elapsed time : 46.69sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.18226331000914797\n",
      "evalution_cost :  0.054433863260783255\n",
      "epoch : 77, t_cost : 0.001753, e_cost : 0.001237, elapsed time : 48.08sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.1824517680797726\n",
      "evalution_cost :  0.05607441277243197\n",
      "epoch : 78, t_cost : 0.001754, e_cost : 0.001274, elapsed time : 47.48sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.18076878134161234\n",
      "evalution_cost :  0.05800782376900315\n",
      "epoch : 79, t_cost : 0.001738, e_cost : 0.001318, elapsed time : 47.02sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.1755463636945933\n",
      "evalution_cost :  0.05837423019693233\n",
      "epoch : 80, t_cost : 0.001688, e_cost : 0.001327, elapsed time : 47.08sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.1708316695294343\n",
      "evalution_cost :  0.05671152487047948\n",
      "epoch : 81, t_cost : 0.001643, e_cost : 0.001289, elapsed time : 46.68sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.164940245449543\n",
      "evalution_cost :  0.05407534941332415\n",
      "epoch : 82, t_cost : 0.001586, e_cost : 0.001229, elapsed time : 46.92sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.15929657593369484\n",
      "evalution_cost :  0.051959163742139935\n",
      "epoch : 83, t_cost : 0.001532, e_cost : 0.001181, elapsed time : 47.26sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.15612835419597104\n",
      "evalution_cost :  0.05070963126490824\n",
      "epoch : 84, t_cost : 0.001501, e_cost : 0.001152, elapsed time : 46.94sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.15471229644026607\n",
      "evalution_cost :  0.04931874948670156\n",
      "epoch : 85, t_cost : 0.001488, e_cost : 0.001121, elapsed time : 48.76sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.1538434171816334\n",
      "evalution_cost :  0.048556356166955084\n",
      "epoch : 86, t_cost : 0.001479, e_cost : 0.001104, elapsed time : 46.89sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.1536315176053904\n",
      "evalution_cost :  0.04807262524263933\n",
      "epoch : 87, t_cost : 0.001477, e_cost : 0.001093, elapsed time : 46.30sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.1547801473061554\n",
      "evalution_cost :  0.04790300122112967\n",
      "epoch : 88, t_cost : 0.001488, e_cost : 0.001089, elapsed time : 46.33sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.1576793200802058\n",
      "evalution_cost :  0.04804129898548126\n",
      "epoch : 89, t_cost : 0.001516, e_cost : 0.001092, elapsed time : 46.56sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.1619832857977599\n",
      "evalution_cost :  0.048203783691860735\n",
      "epoch : 90, t_cost : 0.001558, e_cost : 0.001096, elapsed time : 46.47sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.16743270540609956\n",
      "evalution_cost :  0.0488738295098301\n",
      "epoch : 91, t_cost : 0.001610, e_cost : 0.001111, elapsed time : 46.34sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.17018999275751412\n",
      "evalution_cost :  0.050104317982913926\n",
      "epoch : 92, t_cost : 0.001636, e_cost : 0.001139, elapsed time : 46.42sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.17854218190768734\n",
      "evalution_cost :  0.05094972421647981\n",
      "epoch : 93, t_cost : 0.001717, e_cost : 0.001158, elapsed time : 46.40sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.18051640351768583\n",
      "evalution_cost :  0.05167821832583286\n",
      "epoch : 94, t_cost : 0.001736, e_cost : 0.001175, elapsed time : 46.38sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.17763581295730546\n",
      "evalution_cost :  0.05081326511572115\n",
      "epoch : 95, t_cost : 0.001708, e_cost : 0.001155, elapsed time : 46.45sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.1808362272568047\n",
      "evalution_cost :  0.052645818708697334\n",
      "epoch : 96, t_cost : 0.001739, e_cost : 0.001196, elapsed time : 46.38sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.17670109041500837\n",
      "evalution_cost :  0.05200536939082667\n",
      "epoch : 97, t_cost : 0.001699, e_cost : 0.001182, elapsed time : 46.43sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.1726197621319443\n",
      "evalution_cost :  0.054156441474333405\n",
      "epoch : 98, t_cost : 0.001660, e_cost : 0.001231, elapsed time : 46.38sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.16448836436029524\n",
      "evalution_cost :  0.05215388227952644\n",
      "epoch : 99, t_cost : 0.001582, e_cost : 0.001185, elapsed time : 46.40sec\n",
      "\n",
      "#Best result at epoch 63\n",
      "t_cost : 0.001628, e_cost : 0.001053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f589ffc12b0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "#parameter list\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=32\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "#\n",
    "kospi=StockData(\n",
    "    'StockChart/SAMPLE',\n",
    "    'StockChart/KOSPI.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "\n",
    "print('\\n#training#')\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "result_dic={}\n",
    "evalution_costplt2=[]\n",
    "for i in range(100):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "\n",
    "    #training batch\n",
    "    for batch in kospi.getBatch('training'):\n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(\"traning_cost : \" , training_cost)\n",
    "    print(\"evalution_cost : \" , evalution_cost)\n",
    "   \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    evalution_costplt2.append(evalution_cost)\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "        i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))\n",
    "plt.plot(evalution_costplt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## epoch : 100 , batchsize : 256 , timesize : 32\n",
    "## timesize_for_calc_correlation=50\n",
    "## positive_correlation_stock_num=10\n",
    "## negative_correlation_sotck_num=10\n",
    "# date_duration=3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexPrice shape:  (3000, 1)\n",
      "StockPrice shape:  (3000, 26)\n",
      "making dataset progress : finished\t\n",
      "\n",
      "#training#\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  7.0361625659279525\n",
      "evalution_cost :  2.3805597964674234\n",
      "epoch : 0, t_cost : 0.033666, e_cost : 0.026748, elapsed time : 56.32sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  2.895106978248805\n",
      "evalution_cost :  1.9210706206504256\n",
      "epoch : 1, t_cost : 0.013852, e_cost : 0.021585, elapsed time : 51.19sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  2.470947590423748\n",
      "evalution_cost :  0.9846599128795788\n",
      "epoch : 2, t_cost : 0.011823, e_cost : 0.011064, elapsed time : 51.17sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  1.7363565022242256\n",
      "evalution_cost :  0.6845696675591171\n",
      "epoch : 3, t_cost : 0.008308, e_cost : 0.007692, elapsed time : 51.19sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  1.2061587062780745\n",
      "evalution_cost :  0.5084935737540945\n",
      "epoch : 4, t_cost : 0.005771, e_cost : 0.005713, elapsed time : 51.14sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  1.0806211123708636\n",
      "evalution_cost :  0.4404272382380441\n",
      "epoch : 5, t_cost : 0.005170, e_cost : 0.004949, elapsed time : 51.24sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.9877770801540464\n",
      "evalution_cost :  0.3511540225590579\n",
      "epoch : 6, t_cost : 0.004726, e_cost : 0.003946, elapsed time : 51.34sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.7454395827371627\n",
      "evalution_cost :  0.3480618171743117\n",
      "epoch : 7, t_cost : 0.003567, e_cost : 0.003911, elapsed time : 51.32sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.7369421416660771\n",
      "evalution_cost :  0.34381661971565336\n",
      "epoch : 8, t_cost : 0.003526, e_cost : 0.003863, elapsed time : 51.11sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.7216291734948754\n",
      "evalution_cost :  0.332565496530151\n",
      "epoch : 9, t_cost : 0.003453, e_cost : 0.003737, elapsed time : 51.28sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.6802812085370533\n",
      "evalution_cost :  0.2741420689271763\n",
      "epoch : 10, t_cost : 0.003255, e_cost : 0.003080, elapsed time : 51.35sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.5847813540603966\n",
      "evalution_cost :  0.206234956625849\n",
      "epoch : 11, t_cost : 0.002798, e_cost : 0.002317, elapsed time : 51.16sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.4802378781605512\n",
      "evalution_cost :  0.16663866766612045\n",
      "epoch : 12, t_cost : 0.002298, e_cost : 0.001872, elapsed time : 51.79sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.39745865075383335\n",
      "evalution_cost :  0.15090048560523428\n",
      "epoch : 13, t_cost : 0.001902, e_cost : 0.001696, elapsed time : 51.33sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.35495542231365107\n",
      "evalution_cost :  0.13843031754367985\n",
      "epoch : 14, t_cost : 0.001698, e_cost : 0.001555, elapsed time : 51.36sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.3305938783742022\n",
      "evalution_cost :  0.11793177895015106\n",
      "epoch : 15, t_cost : 0.001582, e_cost : 0.001325, elapsed time : 51.40sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.3088638207409531\n",
      "evalution_cost :  0.10293622856261209\n",
      "epoch : 16, t_cost : 0.001478, e_cost : 0.001157, elapsed time : 51.36sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.290184480661992\n",
      "evalution_cost :  0.09642713161883876\n",
      "epoch : 17, t_cost : 0.001388, e_cost : 0.001083, elapsed time : 51.45sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2743384329951368\n",
      "evalution_cost :  0.10377531478297897\n",
      "epoch : 18, t_cost : 0.001313, e_cost : 0.001166, elapsed time : 51.45sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2705874219245743\n",
      "evalution_cost :  0.11396577759296633\n",
      "epoch : 19, t_cost : 0.001295, e_cost : 0.001281, elapsed time : 51.55sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2781219817115925\n",
      "evalution_cost :  0.14025431967456825\n",
      "epoch : 20, t_cost : 0.001331, e_cost : 0.001576, elapsed time : 51.44sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2897176520782523\n",
      "evalution_cost :  0.15327523148152977\n",
      "epoch : 21, t_cost : 0.001386, e_cost : 0.001722, elapsed time : 51.29sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2974702987994533\n",
      "evalution_cost :  0.1385403886961285\n",
      "epoch : 22, t_cost : 0.001423, e_cost : 0.001557, elapsed time : 51.51sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.294527389050927\n",
      "evalution_cost :  0.12426093276008032\n",
      "epoch : 23, t_cost : 0.001409, e_cost : 0.001396, elapsed time : 51.50sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2973818051395938\n",
      "evalution_cost :  0.10762281718780287\n",
      "epoch : 24, t_cost : 0.001423, e_cost : 0.001209, elapsed time : 51.47sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.28524214439676143\n",
      "evalution_cost :  0.10470184471341781\n",
      "epoch : 25, t_cost : 0.001365, e_cost : 0.001176, elapsed time : 51.44sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2879378225770779\n",
      "evalution_cost :  0.09958251306670718\n",
      "epoch : 26, t_cost : 0.001378, e_cost : 0.001119, elapsed time : 51.46sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2896624252316542\n",
      "evalution_cost :  0.09845329806557857\n",
      "epoch : 27, t_cost : 0.001386, e_cost : 0.001106, elapsed time : 51.42sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2897673479747027\n",
      "evalution_cost :  0.09090149405528791\n",
      "epoch : 28, t_cost : 0.001386, e_cost : 0.001021, elapsed time : 51.44sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.28660425171256065\n",
      "evalution_cost :  0.08807897628867067\n",
      "epoch : 29, t_cost : 0.001371, e_cost : 0.000990, elapsed time : 51.36sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2857529261673335\n",
      "evalution_cost :  0.086268969316734\n",
      "epoch : 30, t_cost : 0.001367, e_cost : 0.000969, elapsed time : 51.48sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.278722133487463\n",
      "evalution_cost :  0.0874578018556349\n",
      "epoch : 31, t_cost : 0.001334, e_cost : 0.000983, elapsed time : 51.46sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.26944004668621346\n",
      "evalution_cost :  0.08755564424791373\n",
      "epoch : 32, t_cost : 0.001289, e_cost : 0.000984, elapsed time : 51.28sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.27387209961307235\n",
      "evalution_cost :  0.11132479214575142\n",
      "epoch : 33, t_cost : 0.001310, e_cost : 0.001251, elapsed time : 51.53sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2890221816196572\n",
      "evalution_cost :  0.12478252078290097\n",
      "epoch : 34, t_cost : 0.001383, e_cost : 0.001402, elapsed time : 51.44sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.30922398579423316\n",
      "evalution_cost :  0.1063711242750287\n",
      "epoch : 35, t_cost : 0.001480, e_cost : 0.001195, elapsed time : 51.40sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.3187401954928646\n",
      "evalution_cost :  0.09837160399183631\n",
      "epoch : 36, t_cost : 0.001525, e_cost : 0.001105, elapsed time : 51.39sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.26717368289246224\n",
      "evalution_cost :  0.08747596977627836\n",
      "epoch : 37, t_cost : 0.001278, e_cost : 0.000983, elapsed time : 51.30sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.25609192450065166\n",
      "evalution_cost :  0.08934891081298701\n",
      "epoch : 38, t_cost : 0.001225, e_cost : 0.001004, elapsed time : 51.36sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2589930673711933\n",
      "evalution_cost :  0.09681511300732382\n",
      "epoch : 39, t_cost : 0.001239, e_cost : 0.001088, elapsed time : 51.17sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2647045240155421\n",
      "evalution_cost :  0.10463726011221297\n",
      "epoch : 40, t_cost : 0.001267, e_cost : 0.001176, elapsed time : 51.12sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.26668059948133305\n",
      "evalution_cost :  0.10422591713722795\n",
      "epoch : 41, t_cost : 0.001276, e_cost : 0.001171, elapsed time : 51.20sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2762516284128651\n",
      "evalution_cost :  0.10758585057919845\n",
      "epoch : 42, t_cost : 0.001322, e_cost : 0.001209, elapsed time : 51.07sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2628202853957191\n",
      "evalution_cost :  0.10227108164690435\n",
      "epoch : 43, t_cost : 0.001258, e_cost : 0.001149, elapsed time : 50.98sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2753412071906496\n",
      "evalution_cost :  0.11313005001284182\n",
      "epoch : 44, t_cost : 0.001317, e_cost : 0.001271, elapsed time : 51.10sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2625116896815598\n",
      "evalution_cost :  0.10394334676675498\n",
      "epoch : 45, t_cost : 0.001256, e_cost : 0.001168, elapsed time : 51.23sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.25842823641141877\n",
      "evalution_cost :  0.10541552075301297\n",
      "epoch : 46, t_cost : 0.001236, e_cost : 0.001184, elapsed time : 51.02sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2571339507267112\n",
      "evalution_cost :  0.10797029672539793\n",
      "epoch : 47, t_cost : 0.001230, e_cost : 0.001213, elapsed time : 50.97sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.25914116532658227\n",
      "evalution_cost :  0.10159848851617426\n",
      "epoch : 48, t_cost : 0.001240, e_cost : 0.001142, elapsed time : 51.04sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2633574416395277\n",
      "evalution_cost :  0.12207793758716434\n",
      "epoch : 49, t_cost : 0.001260, e_cost : 0.001372, elapsed time : 51.07sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.25856073448085226\n",
      "evalution_cost :  0.12208100277348422\n",
      "epoch : 50, t_cost : 0.001237, e_cost : 0.001372, elapsed time : 51.14sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.25601083420042414\n",
      "evalution_cost :  0.1117481192923151\n",
      "epoch : 51, t_cost : 0.001225, e_cost : 0.001256, elapsed time : 51.25sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2552490250382107\n",
      "evalution_cost :  0.1328077192301862\n",
      "epoch : 52, t_cost : 0.001221, e_cost : 0.001492, elapsed time : 51.15sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2521302271343302\n",
      "evalution_cost :  0.14554980711545795\n",
      "epoch : 53, t_cost : 0.001206, e_cost : 0.001635, elapsed time : 51.07sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.24938966106856242\n",
      "evalution_cost :  0.1621199117798824\n",
      "epoch : 54, t_cost : 0.001193, e_cost : 0.001822, elapsed time : 51.13sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.25692603418428916\n",
      "evalution_cost :  0.1521762849879451\n",
      "epoch : 55, t_cost : 0.001229, e_cost : 0.001710, elapsed time : 52.35sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2488205635745544\n",
      "evalution_cost :  0.2042828158591874\n",
      "epoch : 56, t_cost : 0.001191, e_cost : 0.002295, elapsed time : 51.98sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2716073706251336\n",
      "evalution_cost :  0.10341092490125448\n",
      "epoch : 57, t_cost : 0.001300, e_cost : 0.001162, elapsed time : 51.96sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.26745648522046395\n",
      "evalution_cost :  0.10503091994905844\n",
      "epoch : 58, t_cost : 0.001280, e_cost : 0.001180, elapsed time : 51.88sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.25642205990152434\n",
      "evalution_cost :  0.13841222191695124\n",
      "epoch : 59, t_cost : 0.001227, e_cost : 0.001555, elapsed time : 51.56sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2784935900126584\n",
      "evalution_cost :  0.10063533807988279\n",
      "epoch : 60, t_cost : 0.001333, e_cost : 0.001131, elapsed time : 51.29sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.27214828348951414\n",
      "evalution_cost :  0.09757247104425915\n",
      "epoch : 61, t_cost : 0.001302, e_cost : 0.001096, elapsed time : 51.07sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.30640727980062366\n",
      "evalution_cost :  0.09474852902349085\n",
      "epoch : 62, t_cost : 0.001466, e_cost : 0.001065, elapsed time : 51.06sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2727022210310679\n",
      "evalution_cost :  0.16361240090918727\n",
      "epoch : 63, t_cost : 0.001305, e_cost : 0.001838, elapsed time : 51.08sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.27418929027044214\n",
      "evalution_cost :  0.10844044759869576\n",
      "epoch : 64, t_cost : 0.001312, e_cost : 0.001218, elapsed time : 51.16sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2726707779802382\n",
      "evalution_cost :  0.11551281998981722\n",
      "epoch : 65, t_cost : 0.001305, e_cost : 0.001298, elapsed time : 51.16sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.26693465712014586\n",
      "evalution_cost :  0.11803670541848987\n",
      "epoch : 66, t_cost : 0.001277, e_cost : 0.001326, elapsed time : 51.22sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.27682885114336386\n",
      "evalution_cost :  0.10744559657177888\n",
      "epoch : 67, t_cost : 0.001325, e_cost : 0.001207, elapsed time : 51.24sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2765379365591798\n",
      "evalution_cost :  0.10738647149992175\n",
      "epoch : 68, t_cost : 0.001323, e_cost : 0.001207, elapsed time : 52.62sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2748596181627363\n",
      "evalution_cost :  0.10894464116427116\n",
      "epoch : 69, t_cost : 0.001315, e_cost : 0.001224, elapsed time : 52.06sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.28860762214753777\n",
      "evalution_cost :  0.10669346438953653\n",
      "epoch : 70, t_cost : 0.001381, e_cost : 0.001199, elapsed time : 51.16sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.28915994038106874\n",
      "evalution_cost :  0.10558135720202699\n",
      "epoch : 71, t_cost : 0.001384, e_cost : 0.001186, elapsed time : 51.56sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2839046763838269\n",
      "evalution_cost :  0.10412716487189755\n",
      "epoch : 72, t_cost : 0.001358, e_cost : 0.001170, elapsed time : 51.39sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.27792157599469647\n",
      "evalution_cost :  0.10820178547874093\n",
      "epoch : 73, t_cost : 0.001330, e_cost : 0.001216, elapsed time : 51.51sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.27372691314667463\n",
      "evalution_cost :  0.10681707679759711\n",
      "epoch : 74, t_cost : 0.001310, e_cost : 0.001200, elapsed time : 52.32sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2678168159618508\n",
      "evalution_cost :  0.11500511775375344\n",
      "epoch : 75, t_cost : 0.001281, e_cost : 0.001292, elapsed time : 52.30sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traning_cost :  0.27032690215855837\n",
      "evalution_cost :  0.11710303172003478\n",
      "epoch : 76, t_cost : 0.001293, e_cost : 0.001316, elapsed time : 51.29sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2614478645264171\n",
      "evalution_cost :  0.10958913707872853\n",
      "epoch : 77, t_cost : 0.001251, e_cost : 0.001231, elapsed time : 50.93sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.25525349064264446\n",
      "evalution_cost :  0.1037942883267533\n",
      "epoch : 78, t_cost : 0.001221, e_cost : 0.001166, elapsed time : 50.55sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.25818685960257426\n",
      "evalution_cost :  0.10371964395744726\n",
      "epoch : 79, t_cost : 0.001235, e_cost : 0.001165, elapsed time : 52.15sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2602293405798264\n",
      "evalution_cost :  0.10656708054011688\n",
      "epoch : 80, t_cost : 0.001245, e_cost : 0.001197, elapsed time : 51.21sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.25861868425272405\n",
      "evalution_cost :  0.10617694360553287\n",
      "epoch : 81, t_cost : 0.001237, e_cost : 0.001193, elapsed time : 51.22sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.26651685978868045\n",
      "evalution_cost :  0.10851436029770412\n",
      "epoch : 82, t_cost : 0.001275, e_cost : 0.001219, elapsed time : 52.28sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.27750436824862845\n",
      "evalution_cost :  0.1160806211992167\n",
      "epoch : 83, t_cost : 0.001328, e_cost : 0.001304, elapsed time : 51.99sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.27684515638975427\n",
      "evalution_cost :  0.13487594609614462\n",
      "epoch : 84, t_cost : 0.001325, e_cost : 0.001515, elapsed time : 50.68sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.27587461745133623\n",
      "evalution_cost :  0.13900048797950149\n",
      "epoch : 85, t_cost : 0.001320, e_cost : 0.001562, elapsed time : 50.37sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.26605202886275947\n",
      "evalution_cost :  0.1609284853329882\n",
      "epoch : 86, t_cost : 0.001273, e_cost : 0.001808, elapsed time : 50.55sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.26881238995702006\n",
      "evalution_cost :  0.15240992739563808\n",
      "epoch : 87, t_cost : 0.001286, e_cost : 0.001712, elapsed time : 50.51sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2736556757299695\n",
      "evalution_cost :  0.15175896510481834\n",
      "epoch : 88, t_cost : 0.001309, e_cost : 0.001705, elapsed time : 50.58sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2822714828653261\n",
      "evalution_cost :  0.13879690252360888\n",
      "epoch : 89, t_cost : 0.001351, e_cost : 0.001560, elapsed time : 50.62sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.287137024482945\n",
      "evalution_cost :  0.12006679750629701\n",
      "epoch : 90, t_cost : 0.001374, e_cost : 0.001349, elapsed time : 50.58sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.27935788154718466\n",
      "evalution_cost :  0.11632009901222773\n",
      "epoch : 91, t_cost : 0.001337, e_cost : 0.001307, elapsed time : 50.50sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.27087154431501403\n",
      "evalution_cost :  0.11855008607381023\n",
      "epoch : 92, t_cost : 0.001296, e_cost : 0.001332, elapsed time : 50.64sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.2628901891876012\n",
      "evalution_cost :  0.12128323380602524\n",
      "epoch : 93, t_cost : 0.001258, e_cost : 0.001363, elapsed time : 50.48sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.25130094232736155\n",
      "evalution_cost :  0.11507061056909151\n",
      "epoch : 94, t_cost : 0.001202, e_cost : 0.001293, elapsed time : 50.51sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.24281512282323092\n",
      "evalution_cost :  0.116945192363346\n",
      "epoch : 95, t_cost : 0.001162, e_cost : 0.001314, elapsed time : 50.61sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.23516856547212228\n",
      "evalution_cost :  0.10928371781483293\n",
      "epoch : 96, t_cost : 0.001125, e_cost : 0.001228, elapsed time : 50.48sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.23144304010202177\n",
      "evalution_cost :  0.11244422162417322\n",
      "epoch : 97, t_cost : 0.001107, e_cost : 0.001263, elapsed time : 50.54sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.22411777882371098\n",
      "evalution_cost :  0.11648061347659677\n",
      "epoch : 98, t_cost : 0.001072, e_cost : 0.001309, elapsed time : 50.54sec\n",
      "data1 :  (53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "data1 :  (23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "traning_cost :  0.22133074872544967\n",
      "evalution_cost :  0.11102980887517333\n",
      "epoch : 99, t_cost : 0.001059, e_cost : 0.001248, elapsed time : 50.49sec\n",
      "\n",
      "#Best result at epoch 30\n",
      "t_cost : 0.001367, e_cost : 0.000969\n",
      "[<matplotlib.lines.Line2D object at 0x7f58841937b8>]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d06eea0f953d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalution_costplt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalution_costplt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "#parameter list\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=32\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=256\n",
    "#\n",
    "kospi=StockData(\n",
    "    'StockChart/SAMPLE',\n",
    "    'StockChart/KOSPI.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "\n",
    "print('\\n#training#')\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "result_dic={}\n",
    "evalution_costplt2=[]\n",
    "for i in range(100):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "\n",
    "    #training batch\n",
    "    for batch in kospi.getBatch('training'):\n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(\"traning_cost : \" , training_cost)\n",
    "    print(\"evalution_cost : \" , evalution_cost)\n",
    "   \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    evalution_costplt2.append(evalution_cost)\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "        i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))\n",
    "print(plt.plot(evalution_costplt2))\n",
    "\n",
    "mean(evalution_costplt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data : nasdaq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockData():\n",
    "    \"\"\"\n",
    "        훈련용 데이터세트와 평가용 데이터세트를 만들기 위한 과정.\n",
    "\n",
    "        파라미터:\n",
    "            folderPath : 종목시장의 주가 csv가 저장되어있는 디렉토리 경로.\n",
    "            indexPath : 종목시장의 인덱스 주 csv파일의 경로.\n",
    "            timewindowsize : LSTM의 입력으로 들어가는 타임의 사이즈. 10일 경우 미래주가를 예측하기 위해 이전 10일 주가를 사용.\n",
    "            windowsizeForPCC : PCC를 계산하기 위해 사용되는 타임의 사이즈. 10일 경우 관계주를 구하기 위해 이전 10일 주가를 사용.\n",
    "            PositiveStockNumber : 긍정관계주 개수.\n",
    "            NegativeStockNumber : 부정관계주 개수.\n",
    "            train_test_rate : 훈련:평가 세트 비율. 0.7일 경우 생성된 데이터 세트중 70%는 훈련용, 30%는 평가용으로 사용.\n",
    "            batchSize : 세트를 나누는 배치 사이즈.\n",
    "\n",
    "        과정:\n",
    "            종목시장의 모든 종목의 시가와 인덱스 시가를 읽어옴.\n",
    "            minmax스케일러를 각 종목과 인덱스에 적용하고 저장.\n",
    "            PCC계산, 관계주 계산.\n",
    "            데이터세트 저장.\n",
    "               \n",
    "    \"\"\"\n",
    "    def __init__(self,folderPath,indexPath,timewindowsize,windowsizeForPCC,PostiveStockNumber,NegativeStockNumber,train_test_rate,batchSize):        \n",
    "               \n",
    "        if(train_test_rate<=0 or train_test_rate>=1):\n",
    "            raise ValueError('train_test_rate should be between 0 and 1')        \n",
    "        self.P=PostiveStockNumber\n",
    "        self.N=NegativeStockNumber        \n",
    "        self.T=timewindowsize\n",
    "        self.Tr=windowsizeForPCC\n",
    "        self.folderPath = folderPath      \n",
    "        self.indexPath=indexPath    \n",
    "        self.batchSize=batchSize\n",
    "        self.date_duration=40560\n",
    "        \n",
    "        self.train_test_rate=train_test_rate\n",
    "        self.scaler=MinMaxScaler(feature_range=(-1,1))  \n",
    "        self.indexScaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "        self.indexPrice = self.loadIndex()\n",
    "        self.stockPrice = self.loadCSV()\n",
    "\n",
    "        self.trainSet,self.testSet=self.make_dataset()\n",
    "\n",
    "        self.batchNum={}\n",
    "    \n",
    "    def getBatch(self,option):\n",
    "        \"\"\"\n",
    "        클래스에 저장된 세트를 y,xp,xn,xi,target으로 나누고 batch생성.\n",
    "\n",
    "        args:\n",
    "            option='training' or 'evaluation'\n",
    "\n",
    "        returns:\n",
    "            batch 제너레이터\n",
    "            batch={'y','xp','xn','xi','target'}\n",
    "        \"\"\"\n",
    "        if(option is not 'training' and option is not 'evaluation'):\n",
    "            raise ValueError('option should be \"training\" or \"evaluation\".')\n",
    "\n",
    "        if(option is 'training'):\n",
    "            returnSet = self.trainSet\n",
    "        else:\n",
    "            returnSet = self.testSet\n",
    "        \n",
    "        y=[]\n",
    "        xp=[]\n",
    "        xn=[]\n",
    "        xi=[]\n",
    "        target=[]\n",
    "\n",
    "        for d in returnSet:\n",
    "            y.append(d['target_history'])  \n",
    "            xp.append(d['pos_history'])       \n",
    "            xn.append(d['neg_history'])       \n",
    "            xi.append(d['index_history'])       \n",
    "            target.append(d['target_price'])             \n",
    "        y=np.reshape(y,(-1,self.T,1))\n",
    "        xp=np.reshape(xp,(-1,10,self.T,1))\n",
    "        xn=np.reshape(xn,(-1,10,self.T,1))\n",
    "        xi=np.reshape(xi,(-1,self.T,1))\n",
    "        target=np.reshape(target,(-1,1))\n",
    "\n",
    "        print(\"data1 : \" , y.shape,xp.shape,xn.shape,xi.shape,target.shape)     \n",
    "\n",
    "        batchNum=int(len(y)/self.batchSize)\n",
    "        self.batchNum[option]=batchNum\n",
    "\n",
    "        for i in range(batchNum):\n",
    "            yield {'y':y[i*self.batchSize:(i+1)*self.batchSize],\n",
    "                   'xp':xp[i*self.batchSize:(i+1)*self.batchSize],\n",
    "                   'xn':xn[i*self.batchSize:(i+1)*self.batchSize],\n",
    "                   'xi':xi[i*self.batchSize:(i+1)*self.batchSize],\n",
    "                   'target':target[i*self.batchSize:(i+1)*self.batchSize]}\n",
    "\n",
    "    def loadCSV(self):\n",
    "        \"\"\"\n",
    "        csv파일이 있는 폴더를 입력으로 받아 데이터를 읽어옴.\n",
    "        \"\"\"\n",
    "        csvList=os.listdir(self.folderPath)        \n",
    "        dataframe = pd.DataFrame([])\n",
    "        \n",
    "\n",
    "        for csv in csvList:\n",
    "            data=pd.read_csv(self.folderPath+'/'+csv,engine='python')\n",
    "            if(len(data)>=self.date_duration):\n",
    "                data=data[-self.date_duration-1:-1]\n",
    "                data=data.reset_index()\n",
    "                data=data['open']\n",
    "\n",
    "                dataframe=dataframe.append(data,ignore_index=True)\n",
    "        dataT=np.array(dataframe).T\n",
    "        self.scaler.fit(dataT)\n",
    "        dataT=self.scaler.transform(dataT)\n",
    "        dataT=dataT.T\n",
    "        dataframe=pd.DataFrame(dataT)\n",
    "        dataframe=dataframe.transpose()\n",
    "        print('StockPrice shape: ',dataframe.shape)\n",
    "        return dataframe\n",
    "    \n",
    "    def loadIndex(self):\n",
    "        data=pd.read_csv(self.indexPath,engine='python')\n",
    "        data=data[-self.date_duration-1:-1]        \n",
    "        data=data.reset_index()\n",
    "        data=data.fillna(method='ffill')\n",
    "\n",
    "        data=np.array(data['Open'])\n",
    "        data=np.reshape(data,(-1,1))\n",
    "\n",
    "        data=self.indexScaler.fit_transform(data)\n",
    "\n",
    "        data=pd.DataFrame(np.squeeze(data))        \n",
    "\n",
    "        print('IndexPrice shape: ',data.shape)\n",
    "        return data \n",
    "\n",
    "\n",
    "    def make_dataset(self):\n",
    "        \"\"\"\n",
    "        예측모델에 사용되는 입력,타겟 데이터세트.\n",
    "        입력데이터의 shape는 (목표주식+관계주식+인덱스, 타임윈도우사이즈)\n",
    "        타겟데이터의 shape는 (1,1)\n",
    "        \"\"\"\n",
    "        maxday=max([self.T,self.Tr])\n",
    "        dataset=[]\n",
    "\n",
    "        for i in range(maxday,len(self.stockPrice)):\n",
    "            print('making dataset progress : {}/{}'.format(i,len(self.stockPrice)),end='\\r')\n",
    "            priceSet=self.stockPrice.loc[i-self.T:i-1]\n",
    "            targetSet=self.stockPrice.loc[i]\n",
    "            positiveSet,negativeSet=self.calculate_correlation(self.stockPrice.loc[i-maxday:i-1])\n",
    "            indexSet = self.indexPrice.loc[i-self.T:i-1]\n",
    "\n",
    "            for targetNum in priceSet.columns:\n",
    "                target_history=np.reshape(np.array(priceSet[targetNum]),(self.T,1))\n",
    "                pos_history=np.reshape(np.array(positiveSet[targetNum].T),(10,self.T,1))\n",
    "                neg_history=np.reshape(np.array(negativeSet[targetNum].T),(10,self.T,1))\n",
    "                index_history=np.reshape(np.array(indexSet),(self.T,1))\n",
    "                target_price=np.reshape(np.array(targetSet[targetNum]),(1,1))\n",
    "\n",
    "                dataset.append({'target_history':target_history,\n",
    "                                'pos_history':pos_history,\n",
    "                                'neg_history':neg_history,\n",
    "                                'index_history':index_history,\n",
    "                                'target_price':target_price\n",
    "                            })\n",
    "        print('making dataset progress : finished\\t')\n",
    "        \n",
    "        return dataset[:int(len(dataset)*self.train_test_rate)],dataset[int(len(dataset)*self.train_test_rate):]\n",
    "\n",
    "    def calculate_correlation(self,priceSet):\n",
    "        \"\"\"\n",
    "        Pearson Correlation Coefficient(PCC)를 계산하고,\n",
    "        높은순으로 긍정관계주, 낮은순으로 부정관계주를 설정한 개수만큼 생성하여 리스트에 저장한후, 리턴.\n",
    "        입력은 전체 종목의 타임윈도우간의 주가.\n",
    "\n",
    "        Returns:\n",
    "            #모든종목의 관계주. \n",
    "            긍정관계주 shape = (종목 수, dataframe(T*P))\n",
    "            부정관계주 shape = (종목 수, dataframe(T*N))\n",
    "        \"\"\"    \n",
    "        positive=[]\n",
    "        negative=[] \n",
    "        corr=priceSet[-self.Tr:].corr(method='pearson')\n",
    "\n",
    "        for i in corr.columns:\n",
    "            tempCorr=corr[i].sort_values(ascending=False)\n",
    "            index_P=tempCorr[1:self.P+1].index\n",
    "            index_N=tempCorr[-self.N:].index\n",
    "            \n",
    "            priceSet=priceSet[-self.T:]\n",
    "            posSet=priceSet[index_P]\n",
    "            negSet=priceSet[index_N]\n",
    "            posSet.columns=range(self.P)\n",
    "            negSet.columns=range(self.N)\n",
    "            \n",
    "            positive.append(posSet)\n",
    "            negative.append(negSet)\n",
    "        return positive,negative\n",
    "\n",
    "            \n",
    "\"\"\"testLine\n",
    "kospi = StockData('StockChart/SAMPLE','StockChart/KOSPI.csv',20,50,10,10,0.7)\n",
    "print(np.shape(kospi.trainSet))\n",
    "print(np.shape(kospi.testSet))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eopch : 100 , batchsize : 512 , timesize : 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "#parameter list\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=32\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=256\n",
    "#\n",
    "kospi=StockData(\n",
    "    'StockChart/SAMPLE',\n",
    "    'StockChart/KOSPI.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "\n",
    "print('\\n#training#')\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "result_dic={}\n",
    "evalution_costplt2=[]\n",
    "for i in range(100):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "\n",
    "    #training batch\n",
    "    for batch in kospi.getBatch('training'):\n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(\"traning_cost : \" , training_cost)\n",
    "    print(\"evalution_cost : \" , evalution_cost)\n",
    "   \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    evalution_costplt2.append(evalution_cost)\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "        i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))\n",
    "print(plt.plot(evalution_costplt2))\n",
    "\n",
    "mean(evalution_costplt2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
