{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/tf/lib/python3.7/site-packages/pandas_datareader/compat/__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas_datareader import data,wb\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"testLine\\nkospi = StockData('StockChart/SAMPLE','StockChart/KOSPI.csv',20,50,10,10,0.7)\\nprint(np.shape(kospi.trainSet))\\nprint(np.shape(kospi.testSet))\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class StockData():\n",
    "    \"\"\"\n",
    "        훈련용 데이터세트와 평가용 데이터세트를 만들기 위한 과정.\n",
    "\n",
    "        파라미터:\n",
    "            folderPath : 종목시장의 주가 csv가 저장되어있는 디렉토리 경로.\n",
    "            indexPath : 종목시장의 인덱스 주 csv파일의 경로.\n",
    "            timewindowsize : LSTM의 입력으로 들어가는 타임의 사이즈. 10일 경우 미래주가를 예측하기 위해 이전 10일 주가를 사용.\n",
    "            windowsizeForPCC : PCC를 계산하기 위해 사용되는 타임의 사이즈. 10일 경우 관계주를 구하기 위해 이전 10일 주가를 사용.\n",
    "            PositiveStockNumber : 긍정관계주 개수.\n",
    "            NegativeStockNumber : 부정관계주 개수.\n",
    "            train_test_rate : 훈련:평가 세트 비율. 0.7일 경우 생성된 데이터 세트중 70%는 훈련용, 30%는 평가용으로 사용.\n",
    "            batchSize : 세트를 나누는 배치 사이즈.\n",
    "\n",
    "        과정:\n",
    "            종목시장의 모든 종목의 시가와 인덱스 시가를 읽어옴.\n",
    "            minmax스케일러를 각 종목과 인덱스에 적용하고 저장.\n",
    "            PCC계산, 관계주 계산.\n",
    "            데이터세트 저장.\n",
    "               \n",
    "    \"\"\"\n",
    "    def __init__(self,folderPath,indexPath,timewindowsize,windowsizeForPCC,PostiveStockNumber,NegativeStockNumber,train_test_rate,batchSize):        \n",
    "               \n",
    "        if(train_test_rate<=0 or train_test_rate>=1):\n",
    "            raise ValueError('train_test_rate should be between 0 and 1')        \n",
    "        self.P=PostiveStockNumber\n",
    "        self.N=NegativeStockNumber        \n",
    "        self.T=timewindowsize\n",
    "        self.Tr=windowsizeForPCC\n",
    "        self.folderPath = folderPath      \n",
    "        self.indexPath=indexPath    \n",
    "        self.batchSize=batchSize\n",
    "        self.date_duration=40560\n",
    "        \n",
    "        self.train_test_rate=train_test_rate\n",
    "        self.scaler=MinMaxScaler(feature_range=(-1,1))  \n",
    "        self.indexScaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "        self.indexPrice = self.loadIndex()\n",
    "        self.stockPrice = self.loadCSV()\n",
    "\n",
    "        self.trainSet,self.testSet=self.make_dataset()\n",
    "\n",
    "        self.batchNum={}\n",
    "    \n",
    "    def getBatch(self,option):\n",
    "        \"\"\"\n",
    "        클래스에 저장된 세트를 y,xp,xn,xi,target으로 나누고 batch생성.\n",
    "\n",
    "        args:\n",
    "            option='training' or 'evaluation'\n",
    "\n",
    "        returns:\n",
    "            batch 제너레이터\n",
    "            batch={'y','xp','xn','xi','target'}\n",
    "        \"\"\"\n",
    "        if(option is not 'training' and option is not 'evaluation'):\n",
    "            raise ValueError('option should be \"training\" or \"evaluation\".')\n",
    "\n",
    "        if(option is 'training'):\n",
    "            returnSet = self.trainSet\n",
    "        else:\n",
    "            returnSet = self.testSet\n",
    "        \n",
    "        y=[]\n",
    "        xp=[]\n",
    "        xn=[]\n",
    "        xi=[]\n",
    "        target=[]\n",
    "\n",
    "        for d in returnSet:\n",
    "            y.append(d['target_history'])  \n",
    "            xp.append(d['pos_history'])       \n",
    "            xn.append(d['neg_history'])       \n",
    "            xi.append(d['index_history'])       \n",
    "            target.append(d['target_price'])             \n",
    "        y=np.reshape(y,(-1,self.T,1))\n",
    "        xp=np.reshape(xp,(-1,10,self.T,1))\n",
    "        xn=np.reshape(xn,(-1,10,self.T,1))\n",
    "        xi=np.reshape(xi,(-1,self.T,1))\n",
    "        target=np.reshape(target,(-1,1))\n",
    "\n",
    "        print(y.shape,xp.shape,xn.shape,xi.shape,target.shape)     \n",
    "\n",
    "        batchNum=int(len(y)/self.batchSize)\n",
    "        self.batchNum[option]=batchNum\n",
    "\n",
    "        for i in range(batchNum):\n",
    "            yield {'y':y[i*self.batchSize:(i+1)*self.batchSize].astype(np.float32),\n",
    "                   'xp':xp[i*self.batchSize:(i+1)*self.batchSize].astype(np.float32),\n",
    "                   'xn':xn[i*self.batchSize:(i+1)*self.batchSize].astype(np.float32),\n",
    "                   'xi':xi[i*self.batchSize:(i+1)*self.batchSize].astype(np.float32),\n",
    "                   'target':target[i*self.batchSize:(i+1)*self.batchSize].astype(np.float32)}\n",
    "\n",
    "    def loadCSV(self):\n",
    "        \"\"\"\n",
    "        csv파일이 있는 폴더를 입력으로 받아 데이터를 읽어옴.\n",
    "        \"\"\"\n",
    "        csvList=os.listdir(self.folderPath)        \n",
    "        dataframe = pd.DataFrame([])\n",
    "        \n",
    "\n",
    "        for csv in csvList:\n",
    "            data=pd.read_csv(self.folderPath+'/'+csv,engine='python')\n",
    "            if(len(data)>=self.date_duration):\n",
    "                data=data[-self.date_duration-1:-1]\n",
    "                data=data.reset_index()\n",
    "                data=data['open']\n",
    "\n",
    "                dataframe=dataframe.append(data,ignore_index=True)\n",
    "        dataT=np.array(dataframe).T\n",
    "        self.scaler.fit(dataT)\n",
    "        dataT=self.scaler.transform(dataT)\n",
    "        dataT=dataT.T\n",
    "        dataframe=pd.DataFrame(dataT)\n",
    "        dataframe=dataframe.transpose()\n",
    "        print('StockPrice shape: ',dataframe.shape)\n",
    "        return dataframe\n",
    "    \n",
    "    def loadIndex(self):\n",
    "        data=pd.read_csv(self.indexPath,engine='python')\n",
    "        data=data[-self.date_duration-1:-1]        \n",
    "        data=data.reset_index()\n",
    "        data=data.fillna(method='ffill')\n",
    "\n",
    "        data=np.array(data['Open'])\n",
    "        data=np.reshape(data,(-1,1))\n",
    "\n",
    "        data=self.indexScaler.fit_transform(data)\n",
    "\n",
    "        data=pd.DataFrame(np.squeeze(data))        \n",
    "\n",
    "        print('IndexPrice shape: ',data.shape)\n",
    "        return data \n",
    "\n",
    "\n",
    "    def make_dataset(self):\n",
    "        \"\"\"\n",
    "        예측모델에 사용되는 입력,타겟 데이터세트.\n",
    "        입력데이터의 shape는 (목표주식+관계주식+인덱스, 타임윈도우사이즈)\n",
    "        타겟데이터의 shape는 (1,1)\n",
    "        \"\"\"\n",
    "        maxday=max([self.T,self.Tr])\n",
    "        dataset=[]\n",
    "\n",
    "        for i in range(maxday,len(self.stockPrice)):\n",
    "            print('making dataset progress : {}/{}'.format(i,len(self.stockPrice)),end='\\r')\n",
    "            priceSet=self.stockPrice.loc[i-self.T:i-1]\n",
    "            targetSet=self.stockPrice.loc[i]\n",
    "            positiveSet,negativeSet=self.calculate_correlation(self.stockPrice.loc[i-maxday:i-1])\n",
    "            indexSet = self.indexPrice.loc[i-self.T:i-1]\n",
    "\n",
    "            for targetNum in priceSet.columns:\n",
    "                target_history=np.reshape(np.array(priceSet[targetNum]),(self.T,1))\n",
    "                pos_history=np.reshape(np.array(positiveSet[targetNum].T),(10,self.T,1))\n",
    "                neg_history=np.reshape(np.array(negativeSet[targetNum].T),(10,self.T,1))\n",
    "                index_history=np.reshape(np.array(indexSet),(self.T,1))\n",
    "                target_price=np.reshape(np.array(targetSet[targetNum]),(1,1))\n",
    "\n",
    "                dataset.append({'target_history':target_history,\n",
    "                                'pos_history':pos_history,\n",
    "                                'neg_history':neg_history,\n",
    "                                'index_history':index_history,\n",
    "                                'target_price':target_price\n",
    "                            })\n",
    "        print('making dataset progress : finished\\t')\n",
    "        \n",
    "        return dataset[:int(len(dataset)*self.train_test_rate)],dataset[int(len(dataset)*self.train_test_rate):]\n",
    "\n",
    "    def calculate_correlation(self,priceSet):\n",
    "        \"\"\"\n",
    "        Pearson Correlation Coefficient(PCC)를 계산하고,\n",
    "        높은순으로 긍정관계주, 낮은순으로 부정관계주를 설정한 개수만큼 생성하여 리스트에 저장한후, 리턴.\n",
    "        입력은 전체 종목의 타임윈도우간의 주가.\n",
    "\n",
    "        Returns:\n",
    "            #모든종목의 관계주. \n",
    "            긍정관계주 shape = (종목 수, dataframe(T*P))\n",
    "            부정관계주 shape = (종목 수, dataframe(T*N))\n",
    "        \"\"\"    \n",
    "        positive=[]\n",
    "        negative=[] \n",
    "        corr=priceSet[-self.Tr:].corr(method='pearson')\n",
    "\n",
    "        for i in corr.columns:\n",
    "            tempCorr=corr[i].sort_values(ascending=False)\n",
    "            index_P=tempCorr[1:self.P+1].index\n",
    "            index_N=tempCorr[-self.N:].index\n",
    "            \n",
    "            priceSet=priceSet[-self.T:]\n",
    "            posSet=priceSet[index_P]\n",
    "            negSet=priceSet[index_N]\n",
    "            posSet.columns=range(self.P)\n",
    "            negSet.columns=range(self.N)\n",
    "            \n",
    "            positive.append(posSet)\n",
    "            negative.append(negSet)\n",
    "        return positive,negative\n",
    "\n",
    "            \n",
    "\"\"\"testLine\n",
    "kospi = StockData('StockChart/SAMPLE','StockChart/KOSPI.csv',20,50,10,10,0.7)\n",
    "print(np.shape(kospi.trainSet))\n",
    "print(np.shape(kospi.testSet))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn=tf.compat.v1.nn.rnn_cell\n",
    "class base_LSTMCell(rnn.BasicLSTMCell):\n",
    "    def __call__(self,inputs,state,scope=None):\n",
    "        \"\"\"Long short-term memory cell (LSTM).\"\"\"\n",
    "        with tf.variable_scope(scope or type(self).__name__):  # \"BasicLSTMCell\"\n",
    "        # Parameters of gates are concatenated into one multiply for efficiency.\n",
    "            if self._state_is_tuple:\n",
    "                c, h = state\n",
    "            else:\n",
    "                c, h = tf.split(1, 2, state)\n",
    "            concat = tf.layers.dense(tf.concat([inputs, h],axis=1), 4 * self._num_units)\n",
    "\n",
    "            # i = input_gate, j = new_input, f = forget_gate, o = output_gate\n",
    "            i, j, f, o = tf.split(concat, 4, 1)\n",
    "\n",
    "            new_c = (c * tf.sigmoid(f + self._forget_bias) + tf.sigmoid(i) *\n",
    "                    self._activation(j))\n",
    "            new_h = self._activation(new_c) * tf.sigmoid(o)\n",
    "\n",
    "            if self._state_is_tuple:\n",
    "                new_state = rnn.LSTMStateTuple(new_c, new_h)\n",
    "            else:\n",
    "                new_state = tf.concat(1, [new_c, new_h])\n",
    "        return new_h, new_state\n",
    "\n",
    "class MI_LSTMCell(rnn.BasicLSTMCell):\n",
    "    \"\"\"\n",
    "    Multi-Input LSTM proposed in the paper, Stock Price Prediction Using Attention-based Multi-Input LSTM.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "               num_units,\n",
    "               num_inputs,\n",
    "               forget_bias=1.0,\n",
    "               state_is_tuple=True,\n",
    "               activation=None,\n",
    "               reuse=None,\n",
    "               name=None,\n",
    "               dtype=None,\n",
    "               **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize the basic LSTM cell.\n",
    "        args:\n",
    "            num_inputs: MI-LSTM의 입력의 개수. \n",
    "                이 파라미터에 따라 입력 게이트의 어텐션 레이어를 설정.\n",
    "                최소 1개이상.\n",
    "                1개일 경우, 어텐션 레이어를 제외하고 기본 LSTM과 동일.\n",
    "        \"\"\"        \n",
    "        super(MI_LSTMCell,self).__init__(num_units,\n",
    "               forget_bias=1.0,\n",
    "               state_is_tuple=True,\n",
    "               activation=None,\n",
    "               reuse=None,\n",
    "               name=None,\n",
    "               dtype=None,\n",
    "               **kwargs)\n",
    "        \n",
    "        if(type(num_inputs) is not int):\n",
    "            raise ValueError(\"num_inputs should be integer\")\n",
    "        if(num_inputs < 1):\n",
    "            raise ValueError(\"num_inputs should not be less than 0\")\n",
    "        self.num_inputs = num_inputs\n",
    "        self.alpha_weight=self.add_variable('alpha_weight',shape=[self._num_units,self._num_units])\n",
    "        self.alpha_bias=[]\n",
    "        for i in range(self.num_inputs):\n",
    "            self.alpha_bias.append(self.add_variable('alpha_bias'+str(i),shape=[1],initializer=tf.zeros_initializer()))\n",
    "\n",
    "    def __call__(self,inputs,state,scope=None):\n",
    "        \"\"\"Long short-term memory cell (LSTM).\"\"\"\n",
    "        with tf.compat.v1.variable_scope(scope or type(self).__name__ ):  # \"BasicLSTMCell\"\n",
    "        # Parameters of gates are concatenated into one multiply for efficiency.\n",
    "            if self._state_is_tuple:\n",
    "                c, h = state\n",
    "            else:\n",
    "                c, h = tf.split(1, 2, state)\n",
    "            inputs_list = tf.split(inputs,self.num_inputs,1)\n",
    "            concat = tf.compat.v1.layers.dense(tf.concat([inputs_list[0], h],axis=1), (3+self.num_inputs) * self._num_units)\n",
    "                                 \n",
    "            # 0 = forget_gate, 1 = output_gate, 2= main_new_input, 3 = main_input_gate, 4~ = input_gate_for_auxiliary\n",
    "            main_list = tf.split(concat, 3+self.num_inputs, 1)\n",
    "                        \n",
    "            #new_input_gate= list of all new_input.\n",
    "            new_input_gate=[tf.tanh(main_list[2])]\n",
    "            #linear layer for auxiliary inputs.\n",
    "            for i in range(1,self.num_inputs):\n",
    "                new_input_gate.append(tf.compat.v1.layers.dense(tf.concat([inputs_list[i], h],axis=1),self._num_units,activation=tf.tanh))\n",
    "\n",
    "            #making list of l. l = sigmoid(input_gate) * tanh(new_input)\n",
    "            new_l=[]\n",
    "            for i,new_input in enumerate(new_input_gate,3):\n",
    "                new_l.append(tf.sigmoid(main_list[i]) * new_input)\n",
    "\n",
    "\n",
    "            #making list of u.            \n",
    "            u=[]\n",
    "            for i,l in enumerate(new_l):\n",
    "                #temp = transpos(l) X W X Cell_State.\n",
    "                temp1=tf.matmul(l,self.alpha_weight)\n",
    "                temp1=tf.expand_dims(temp1,1)\n",
    "                temp2=tf.matmul(temp1,tf.expand_dims(c,2))\n",
    "                u.append(tf.tanh(tf.squeeze(temp2+self.alpha_bias[i],axis=2)))\n",
    "\n",
    "            #making list of alpha.\n",
    "            alpha=tf.nn.softmax(u,axis=0)\n",
    "\n",
    "            #making L.\n",
    "            L=[]\n",
    "            for i,l in enumerate(new_l):\n",
    "                L.append(alpha[i]*l)\n",
    "            L=tf.reduce_sum(L,axis=0)\n",
    "\n",
    "\n",
    "            #new state = c(t-1) * f + L. new h = tanh(c) + sigmoid(o)\n",
    "            new_c = (c * tf.sigmoid(main_list[0] + self._forget_bias)+L)\n",
    "            new_h = self._activation(new_c) * tf.sigmoid(main_list[1])\n",
    "\n",
    "            if self._state_is_tuple:\n",
    "                new_state = rnn.LSTMStateTuple(new_c, new_h)\n",
    "            else:\n",
    "                new_state = tf.concat(1, [new_c, new_h])\n",
    "        return new_h, new_state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "class Attention(keras.Model):\n",
    "    def __init__(self, input_dim, var_scope, reuse=True):\n",
    "        super(Attention, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        with tf.compat.v1.variable_scope(var_scope, reuse=reuse):\n",
    "            self.attention_w = layers.Dense(self.input_dim, name='W')\n",
    "            self.attention_u = layers.Dense(self.input_dim, name='U')\n",
    "            self.attention_v = layers.Dense(1, name='V')\n",
    "\n",
    "    def call(self, input_x, prev_state_tuple):\n",
    "        \"\"\"\n",
    "        Compute the attention weight for input series\n",
    "        hidden_state, cell_state (batch_size, hidden_dim)\n",
    "        input_x (batch_size, num_series, input_dim),\n",
    "        input_dim = num_steps for input attention\n",
    "        \"\"\"\n",
    "        prev_hidden_state, prev_cell_state = prev_state_tuple\n",
    "\n",
    "        # (batch_size, 1, hidden_dim * 2)\n",
    "        concat_state = tf.expand_dims(tf.concat([prev_hidden_state, prev_cell_state], axis=-1),\n",
    "                                      axis=1)\n",
    "\n",
    "        # (batch_size, num_series, input_dim)\n",
    "        score_ = self.attention_w(concat_state) + self.attention_u(input_x)\n",
    "\n",
    "        # (batch_size, num_series, 1)\n",
    "        # Equation (8)\n",
    "        score = self.attention_v(tf.nn.tanh(score_))\n",
    "\n",
    "        # (batch_size, num_series)\n",
    "        # Equation (9)\n",
    "        weight = tf.squeeze(tf.nn.softmax(score, axis=1), axis=-1)\n",
    "\n",
    "        return weight\n",
    "\n",
    "\n",
    "class LSTMCell(keras.Model):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_fc = layers.Dense(self.hidden_dim)\n",
    "\n",
    "    def call(self, input_x, prev_state_tuple):\n",
    "        \"\"\" Return next step's hidden state and cell state  \"\"\"\n",
    "        hidden_state, cell_state = prev_state_tuple\n",
    "\n",
    "        # (batch_size, hidden_dim + input_dim)\n",
    "        concat_input = tf.concat([hidden_state, input_x], axis=-1)\n",
    "\n",
    "        # (batch_size * 4, hidden_dim + input_dim)\n",
    "        concat_input_tiled = tf.tile(concat_input, [4, 1])\n",
    "\n",
    "        # Equation (3) - (6) without activation\n",
    "        forget_, input_, output_, cell_bar = tf.split(self.layer_fc(concat_input_tiled),\n",
    "                                                      axis=0,\n",
    "                                                      num_or_size_splits=4)\n",
    "\n",
    "        # (batch_size, hidden_dim)\n",
    "        # Equation (6)\n",
    "        cell_state = tf.nn.sigmoid(forget_) * cell_state + \\\n",
    "                     tf.nn.sigmoid(input_) * tf.nn.tanh(cell_bar)\n",
    "\n",
    "        # Equation (7)\n",
    "        hidden_state = tf.nn.sigmoid(output_) * tf.nn.tanh(cell_state)\n",
    "        return (hidden_state, cell_state)\n",
    "\n",
    "\n",
    "class Encoder(keras.Model):\n",
    "    def __init__(self, encoder_dim, num_steps):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder_dim = encoder_dim\n",
    "        self.attention_layer = Attention(num_steps, var_scope='input_attention')\n",
    "        self.lstm_cell = LSTMCell(encoder_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        inputs: (batch_size, num_steps, num_series)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        def one_step(prev_state_tuple, current_input):\n",
    "            \"\"\" Move along the time axis by one step  \"\"\"\n",
    "\n",
    "            # (batch_size, num_series, num_steps)\n",
    "            inputs_scan = tf.transpose(inputs, perm=[0, 2, 1])\n",
    "\n",
    "            # (batch_size, num_series)\n",
    "            weight = self.attention_layer(inputs_scan, prev_state_tuple)\n",
    "\n",
    "            weighted_current_input = weight * current_input\n",
    "\n",
    "            return self.lstm_cell(weighted_current_input, prev_state_tuple)\n",
    "\n",
    "        # Get the batch size from inputs\n",
    "        self.batch_size = tf.shape(inputs)[0]\n",
    "        self.num_steps = inputs.get_shape().as_list()[1]\n",
    "\n",
    "        self.init_hidden_state = tf.random.truncated_normal([self.batch_size, self.encoder_dim])\n",
    "        self.init_cell_state = tf.random.truncated_normal([self.batch_size, self.encoder_dim])\n",
    "\n",
    "        # (num_steps, batch_size, num_series)\n",
    "        inputs_ = tf.transpose(inputs, perm=[1, 0, 2])\n",
    "\n",
    "        # use scan to run over all time steps\n",
    "        state_tuple = tf.scan(one_step,\n",
    "                              elems=inputs_,\n",
    "                              initializer=(self.init_hidden_state,\n",
    "                                           self.init_cell_state))\n",
    "\n",
    "        # (batch_size, num_steps, encoder_dim)\n",
    "        all_hidden_state = tf.transpose(state_tuple[0], perm=[1, 0, 2])\n",
    "        return all_hidden_state\n",
    "\n",
    "\n",
    "class Decoder(keras.Model):\n",
    "    def __init__(self, decoder_dim, num_steps):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder_dim = decoder_dim\n",
    "        self.attention_layer = Attention(num_steps, var_scope='temporal_attention')\n",
    "        self.lstm_cell = LSTMCell(decoder_dim)\n",
    "        self.layer_fc_context = layers.Dense(1)\n",
    "        self.layer_prediction_fc_1 = layers.Dense(decoder_dim)\n",
    "        self.layer_prediction_fc_2 = layers.Dense(decoder_dim/2)\n",
    "        self.layer_prediction_fc_3 = layers.Dense(1)\n",
    "\n",
    "    def call(self, encoder_states, inputs, labels):\n",
    "        \"\"\"\n",
    "        encoder_states: (batch_size, num_steps, encoder_dim)\n",
    "        labels: (batch_size, num_steps)\n",
    "        \"\"\"\n",
    "\n",
    "        def one_step(accumulator, current_label):\n",
    "            \"\"\" Move along the time axis by one step  \"\"\"\n",
    "            #inputs_scan2 = tf.transpose(inputs, perm=[0, 2, 1])\n",
    "            \n",
    "            prev_state_tuple, context = accumulator\n",
    "            # (batch_size, num_steps)\n",
    "            # Equation (12) (13)\n",
    "            print(\"inputs : \" , inputs )\n",
    "            weight = self.attention_layer(inputs, prev_state_tuple)\n",
    "            print(\"weight : \" , weight )\n",
    "\n",
    "            # Equation (14)\n",
    "            # (batch_size, encoder_dim)\n",
    "            print(\"encoder_states : \" , encoder_states)\n",
    "            context = tf.reduce_sum(tf.expand_dims(weight, axis=-1) * encoder_states,\n",
    "                                    axis=1)\n",
    "\n",
    "            # Equation (15)\n",
    "            # (batch_size, 1)\n",
    "            y_tilde = self.layer_fc_context(tf.concat([current_label, context], axis=-1))\n",
    "\n",
    "            # Equation (16)\n",
    "            return self.lstm_cell(y_tilde, prev_state_tuple), context\n",
    "\n",
    "        # Get the batch size from inputs\n",
    "        self.batch_size = tf.shape(encoder_states)[0]\n",
    "        self.num_steps = encoder_states.get_shape().as_list()[1]\n",
    "        self.encoder_dim = encoder_states.get_shape().as_list()[-1]\n",
    "\n",
    "        init_hidden_state = tf.random.truncated_normal([self.batch_size, self.decoder_dim])\n",
    "        init_cell_state = tf.random.truncated_normal([self.batch_size, self.decoder_dim])\n",
    "        init_context = tf.random.truncated_normal([self.batch_size, self.encoder_dim])\n",
    "\n",
    "        # (num_steps, batch_size, num_series)\n",
    "        inputs_ = tf.transpose(encoder_states, perm=[1, 0, 2])\n",
    "\n",
    "        # use scan to run over all time steps\n",
    "        state_tuple, all_context = tf.scan(one_step,\n",
    "                                           elems=inputs_,\n",
    "                                           initializer=((init_hidden_state,\n",
    "                                                        init_cell_state),\n",
    "                                                        init_context))\n",
    "\n",
    "        # (batch_size, num_steps, decoder_dim)\n",
    "        all_hidden_state = tf.transpose(state_tuple[0], perm=[1, 0, 2])\n",
    "\n",
    "        # (batch_size, num_steps, encoder_dim)\n",
    "        all_context = tf.transpose(all_context, perm=[1, 0, 2])\n",
    "\n",
    "        last_hidden_state = all_hidden_state[:, -1, :]\n",
    "        last_context = all_context[:, -1, :]\n",
    "\n",
    "        # (batch_size, 1)\n",
    "        # Equation (22)\n",
    "        pred_ = self.layer_prediction_fc_1(tf.concat([last_hidden_state, last_context], axis=-1))\n",
    "        pred__ = self.layer_prediction_fc_2(pred_)\n",
    "        pred= self.layer_prediction_fc_3(pred__)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DARNN():\n",
    "    def __init__(self,  num_series, encoder_dim, decoder_dim, num_steps, stateful_encoder=False, stateful_decoder=False):\n",
    "        super(self.__class__, self).__init__()\n",
    "        encoder_steps=num_steps+1\n",
    "        self.encoder = Encoder(encoder_dim, encoder_steps)\n",
    "\n",
    "        self.decoder = Decoder(decoder_dim, num_steps)\n",
    "    def __call__(self, X_history, y_history):\n",
    "        out =self.decoder(self.encoder(X_history),X_history, y_history) \n",
    "        #TemporalAttentionDecoder.forward(id(self.decoder),InputAttentionEncoder.forward(id(self.encoder),X_history), X_history,y_history)\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    \"\"\"\n",
    "    모든 예측모델들의 기본 클래스\n",
    "    \"\"\"\n",
    "    def __init__(self,sess,name,windowsize,Pos,Neg):\n",
    "        self.sess=sess\n",
    "        self.name=name\n",
    "        self.T=windowsize\n",
    "        self.P=Pos\n",
    "        self.N=Neg\n",
    "\n",
    "        \n",
    "        self._build_net()\n",
    "\n",
    "    def _build_net(self):\n",
    "        pass\n",
    "\n",
    "class LSTM_Model(Model):\n",
    "    \"\"\"\n",
    "    Basic LSTM list for test.\n",
    "    \"\"\"\n",
    "    def _build_net(self):\n",
    "       \n",
    "        #tf. compat.v1.reset_default_graph()\n",
    "        self.Y=tf.compat.v1.placeholder(tf.float32,[None,self.T,1])\n",
    "        self.Xp=tf.compat.v1.placeholder(tf.float32,[None,self.P,self.T,1])\n",
    "        self.Xn=tf.compat.v1.placeholder(tf.float32,[None,self.N,self.T,1])\n",
    "        self.Xi=tf.compat.v1.placeholder(tf.float32,[None,self.T,1])\n",
    "        self.Target=tf.compat.v1.placeholder(tf.float32,[None,1])\n",
    "\n",
    "\n",
    "        Xps=tf.split(self.Xp,self.P,1)\n",
    "        Xns=tf.split(self.Xn,self.N,1)\n",
    "        Xp_list=[]\n",
    "        Xn_list=[]\n",
    "\n",
    "    \n",
    "        LSTM=tf.compat.v1.nn.rnn_cell.LSTMCell(64,name='lstm1')\n",
    "        \n",
    "        Y_1,_=tf.compat.v1.nn.dynamic_rnn(LSTM,self.Y,dtype=tf.float32)\n",
    "        Xi_1,_=tf.compat.v1.nn.dynamic_rnn(LSTM,self.Xi,dtype=tf.float32)\n",
    "        for i in range(len(Xps)):\n",
    "            o,_=tf.compat.v1.nn.dynamic_rnn(LSTM,tf.squeeze(Xps[i],axis=1),dtype=tf.float32)\n",
    "            Xp_list.append(o)\n",
    "        for i in range(len(Xns)):\n",
    "            o,_=tf.compat.v1.nn.dynamic_rnn(LSTM,tf.squeeze(Xns[i],axis=1),dtype=tf.float32)\n",
    "            Xn_list.append(o)\n",
    "        Xp_1=tf.reduce_mean(Xp_list,0)\n",
    "        Xn_1=tf.reduce_mean(Xn_list,0)\n",
    "\n",
    "        result=tf.concat([Y_1,Xp_1,Xn_1,Xi_1],axis=2)\n",
    "        print(\"result = \" , result)\n",
    "\n",
    "        #MI-LSTM\n",
    "        LSTM2=MI_LSTMCell(64,4,name='lstm2')\n",
    "        print(\"LSTM2 = \" , LSTM2)\n",
    "        Y_2,_ =tf.compat.v1.nn.dynamic_rnn(LSTM2,result,dtype=tf.float32)\n",
    "        print(\"Y_2 = \" , Y_2.shape)\n",
    "\n",
    "        #Attention_Layer\n",
    "        \n",
    "        \n",
    "        model = DARNN(64, 64, 64, self.T) \n",
    "        y_pred = model(Y_2, self.Y) \n",
    "        print(\"y_pred : \" , y_pred )\n",
    "        #y_pred = tf.squeeze(y_pred)\n",
    "        #print(\"y_pred : \" , y_pred )\n",
    "\n",
    "        #Non-linear units for producing final prediction.\n",
    "       \n",
    "\n",
    "        self.out=y_pred\n",
    "        #self.out=Y_2\n",
    "        \n",
    "        self.cost=tf.compat.v1.losses.mean_squared_error(labels=self.Target,predictions=self.out)\n",
    "        self.optimizer=tf.compat.v1.train.AdamOptimizer(0.001).minimize(self.cost)\n",
    "\n",
    "    def outputs(self,y,xp,xn,xi,target):\n",
    "        fd={self.Y:y,self.Xp:xp,self.Xn:xn,self.Xi:xi,self.Target:target}\n",
    "        return self.sess.run(self.out,feed_dict=fd)\n",
    "    \n",
    "\n",
    "\n",
    "    def training(self,y,xp,xn,xi,target):\n",
    "        fd={self.Y:y,self.Xp:xp,self.Xn:xn,self.Xi:xi,self.Target:target}\n",
    "        return self.sess.run([self.cost,self.optimizer],feed_dict=fd)\n",
    "\n",
    "    def returnCost(self,y,xp,xn,xi,target):\n",
    "        fd={self.Y:y,self.Xp:xp,self.Xn:xn,self.Xi:xi,self.Target:target}\n",
    "        return self.sess.run(self.cost,feed_dict=fd)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## epoch : 100 , batchsize : 512 , timesize : 16\n",
    "## timesize_for_calc_correlation=100\n",
    "## positive_correlation_stock_num=10\n",
    "## negative_correlation_sotck_num=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexPrice shape:  (40559, 1)\n",
      "StockPrice shape:  (40559, 81)\n",
      "making dataset progress : finished\t59\n",
      "WARNING:tensorflow:From <ipython-input-6-5e94407ee4da>:38: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-6-5e94407ee4da>:40: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "result =  Tensor(\"concat:0\", shape=(None, 16, 256), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-3-a8129d876eea>:55: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "LSTM2 =  <__main__.MI_LSTMCell object at 0x7f7f29830450>\n",
      "WARNING:tensorflow:From <ipython-input-3-a8129d876eea>:76: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "Y_2 =  (None, 16, 64)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f7f297e4410>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f7f295d3e90>, <gast.gast.Return object at 0x7f7f295d3f10>]\n",
      "WARNING: AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f7f297e4410>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f7f295d3e90>, <gast.gast.Return object at 0x7f7f295d3f10>]\n",
      "inputs :  Tensor(\"rnn_22/transpose_1:0\", shape=(None, 16, 64), dtype=float32)\n",
      "weight :  Tensor(\"attention_1/Squeeze:0\", shape=(None, 16), dtype=float32)\n",
      "encoder_states :  Tensor(\"encoder/transpose_1:0\", shape=(None, 16, 64), dtype=float32)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f7f29739250>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f7f29287a10>, <gast.gast.Return object at 0x7f7f29287950>]\n",
      "WARNING: AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f7f29739250>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f7f29287a10>, <gast.gast.Return object at 0x7f7f29287950>]\n",
      "y_pred :  Tensor(\"decoder/dense_5/BiasAdd:0\", shape=(None, 1), dtype=float32)\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "19.27176607861111\n",
      "623.46863889003\n",
      "epoch : 0, t_cost : 0.004302, e_cost : 0.324723, elapsed time : 802.98sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "5.272112489517895\n",
      "306.9796388821633\n",
      "epoch : 1, t_cost : 0.001177, e_cost : 0.159885, elapsed time : 796.99sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "3.6381043772926205\n",
      "192.9746839872023\n",
      "epoch : 2, t_cost : 0.000812, e_cost : 0.100508, elapsed time : 796.87sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "2.3058188230497763\n",
      "127.31486454072729\n",
      "epoch : 3, t_cost : 0.000515, e_cost : 0.066310, elapsed time : 797.09sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "1.4584700405666808\n",
      "86.88075818175275\n",
      "epoch : 4, t_cost : 0.000326, e_cost : 0.045250, elapsed time : 797.18sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.9812436739566692\n",
      "63.47437259416438\n",
      "epoch : 5, t_cost : 0.000219, e_cost : 0.033060, elapsed time : 797.06sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.7524243977077276\n",
      "47.62314354017872\n",
      "epoch : 6, t_cost : 0.000168, e_cost : 0.024804, elapsed time : 797.28sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.6464320041436622\n",
      "39.96989243772623\n",
      "epoch : 7, t_cost : 0.000144, e_cost : 0.020818, elapsed time : 797.47sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.6064596528149195\n",
      "37.193913645418434\n",
      "epoch : 8, t_cost : 0.000135, e_cost : 0.019372, elapsed time : 797.29sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.5919299795978077\n",
      "35.1931808305053\n",
      "epoch : 9, t_cost : 0.000132, e_cost : 0.018330, elapsed time : 797.23sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.5697639065383555\n",
      "34.2371088022428\n",
      "epoch : 10, t_cost : 0.000127, e_cost : 0.017832, elapsed time : 797.50sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.5372706665075384\n",
      "29.872236636341768\n",
      "epoch : 11, t_cost : 0.000120, e_cost : 0.015558, elapsed time : 797.30sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.5193654553345368\n",
      "30.79710248246556\n",
      "epoch : 12, t_cost : 0.000116, e_cost : 0.016040, elapsed time : 797.29sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.4986850180248439\n",
      "27.21693865092311\n",
      "epoch : 13, t_cost : 0.000111, e_cost : 0.014175, elapsed time : 797.21sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.4769641525758743\n",
      "27.420089892528267\n",
      "epoch : 14, t_cost : 0.000106, e_cost : 0.014281, elapsed time : 797.40sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.4712138525505907\n",
      "24.20151381362666\n",
      "epoch : 15, t_cost : 0.000105, e_cost : 0.012605, elapsed time : 797.41sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.45578262144226755\n",
      "23.91064133580221\n",
      "epoch : 16, t_cost : 0.000102, e_cost : 0.012453, elapsed time : 797.90sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.4506245734555705\n",
      "22.71208808564006\n",
      "epoch : 17, t_cost : 0.000101, e_cost : 0.011829, elapsed time : 798.18sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.4386409599542276\n",
      "22.44712483540752\n",
      "epoch : 18, t_cost : 0.000098, e_cost : 0.011691, elapsed time : 798.42sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.43465145106438285\n",
      "21.66839615759818\n",
      "epoch : 19, t_cost : 0.000097, e_cost : 0.011286, elapsed time : 798.46sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.42249610536646287\n",
      "20.612841670508715\n",
      "epoch : 20, t_cost : 0.000094, e_cost : 0.010736, elapsed time : 798.03sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.41372497390057106\n",
      "20.53436641886219\n",
      "epoch : 21, t_cost : 0.000092, e_cost : 0.010695, elapsed time : 797.91sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.4060161625961882\n",
      "23.116395140148597\n",
      "epoch : 22, t_cost : 0.000091, e_cost : 0.012040, elapsed time : 798.19sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.40436640318102945\n",
      "68.1340718464271\n",
      "epoch : 23, t_cost : 0.000090, e_cost : 0.035486, elapsed time : 798.15sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.4022848181025438\n",
      "20.002530568430302\n",
      "epoch : 24, t_cost : 0.000090, e_cost : 0.010418, elapsed time : 798.07sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3914400263188327\n",
      "33.32465974065781\n",
      "epoch : 25, t_cost : 0.000087, e_cost : 0.017357, elapsed time : 798.11sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.38535573696026404\n",
      "20.804850928694577\n",
      "epoch : 26, t_cost : 0.000086, e_cost : 0.010836, elapsed time : 798.14sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3829686304147799\n",
      "26.53312187261872\n",
      "epoch : 27, t_cost : 0.000085, e_cost : 0.013819, elapsed time : 798.21sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.38190330890893165\n",
      "43.15760383210545\n",
      "epoch : 28, t_cost : 0.000085, e_cost : 0.022478, elapsed time : 797.99sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.37669710014324664\n",
      "29.765558086146484\n",
      "epoch : 29, t_cost : 0.000084, e_cost : 0.015503, elapsed time : 798.07sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3779563656485152\n",
      "66.14092076212546\n",
      "epoch : 30, t_cost : 0.000084, e_cost : 0.034448, elapsed time : 798.12sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3757620797232448\n",
      "50.643661933003386\n",
      "epoch : 31, t_cost : 0.000084, e_cost : 0.026377, elapsed time : 798.06sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3718559643543813\n",
      "39.06805204477132\n",
      "epoch : 32, t_cost : 0.000083, e_cost : 0.020348, elapsed time : 798.24sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.37082009533241944\n",
      "46.41349503273159\n",
      "epoch : 33, t_cost : 0.000083, e_cost : 0.024174, elapsed time : 798.31sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3666159878180224\n",
      "62.60569641011534\n",
      "epoch : 34, t_cost : 0.000082, e_cost : 0.032607, elapsed time : 798.36sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3740481162853939\n",
      "21.96023802779382\n",
      "epoch : 35, t_cost : 0.000083, e_cost : 0.011438, elapsed time : 798.05sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3727303473192478\n",
      "28.75384215579652\n",
      "epoch : 36, t_cost : 0.000083, e_cost : 0.014976, elapsed time : 798.32sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3672331192274214\n",
      "27.700237607701638\n",
      "epoch : 37, t_cost : 0.000082, e_cost : 0.014427, elapsed time : 798.21sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.36411732022679644\n",
      "21.52930376354925\n",
      "epoch : 38, t_cost : 0.000081, e_cost : 0.011213, elapsed time : 798.25sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.36740695733215034\n",
      "39.73304670113066\n",
      "epoch : 39, t_cost : 0.000082, e_cost : 0.020694, elapsed time : 798.15sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3639217393160834\n",
      "20.85308593545051\n",
      "epoch : 40, t_cost : 0.000081, e_cost : 0.010861, elapsed time : 798.15sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3615861641146694\n",
      "27.709426927336608\n",
      "epoch : 41, t_cost : 0.000081, e_cost : 0.014432, elapsed time : 798.23sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.36141304588909406\n",
      "19.018610177699884\n",
      "epoch : 42, t_cost : 0.000081, e_cost : 0.009906, elapsed time : 798.00sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.35933137636402535\n",
      "20.244698634940505\n",
      "epoch : 43, t_cost : 0.000080, e_cost : 0.010544, elapsed time : 798.14sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.35923607301310767\n",
      "19.144292132375995\n",
      "epoch : 44, t_cost : 0.000080, e_cost : 0.009971, elapsed time : 798.22sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.35594964730034917\n",
      "21.112327174025268\n",
      "epoch : 45, t_cost : 0.000079, e_cost : 0.010996, elapsed time : 798.25sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.35626369265719404\n",
      "19.404318809461984\n",
      "epoch : 46, t_cost : 0.000080, e_cost : 0.010106, elapsed time : 798.33sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.35701925338662477\n",
      "20.40787288987849\n",
      "epoch : 47, t_cost : 0.000080, e_cost : 0.010629, elapsed time : 798.20sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3523863243026426\n",
      "18.40651220996915\n",
      "epoch : 48, t_cost : 0.000079, e_cost : 0.009587, elapsed time : 798.23sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3544165546227305\n",
      "18.39093916940874\n",
      "epoch : 49, t_cost : 0.000079, e_cost : 0.009579, elapsed time : 798.21sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.35107236106978235\n",
      "19.728982015505608\n",
      "epoch : 50, t_cost : 0.000078, e_cost : 0.010276, elapsed time : 798.28sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3477965647966812\n",
      "16.75047858922335\n",
      "epoch : 51, t_cost : 0.000078, e_cost : 0.008724, elapsed time : 798.31sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3493757778105646\n",
      "22.592014276520786\n",
      "epoch : 52, t_cost : 0.000078, e_cost : 0.011767, elapsed time : 798.29sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3469903420168521\n",
      "17.127750198400463\n",
      "epoch : 53, t_cost : 0.000077, e_cost : 0.008921, elapsed time : 798.16sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.34748200357626047\n",
      "19.5168372113003\n",
      "epoch : 54, t_cost : 0.000078, e_cost : 0.010165, elapsed time : 798.05sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.34512307486011196\n",
      "73.18176979798773\n",
      "epoch : 55, t_cost : 0.000077, e_cost : 0.038116, elapsed time : 798.24sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3460959910271413\n",
      "27.84368627346339\n",
      "epoch : 56, t_cost : 0.000077, e_cost : 0.014502, elapsed time : 798.07sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3447360897653198\n",
      "32.33241487514715\n",
      "epoch : 57, t_cost : 0.000077, e_cost : 0.016840, elapsed time : 798.16sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.34390331036684074\n",
      "35.655140268012474\n",
      "epoch : 58, t_cost : 0.000077, e_cost : 0.018570, elapsed time : 798.33sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3418492525711372\n",
      "45.685930552086575\n",
      "epoch : 59, t_cost : 0.000076, e_cost : 0.023795, elapsed time : 798.26sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3370077918989409\n",
      "57.63753964103125\n",
      "epoch : 60, t_cost : 0.000075, e_cost : 0.030020, elapsed time : 798.13sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.33550030181049806\n",
      "32.70402038891007\n",
      "epoch : 61, t_cost : 0.000075, e_cost : 0.017033, elapsed time : 798.00sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.33160526756773834\n",
      "65.7129076845722\n",
      "epoch : 62, t_cost : 0.000074, e_cost : 0.034225, elapsed time : 798.16sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.33757596013265356\n",
      "36.65039921665266\n",
      "epoch : 63, t_cost : 0.000075, e_cost : 0.019089, elapsed time : 797.84sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3346456624390157\n",
      "577.2882297061624\n",
      "epoch : 64, t_cost : 0.000075, e_cost : 0.300671, elapsed time : 798.39sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.33263944419149993\n",
      "98.35633449392662\n",
      "epoch : 65, t_cost : 0.000074, e_cost : 0.051227, elapsed time : 798.26sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.33465946249816625\n",
      "147.3791228146365\n",
      "epoch : 66, t_cost : 0.000075, e_cost : 0.076760, elapsed time : 797.99sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3351074001334382\n",
      "107.0140413674817\n",
      "epoch : 67, t_cost : 0.000075, e_cost : 0.055736, elapsed time : 798.17sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.33295038225151075\n",
      "131.3355354063733\n",
      "epoch : 68, t_cost : 0.000074, e_cost : 0.068404, elapsed time : 798.41sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.33110251579910255\n",
      "38.6260584929023\n",
      "epoch : 69, t_cost : 0.000074, e_cost : 0.020118, elapsed time : 798.27sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3313503504241453\n",
      "498.37559975779186\n",
      "epoch : 70, t_cost : 0.000074, e_cost : 0.259571, elapsed time : 798.15sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.33352357207331806\n",
      "469.89888205942407\n",
      "epoch : 71, t_cost : 0.000074, e_cost : 0.244739, elapsed time : 798.24sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3320425637025437\n",
      "319.17709971709337\n",
      "epoch : 72, t_cost : 0.000074, e_cost : 0.166238, elapsed time : 798.09sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3304106774353386\n",
      "317.1755637642782\n",
      "epoch : 73, t_cost : 0.000074, e_cost : 0.165196, elapsed time : 798.12sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3288159949074725\n",
      "384.0169763660433\n",
      "epoch : 74, t_cost : 0.000073, e_cost : 0.200009, elapsed time : 798.08sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3289662990478064\n",
      "250.9209993526565\n",
      "epoch : 75, t_cost : 0.000073, e_cost : 0.130688, elapsed time : 798.28sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3361115087359394\n",
      "68.98134321012549\n",
      "epoch : 76, t_cost : 0.000075, e_cost : 0.035928, elapsed time : 798.12sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3257983132934896\n",
      "164.91220345939473\n",
      "epoch : 77, t_cost : 0.000073, e_cost : 0.085892, elapsed time : 798.11sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3284307899439227\n",
      "53.71432810779879\n",
      "epoch : 78, t_cost : 0.000073, e_cost : 0.027976, elapsed time : 798.29sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.33401883253873166\n",
      "62.819033046040204\n",
      "epoch : 79, t_cost : 0.000075, e_cost : 0.032718, elapsed time : 798.14sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3315943755169428\n",
      "47.713812287314795\n",
      "epoch : 80, t_cost : 0.000074, e_cost : 0.024851, elapsed time : 798.21sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.32744776983872725\n",
      "39.66391648045828\n",
      "epoch : 81, t_cost : 0.000073, e_cost : 0.020658, elapsed time : 798.52sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3274491555757777\n",
      "339.00427757175385\n",
      "epoch : 82, t_cost : 0.000073, e_cost : 0.176565, elapsed time : 798.06sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3262913141725221\n",
      "86.94581014612413\n",
      "epoch : 83, t_cost : 0.000073, e_cost : 0.045284, elapsed time : 797.93sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3270222733949595\n",
      "318.8772060087995\n",
      "epoch : 84, t_cost : 0.000073, e_cost : 0.166082, elapsed time : 798.34sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.32709479081040627\n",
      "53.1532244081136\n",
      "epoch : 85, t_cost : 0.000073, e_cost : 0.027684, elapsed time : 798.36sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3285597466629042\n",
      "70.72873299297316\n",
      "epoch : 86, t_cost : 0.000073, e_cost : 0.036838, elapsed time : 798.08sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.32744937055895207\n",
      "77.02338491701448\n",
      "epoch : 87, t_cost : 0.000073, e_cost : 0.040116, elapsed time : 798.12sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.32585156867980913\n",
      "344.3915955735629\n",
      "epoch : 88, t_cost : 0.000073, e_cost : 0.179371, elapsed time : 798.38sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3259729029068694\n",
      "79.24130264268024\n",
      "epoch : 89, t_cost : 0.000073, e_cost : 0.041272, elapsed time : 798.24sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.32664190180730657\n",
      "22.62478478205776\n",
      "epoch : 90, t_cost : 0.000073, e_cost : 0.011784, elapsed time : 797.96sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.324809758034462\n",
      "47.331134599004145\n",
      "epoch : 91, t_cost : 0.000073, e_cost : 0.024652, elapsed time : 798.08sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3240069902085452\n",
      "20.938263838623243\n",
      "epoch : 92, t_cost : 0.000072, e_cost : 0.010905, elapsed time : 798.08sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.326713958716482\n",
      "21.86363494210127\n",
      "epoch : 93, t_cost : 0.000073, e_cost : 0.011387, elapsed time : 796.01sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3276552717152299\n",
      "30.4741496583556\n",
      "epoch : 94, t_cost : 0.000073, e_cost : 0.015872, elapsed time : 796.31sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3283227953866117\n",
      "20.67196694614904\n",
      "epoch : 95, t_cost : 0.000073, e_cost : 0.010767, elapsed time : 796.32sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.32578527382338507\n",
      "29.909035580041746\n",
      "epoch : 96, t_cost : 0.000073, e_cost : 0.015578, elapsed time : 796.04sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3261291177223029\n",
      "73.29705861523325\n",
      "epoch : 97, t_cost : 0.000073, e_cost : 0.038176, elapsed time : 795.82sec\n",
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.3280677631018989\n",
      "25.905730474149095\n",
      "epoch : 98, t_cost : 0.000073, e_cost : 0.013493, elapsed time : 796.07sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2294025, 16, 1) (2294025, 10, 16, 1) (2294025, 10, 16, 1) (2294025, 16, 1) (2294025, 1)\n",
      "(983154, 16, 1) (983154, 10, 16, 1) (983154, 10, 16, 1) (983154, 16, 1) (983154, 1)\n",
      "0.32843965281108467\n",
      "22.817327744405702\n",
      "epoch : 99, t_cost : 0.000073, e_cost : 0.011884, elapsed time : 796.08sec\n",
      "\n",
      "#Best result at epoch 51\n",
      "t_cost : 0.000078, e_cost : 0.008724\n",
      "[<matplotlib.lines.Line2D object at 0x7f7f1c2040d0>]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.keras.backend.clear_session()\n",
    "#tf.compat.v1.reset_default_graph()\n",
    "#parameter list\n",
    "'''\n",
    "sess=tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(allow_soft_placement=True))\n",
    "name='lstm'\n",
    "timesize=20\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "#\n",
    "'''\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=16\n",
    "timesize_for_calc_correlation=100\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "\n",
    "\n",
    "kospi=StockData(\n",
    "    'NASDAQ/Sample',\n",
    "    'NASDAQ/NDX.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "\n",
    "\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    \n",
    "result_dic={}\n",
    "evalution_costplt=[]\n",
    "for i in range(100):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "    \n",
    "    #training batch\n",
    "    \n",
    "    for batch in kospi.getBatch('training'):        \n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    \n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(training_cost)\n",
    "    print(evalution_cost)\n",
    "    \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "    evalution_costplt.append(evalution_cost)\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "    i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))\n",
    "print(plt.plot(evalution_costplt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## epoch : 100 , batchsize : 512 , timesize : 32\n",
    "## timesize_for_calc_correlation=50\n",
    "## positive_correlation_stock_num=10\n",
    "## negative_correlation_sotck_num=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexPrice shape:  (40559, 1)\n",
      "StockPrice shape:  (40559, 81)\n",
      "making dataset progress : finished\t59\n",
      "result =  Tensor(\"concat:0\", shape=(None, 32, 256), dtype=float32)\n",
      "LSTM2 =  <__main__.MI_LSTMCell object at 0x7f7f201fa6d0>\n",
      "Y_2 =  (None, 32, 64)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f7f1fc2bc90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f7f1f8b9e10>, <gast.gast.Return object at 0x7f7f1f8b9e90>]\n",
      "WARNING: AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f7f1fc2bc90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f7f1f8b9e10>, <gast.gast.Return object at 0x7f7f1f8b9e90>]\n",
      "inputs :  Tensor(\"rnn_22/transpose_1:0\", shape=(None, 32, 64), dtype=float32)\n",
      "weight :  Tensor(\"attention_1/Squeeze:0\", shape=(None, 32), dtype=float32)\n",
      "encoder_states :  Tensor(\"encoder/transpose_1:0\", shape=(None, 32, 64), dtype=float32)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f7f1f64a1d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f7f20637050>, <gast.gast.Return object at 0x7f7f206370d0>]\n",
      "WARNING: AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f7f1f64a1d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f7f20637050>, <gast.gast.Return object at 0x7f7f206370d0>]\n",
      "y_pred :  Tensor(\"decoder/dense_5/BiasAdd:0\", shape=(None, 1), dtype=float32)\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "15.516362362996006\n",
      "40.02040918728744\n",
      "epoch : 0, t_cost : 0.003459, e_cost : 0.020822, elapsed time : 1625.19sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "1.779869169839003\n",
      "158.61445982657096\n",
      "epoch : 1, t_cost : 0.000397, e_cost : 0.082526, elapsed time : 1618.69sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "1.5476340273371534\n",
      "409.70774877448093\n",
      "epoch : 2, t_cost : 0.000345, e_cost : 0.213167, elapsed time : 1618.82sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "1.3461583006137516\n",
      "173.34899397917252\n",
      "epoch : 3, t_cost : 0.000300, e_cost : 0.090192, elapsed time : 1620.11sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.937570203780524\n",
      "56.00912854880153\n",
      "epoch : 4, t_cost : 0.000209, e_cost : 0.029141, elapsed time : 1618.85sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.6357517666810963\n",
      "53.8220582949798\n",
      "epoch : 5, t_cost : 0.000142, e_cost : 0.028003, elapsed time : 1618.28sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.6137679207995461\n",
      "62.01690487133237\n",
      "epoch : 6, t_cost : 0.000137, e_cost : 0.032267, elapsed time : 1618.58sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.5502998986103194\n",
      "78.85898228155202\n",
      "epoch : 7, t_cost : 0.000123, e_cost : 0.041030, elapsed time : 1618.40sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.5794505805042718\n",
      "55.495955242193304\n",
      "epoch : 8, t_cost : 0.000129, e_cost : 0.028874, elapsed time : 1618.74sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.44443967902589065\n",
      "44.230268471103045\n",
      "epoch : 9, t_cost : 0.000099, e_cost : 0.023013, elapsed time : 1618.72sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.39840997990722826\n",
      "58.11065695268917\n",
      "epoch : 10, t_cost : 0.000089, e_cost : 0.030234, elapsed time : 1618.54sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.4381355140767482\n",
      "76.67297944736129\n",
      "epoch : 11, t_cost : 0.000098, e_cost : 0.039892, elapsed time : 1618.88sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.4936981495902728\n",
      "57.153043521881045\n",
      "epoch : 12, t_cost : 0.000110, e_cost : 0.029736, elapsed time : 1618.58sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.40457108133614383\n",
      "57.925519021679065\n",
      "epoch : 13, t_cost : 0.000090, e_cost : 0.030138, elapsed time : 1618.48sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3744174465709875\n",
      "59.49371951788635\n",
      "epoch : 14, t_cost : 0.000083, e_cost : 0.030954, elapsed time : 1618.56sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3853523362231499\n",
      "67.57006162087055\n",
      "epoch : 15, t_cost : 0.000086, e_cost : 0.035156, elapsed time : 1618.53sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.4540730432327109\n",
      "58.40326466782608\n",
      "epoch : 16, t_cost : 0.000101, e_cost : 0.030387, elapsed time : 1618.67sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.41613757836967125\n",
      "43.11876159237363\n",
      "epoch : 17, t_cost : 0.000093, e_cost : 0.022434, elapsed time : 1618.57sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3977611188033734\n",
      "31.06953836352841\n",
      "epoch : 18, t_cost : 0.000089, e_cost : 0.016165, elapsed time : 1618.47sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.37558666057338996\n",
      "28.69138393292451\n",
      "epoch : 19, t_cost : 0.000084, e_cost : 0.014928, elapsed time : 1619.02sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38342156527232873\n",
      "29.940779175169155\n",
      "epoch : 20, t_cost : 0.000085, e_cost : 0.015578, elapsed time : 1619.06sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.37405850167851895\n",
      "31.451034436449845\n",
      "epoch : 21, t_cost : 0.000083, e_cost : 0.016364, elapsed time : 1618.48sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3647680469389343\n",
      "33.437976743000036\n",
      "epoch : 22, t_cost : 0.000081, e_cost : 0.017397, elapsed time : 1618.87sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3988343689920839\n",
      "34.82538341031977\n",
      "epoch : 23, t_cost : 0.000089, e_cost : 0.018119, elapsed time : 1618.86sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.4257967255753101\n",
      "36.08037144813352\n",
      "epoch : 24, t_cost : 0.000095, e_cost : 0.018772, elapsed time : 1618.44sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.46534820494343876\n",
      "36.183799279613595\n",
      "epoch : 25, t_cost : 0.000104, e_cost : 0.018826, elapsed time : 1618.88sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.4777111672583487\n",
      "34.58689938160023\n",
      "epoch : 26, t_cost : 0.000106, e_cost : 0.017995, elapsed time : 1618.95sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.4454464681448371\n",
      "38.90802994072874\n",
      "epoch : 27, t_cost : 0.000099, e_cost : 0.020244, elapsed time : 1618.77sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.4326504256841872\n",
      "40.87675054469946\n",
      "epoch : 28, t_cost : 0.000096, e_cost : 0.021268, elapsed time : 1618.56sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.43302054079458685\n",
      "36.72925750169816\n",
      "epoch : 29, t_cost : 0.000097, e_cost : 0.019110, elapsed time : 1618.95sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.4347138910020476\n",
      "33.60212638401208\n",
      "epoch : 30, t_cost : 0.000097, e_cost : 0.017483, elapsed time : 1618.74sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.4067829375526344\n",
      "32.07714144466809\n",
      "epoch : 31, t_cost : 0.000091, e_cost : 0.016689, elapsed time : 1618.65sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.38483813164748426\n",
      "31.19635422561987\n",
      "epoch : 32, t_cost : 0.000086, e_cost : 0.016231, elapsed time : 1618.60sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.37552504072846205\n",
      "31.013820657521137\n",
      "epoch : 33, t_cost : 0.000084, e_cost : 0.016136, elapsed time : 1618.74sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.36506530895712785\n",
      "29.277113427364384\n",
      "epoch : 34, t_cost : 0.000081, e_cost : 0.015233, elapsed time : 1624.15sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.35873697384113257\n",
      "29.70123626948407\n",
      "epoch : 35, t_cost : 0.000080, e_cost : 0.015453, elapsed time : 1619.70sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3595417600890869\n",
      "29.373372053512867\n",
      "epoch : 36, t_cost : 0.000080, e_cost : 0.015283, elapsed time : 1619.23sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.36559591732111585\n",
      "28.512952366687387\n",
      "epoch : 37, t_cost : 0.000081, e_cost : 0.014835, elapsed time : 1618.95sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3676379927351263\n",
      "25.940677745045832\n",
      "epoch : 38, t_cost : 0.000082, e_cost : 0.013497, elapsed time : 1619.04sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3675542033579404\n",
      "21.73070184990138\n",
      "epoch : 39, t_cost : 0.000082, e_cost : 0.011306, elapsed time : 1619.39sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.35368454747140277\n",
      "22.326658552619847\n",
      "epoch : 40, t_cost : 0.000079, e_cost : 0.011616, elapsed time : 1618.47sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.35360601359843713\n",
      "23.13966435086695\n",
      "epoch : 41, t_cost : 0.000079, e_cost : 0.012039, elapsed time : 1618.72sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3585485339540355\n",
      "22.984816661995865\n",
      "epoch : 42, t_cost : 0.000080, e_cost : 0.011959, elapsed time : 1619.33sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3585059597980944\n",
      "23.36931390873906\n",
      "epoch : 43, t_cost : 0.000080, e_cost : 0.012159, elapsed time : 1618.63sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.36164244685323865\n",
      "21.916752766555874\n",
      "epoch : 44, t_cost : 0.000081, e_cost : 0.011403, elapsed time : 1618.93sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3595179307549188\n",
      "21.195666717274435\n",
      "epoch : 45, t_cost : 0.000080, e_cost : 0.011028, elapsed time : 1618.93sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3568918147043405\n",
      "20.289206753128383\n",
      "epoch : 46, t_cost : 0.000080, e_cost : 0.010556, elapsed time : 1618.87sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3528008947305352\n",
      "19.36607587699109\n",
      "epoch : 47, t_cost : 0.000079, e_cost : 0.010076, elapsed time : 1619.67sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3521788678926896\n",
      "19.298686798185372\n",
      "epoch : 48, t_cost : 0.000079, e_cost : 0.010041, elapsed time : 1619.16sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3446868072446705\n",
      "19.27193522993548\n",
      "epoch : 49, t_cost : 0.000077, e_cost : 0.010027, elapsed time : 1618.62sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3514247948724005\n",
      "18.899671098275576\n",
      "epoch : 50, t_cost : 0.000078, e_cost : 0.009833, elapsed time : 1618.97sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.35737167157276417\n",
      "18.687290839250636\n",
      "epoch : 51, t_cost : 0.000080, e_cost : 0.009723, elapsed time : 1618.78sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.351011120757903\n",
      "17.74864619989603\n",
      "epoch : 52, t_cost : 0.000078, e_cost : 0.009234, elapsed time : 1619.08sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3520100503337744\n",
      "17.671872888327925\n",
      "epoch : 53, t_cost : 0.000078, e_cost : 0.009195, elapsed time : 1618.70sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.34790762470674963\n",
      "17.363378120251582\n",
      "epoch : 54, t_cost : 0.000078, e_cost : 0.009034, elapsed time : 1619.61sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3459942531121669\n",
      "18.17200013927868\n",
      "epoch : 55, t_cost : 0.000077, e_cost : 0.009455, elapsed time : 1619.43sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3496477505182156\n",
      "17.38211908811354\n",
      "epoch : 56, t_cost : 0.000078, e_cost : 0.009044, elapsed time : 1619.23sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3467324205771547\n",
      "17.958553327818663\n",
      "epoch : 57, t_cost : 0.000077, e_cost : 0.009344, elapsed time : 1619.05sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3473542711290065\n",
      "17.5524428681274\n",
      "epoch : 58, t_cost : 0.000077, e_cost : 0.009132, elapsed time : 1619.64sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.34567279343991686\n",
      "17.84125414848313\n",
      "epoch : 59, t_cost : 0.000077, e_cost : 0.009283, elapsed time : 1619.54sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3458481583465982\n",
      "18.602877575161983\n",
      "epoch : 60, t_cost : 0.000077, e_cost : 0.009679, elapsed time : 1619.50sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.34562613690968647\n",
      "18.172430730166525\n",
      "epoch : 61, t_cost : 0.000077, e_cost : 0.009455, elapsed time : 1618.85sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.35195240106122583\n",
      "17.90113456927429\n",
      "epoch : 62, t_cost : 0.000078, e_cost : 0.009314, elapsed time : 1619.39sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3552610286201343\n",
      "17.53345007840835\n",
      "epoch : 63, t_cost : 0.000079, e_cost : 0.009123, elapsed time : 1619.18sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3508658743635351\n",
      "17.54951159873235\n",
      "epoch : 64, t_cost : 0.000078, e_cost : 0.009131, elapsed time : 1619.34sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.34793651606787535\n",
      "16.60850505205235\n",
      "epoch : 65, t_cost : 0.000078, e_cost : 0.008641, elapsed time : 1619.49sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3495375569436874\n",
      "16.490204581132275\n",
      "epoch : 66, t_cost : 0.000078, e_cost : 0.008580, elapsed time : 1619.32sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3519593189766965\n",
      "15.968568959280674\n",
      "epoch : 67, t_cost : 0.000078, e_cost : 0.008308, elapsed time : 1619.30sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3492367140765964\n",
      "15.840580228363251\n",
      "epoch : 68, t_cost : 0.000078, e_cost : 0.008242, elapsed time : 1619.57sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3510004327072238\n",
      "16.14423308901314\n",
      "epoch : 69, t_cost : 0.000078, e_cost : 0.008400, elapsed time : 1619.33sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3532073797468911\n",
      "15.0125030765048\n",
      "epoch : 70, t_cost : 0.000079, e_cost : 0.007811, elapsed time : 1618.91sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3474065785731\n",
      "15.75024896114337\n",
      "epoch : 71, t_cost : 0.000077, e_cost : 0.008195, elapsed time : 1619.20sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.34856339751377163\n",
      "22.778847311787104\n",
      "epoch : 72, t_cost : 0.000078, e_cost : 0.011852, elapsed time : 1619.73sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.34677647138823886\n",
      "28.38825043181714\n",
      "epoch : 73, t_cost : 0.000077, e_cost : 0.014770, elapsed time : 1618.96sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3527367303536266\n",
      "15.74485931621166\n",
      "epoch : 74, t_cost : 0.000079, e_cost : 0.008192, elapsed time : 1618.99sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3517249688375159\n",
      "15.220450871205685\n",
      "epoch : 75, t_cost : 0.000078, e_cost : 0.007919, elapsed time : 1619.16sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3478966042648608\n",
      "17.782140913423063\n",
      "epoch : 76, t_cost : 0.000078, e_cost : 0.009252, elapsed time : 1619.46sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3451235282336711\n",
      "14.676570694022303\n",
      "epoch : 77, t_cost : 0.000077, e_cost : 0.007636, elapsed time : 1619.40sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.34616390383553153\n",
      "14.841645676628104\n",
      "epoch : 78, t_cost : 0.000077, e_cost : 0.007722, elapsed time : 1619.53sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3478160435979589\n",
      "28.100275063836307\n",
      "epoch : 79, t_cost : 0.000078, e_cost : 0.014620, elapsed time : 1619.26sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.34367625296044935\n",
      "19.253478292557702\n",
      "epoch : 80, t_cost : 0.000077, e_cost : 0.010017, elapsed time : 1618.99sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3403505410301477\n",
      "13.932693989805557\n",
      "epoch : 81, t_cost : 0.000076, e_cost : 0.007249, elapsed time : 1619.35sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.34179907160023504\n",
      "18.087865219360538\n",
      "epoch : 82, t_cost : 0.000076, e_cost : 0.009411, elapsed time : 1619.28sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3478312734364408\n",
      "14.817630748953889\n",
      "epoch : 83, t_cost : 0.000078, e_cost : 0.007709, elapsed time : 1619.11sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.34613833800131033\n",
      "29.601299736928922\n",
      "epoch : 84, t_cost : 0.000077, e_cost : 0.015401, elapsed time : 1619.42sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3521260353472826\n",
      "19.039788971605958\n",
      "epoch : 85, t_cost : 0.000078, e_cost : 0.009906, elapsed time : 1619.16sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3627856046450688\n",
      "14.18308901043929\n",
      "epoch : 86, t_cost : 0.000081, e_cost : 0.007379, elapsed time : 1619.35sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3486566892834162\n",
      "18.119430723245387\n",
      "epoch : 87, t_cost : 0.000078, e_cost : 0.009427, elapsed time : 1619.30sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3392356540189212\n",
      "26.63125478643633\n",
      "epoch : 88, t_cost : 0.000076, e_cost : 0.013856, elapsed time : 1619.55sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.34430752802200004\n",
      "14.177693180316055\n",
      "epoch : 89, t_cost : 0.000077, e_cost : 0.007377, elapsed time : 1619.45sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.34229375648737914\n",
      "25.01276515605059\n",
      "epoch : 90, t_cost : 0.000076, e_cost : 0.013014, elapsed time : 1619.39sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.34156494959506745\n",
      "20.456807519192807\n",
      "epoch : 91, t_cost : 0.000076, e_cost : 0.010644, elapsed time : 1619.57sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3443677914347063\n",
      "14.864555338339414\n",
      "epoch : 92, t_cost : 0.000077, e_cost : 0.007734, elapsed time : 1619.46sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.34491485327589544\n",
      "30.03818388052059\n",
      "epoch : 93, t_cost : 0.000077, e_cost : 0.015629, elapsed time : 1618.96sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.34375660709656586\n",
      "21.644056177226958\n",
      "epoch : 94, t_cost : 0.000077, e_cost : 0.011261, elapsed time : 1619.59sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3464573746914539\n",
      "18.110913269887533\n",
      "epoch : 95, t_cost : 0.000077, e_cost : 0.009423, elapsed time : 1619.52sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3445958070337838\n",
      "14.259026814435856\n",
      "epoch : 96, t_cost : 0.000077, e_cost : 0.007419, elapsed time : 1621.92sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3489172690883606\n",
      "19.935997018601483\n",
      "epoch : 97, t_cost : 0.000078, e_cost : 0.010373, elapsed time : 1621.72sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.34750431566590123\n",
      "46.326224721298786\n",
      "epoch : 98, t_cost : 0.000077, e_cost : 0.024103, elapsed time : 1632.79sec\n",
      "(2296860, 32, 1) (2296860, 10, 32, 1) (2296860, 10, 32, 1) (2296860, 32, 1) (2296860, 1)\n",
      "(984369, 32, 1) (984369, 10, 32, 1) (984369, 10, 32, 1) (984369, 32, 1) (984369, 1)\n",
      "0.3454975268373346\n",
      "14.756774502213375\n",
      "epoch : 99, t_cost : 0.000077, e_cost : 0.007678, elapsed time : 1617.66sec\n",
      "\n",
      "#Best result at epoch 81\n",
      "t_cost : 0.000076, e_cost : 0.007249\n",
      "[<matplotlib.lines.Line2D object at 0x7f810453af50>]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.keras.backend.clear_session()\n",
    "#tf.compat.v1.reset_default_graph()\n",
    "#parameter list\n",
    "'''\n",
    "sess=tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(allow_soft_placement=True))\n",
    "name='lstm'\n",
    "timesize=20\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "#\n",
    "'''\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=32\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "\n",
    "\n",
    "kospi=StockData(\n",
    "    'NASDAQ/Sample',\n",
    "    'NASDAQ/NDX.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "\n",
    "\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    \n",
    "result_dic={}\n",
    "evalution_costplt=[]\n",
    "for i in range(100):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "    \n",
    "    #training batch\n",
    "    \n",
    "    for batch in kospi.getBatch('training'):        \n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    \n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(training_cost)\n",
    "    print(evalution_cost)\n",
    "    \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "    evalution_costplt.append(evalution_cost)\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "    i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))\n",
    "print(plt.plot(evalution_costplt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
