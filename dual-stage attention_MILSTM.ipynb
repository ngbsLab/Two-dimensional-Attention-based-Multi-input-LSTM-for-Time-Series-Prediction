{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/tf/lib/python3.7/site-packages/pandas_datareader/compat/__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas_datareader import data,wb\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"testLine\\nkospi = StockData('StockChart/SAMPLE','StockChart/KOSPI.csv',20,50,10,10,0.7)\\nprint(np.shape(kospi.trainSet))\\nprint(np.shape(kospi.testSet))\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class StockData():\n",
    "    \"\"\"\n",
    "        훈련용 데이터세트와 평가용 데이터세트를 만들기 위한 과정.\n",
    "\n",
    "        파라미터:\n",
    "            folderPath : 종목시장의 주가 csv가 저장되어있는 디렉토리 경로.\n",
    "            indexPath : 종목시장의 인덱스 주 csv파일의 경로.\n",
    "            timewindowsize : LSTM의 입력으로 들어가는 타임의 사이즈. 10일 경우 미래주가를 예측하기 위해 이전 10일 주가를 사용.\n",
    "            windowsizeForPCC : PCC를 계산하기 위해 사용되는 타임의 사이즈. 10일 경우 관계주를 구하기 위해 이전 10일 주가를 사용.\n",
    "            PositiveStockNumber : 긍정관계주 개수.\n",
    "            NegativeStockNumber : 부정관계주 개수.\n",
    "            train_test_rate : 훈련:평가 세트 비율. 0.7일 경우 생성된 데이터 세트중 70%는 훈련용, 30%는 평가용으로 사용.\n",
    "            batchSize : 세트를 나누는 배치 사이즈.\n",
    "\n",
    "        과정:\n",
    "            종목시장의 모든 종목의 시가와 인덱스 시가를 읽어옴.\n",
    "            minmax스케일러를 각 종목과 인덱스에 적용하고 저장.\n",
    "            PCC계산, 관계주 계산.\n",
    "            데이터세트 저장.\n",
    "               \n",
    "    \"\"\"\n",
    "    def __init__(self,folderPath,indexPath,timewindowsize,windowsizeForPCC,PostiveStockNumber,NegativeStockNumber,train_test_rate,batchSize):        \n",
    "               \n",
    "        if(train_test_rate<=0 or train_test_rate>=1):\n",
    "            raise ValueError('train_test_rate should be between 0 and 1')        \n",
    "        self.P=PostiveStockNumber\n",
    "        self.N=NegativeStockNumber        \n",
    "        self.T=timewindowsize\n",
    "        self.Tr=windowsizeForPCC\n",
    "        self.folderPath = folderPath      \n",
    "        self.indexPath=indexPath    \n",
    "        self.batchSize=batchSize\n",
    "        self.date_duration=3000\n",
    "        \n",
    "        self.train_test_rate=train_test_rate\n",
    "        self.scaler=MinMaxScaler(feature_range=(-1,1))  \n",
    "        self.indexScaler = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "        self.indexPrice = self.loadIndex()\n",
    "        self.stockPrice = self.loadCSV()\n",
    "\n",
    "        self.trainSet,self.testSet=self.make_dataset()\n",
    "\n",
    "        self.batchNum={}\n",
    "    \n",
    "    def getBatch(self,option):\n",
    "        \"\"\"\n",
    "        클래스에 저장된 세트를 y,xp,xn,xi,target으로 나누고 batch생성.\n",
    "\n",
    "        args:\n",
    "            option='training' or 'evaluation'\n",
    "\n",
    "        returns:\n",
    "            batch 제너레이터\n",
    "            batch={'y','xp','xn','xi','target'}\n",
    "        \"\"\"\n",
    "        if(option is not 'training' and option is not 'evaluation'):\n",
    "            raise ValueError('option should be \"training\" or \"evaluation\".')\n",
    "\n",
    "        if(option is 'training'):\n",
    "            returnSet = self.trainSet\n",
    "        else:\n",
    "            returnSet = self.testSet\n",
    "        \n",
    "        y=[]\n",
    "        xp=[]\n",
    "        xn=[]\n",
    "        xi=[]\n",
    "        target=[]\n",
    "\n",
    "        for d in returnSet:\n",
    "            y.append(d['target_history'])  \n",
    "            xp.append(d['pos_history'])       \n",
    "            xn.append(d['neg_history'])       \n",
    "            xi.append(d['index_history'])       \n",
    "            target.append(d['target_price'])             \n",
    "        y=np.reshape(y,(-1,self.T,1))\n",
    "        xp=np.reshape(xp,(-1,10,self.T,1))\n",
    "        xn=np.reshape(xn,(-1,10,self.T,1))\n",
    "        xi=np.reshape(xi,(-1,self.T,1))\n",
    "        target=np.reshape(target,(-1,1))\n",
    "\n",
    "        print(y.shape,xp.shape,xn.shape,xi.shape,target.shape)     \n",
    "\n",
    "        batchNum=int(len(y)/self.batchSize)\n",
    "        self.batchNum[option]=batchNum\n",
    "\n",
    "        for i in range(batchNum):\n",
    "            yield {'y':y[i*self.batchSize:(i+1)*self.batchSize].astype(np.float32),\n",
    "                   'xp':xp[i*self.batchSize:(i+1)*self.batchSize].astype(np.float32),\n",
    "                   'xn':xn[i*self.batchSize:(i+1)*self.batchSize].astype(np.float32),\n",
    "                   'xi':xi[i*self.batchSize:(i+1)*self.batchSize].astype(np.float32),\n",
    "                   'target':target[i*self.batchSize:(i+1)*self.batchSize].astype(np.float32)}\n",
    "\n",
    "    def loadCSV(self):\n",
    "        \"\"\"\n",
    "        csv파일이 있는 폴더를 입력으로 받아 데이터를 읽어옴.\n",
    "        \"\"\"\n",
    "        csvList=os.listdir(self.folderPath)        \n",
    "        dataframe = pd.DataFrame([])\n",
    "        \n",
    "\n",
    "        for csv in csvList:\n",
    "            data=pd.read_csv(self.folderPath+'/'+csv,engine='python')\n",
    "            if(len(data)>self.date_duration):\n",
    "                data=data[-self.date_duration-1:-1]\n",
    "                data=data.reset_index()\n",
    "                data=data['open']\n",
    "\n",
    "                dataframe=dataframe.append(data,ignore_index=True)\n",
    "        dataT=np.array(dataframe).T\n",
    "        self.scaler.fit(dataT)\n",
    "        dataT=self.scaler.transform(dataT)\n",
    "        dataT=dataT.T\n",
    "        dataframe=pd.DataFrame(dataT)\n",
    "        dataframe=dataframe.transpose()\n",
    "        print('StockPrice shape: ',dataframe.shape)\n",
    "        return dataframe\n",
    "    \n",
    "    def loadIndex(self):\n",
    "        data=pd.read_csv(self.indexPath,engine='python')\n",
    "        data=data[-self.date_duration-1:-1]        \n",
    "        data=data.reset_index()\n",
    "        data=data.fillna(method='ffill')\n",
    "\n",
    "        data=np.array(data['Open'])\n",
    "        data=np.reshape(data,(-1,1))\n",
    "\n",
    "        data=self.indexScaler.fit_transform(data)\n",
    "\n",
    "        data=pd.DataFrame(np.squeeze(data))        \n",
    "\n",
    "        print('IndexPrice shape: ',data.shape)\n",
    "        return data \n",
    "\n",
    "\n",
    "    def make_dataset(self):\n",
    "        \"\"\"\n",
    "        예측모델에 사용되는 입력,타겟 데이터세트.\n",
    "        입력데이터의 shape는 (목표주식+관계주식+인덱스, 타임윈도우사이즈)\n",
    "        타겟데이터의 shape는 (1,1)\n",
    "        \"\"\"\n",
    "        maxday=max([self.T,self.Tr])\n",
    "        dataset=[]\n",
    "\n",
    "        for i in range(maxday,len(self.stockPrice)):\n",
    "            print('making dataset progress : {}/{}'.format(i,len(self.stockPrice)),end='\\r')\n",
    "            priceSet=self.stockPrice.loc[i-self.T:i-1]\n",
    "            targetSet=self.stockPrice.loc[i]\n",
    "            positiveSet,negativeSet=self.calculate_correlation(self.stockPrice.loc[i-maxday:i-1])\n",
    "            indexSet = self.indexPrice.loc[i-self.T:i-1]\n",
    "\n",
    "            for targetNum in priceSet.columns:\n",
    "                target_history=np.reshape(np.array(priceSet[targetNum]),(self.T,1))\n",
    "                pos_history=np.reshape(np.array(positiveSet[targetNum].T),(10,self.T,1))\n",
    "                neg_history=np.reshape(np.array(negativeSet[targetNum].T),(10,self.T,1))\n",
    "                index_history=np.reshape(np.array(indexSet),(self.T,1))\n",
    "                target_price=np.reshape(np.array(targetSet[targetNum]),(1,1))\n",
    "\n",
    "                dataset.append({'target_history':target_history,\n",
    "                                'pos_history':pos_history,\n",
    "                                'neg_history':neg_history,\n",
    "                                'index_history':index_history,\n",
    "                                'target_price':target_price\n",
    "                            })\n",
    "        print('making dataset progress : finished\\t')\n",
    "        \n",
    "        return dataset[:int(len(dataset)*self.train_test_rate)],dataset[int(len(dataset)*self.train_test_rate):]\n",
    "\n",
    "    def calculate_correlation(self,priceSet):\n",
    "        \"\"\"\n",
    "        Pearson Correlation Coefficient(PCC)를 계산하고,\n",
    "        높은순으로 긍정관계주, 낮은순으로 부정관계주를 설정한 개수만큼 생성하여 리스트에 저장한후, 리턴.\n",
    "        입력은 전체 종목의 타임윈도우간의 주가.\n",
    "\n",
    "        Returns:\n",
    "            #모든종목의 관계주. \n",
    "            긍정관계주 shape = (종목 수, dataframe(T*P))\n",
    "            부정관계주 shape = (종목 수, dataframe(T*N))\n",
    "        \"\"\"    \n",
    "        positive=[]\n",
    "        negative=[] \n",
    "        corr=priceSet[-self.Tr:].corr(method='pearson')\n",
    "\n",
    "        for i in corr.columns:\n",
    "            tempCorr=corr[i].sort_values(ascending=False)\n",
    "            index_P=tempCorr[1:self.P+1].index\n",
    "            index_N=tempCorr[-self.N:].index\n",
    "            \n",
    "            priceSet=priceSet[-self.T:]\n",
    "            posSet=priceSet[index_P]\n",
    "            negSet=priceSet[index_N]\n",
    "            posSet.columns=range(self.P)\n",
    "            negSet.columns=range(self.N)\n",
    "            \n",
    "            positive.append(posSet)\n",
    "            negative.append(negSet)\n",
    "        return positive,negative\n",
    "\n",
    "            \n",
    "\"\"\"testLine\n",
    "kospi = StockData('StockChart/SAMPLE','StockChart/KOSPI.csv',20,50,10,10,0.7)\n",
    "print(np.shape(kospi.trainSet))\n",
    "print(np.shape(kospi.testSet))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn=tf.compat.v1.nn.rnn_cell\n",
    "class base_LSTMCell(rnn.BasicLSTMCell):\n",
    "    def __call__(self,inputs,state,scope=None):\n",
    "        \"\"\"Long short-term memory cell (LSTM).\"\"\"\n",
    "        with tf.variable_scope(scope or type(self).__name__):  # \"BasicLSTMCell\"\n",
    "        # Parameters of gates are concatenated into one multiply for efficiency.\n",
    "            if self._state_is_tuple:\n",
    "                c, h = state\n",
    "            else:\n",
    "                c, h = tf.split(1, 2, state)\n",
    "            concat = tf.layers.dense(tf.concat([inputs, h],axis=1), 4 * self._num_units)\n",
    "\n",
    "            # i = input_gate, j = new_input, f = forget_gate, o = output_gate\n",
    "            i, j, f, o = tf.split(concat, 4, 1)\n",
    "\n",
    "            new_c = (c * tf.sigmoid(f + self._forget_bias) + tf.sigmoid(i) *\n",
    "                    self._activation(j))\n",
    "            new_h = self._activation(new_c) * tf.sigmoid(o)\n",
    "\n",
    "            if self._state_is_tuple:\n",
    "                new_state = rnn.LSTMStateTuple(new_c, new_h)\n",
    "            else:\n",
    "                new_state = tf.concat(1, [new_c, new_h])\n",
    "        return new_h, new_state\n",
    "\n",
    "class MI_LSTMCell(rnn.BasicLSTMCell):\n",
    "    \"\"\"\n",
    "    Multi-Input LSTM proposed in the paper, Stock Price Prediction Using Attention-based Multi-Input LSTM.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "               num_units,\n",
    "               num_inputs,\n",
    "               forget_bias=1.0,\n",
    "               state_is_tuple=True,\n",
    "               activation=None,\n",
    "               reuse=None,\n",
    "               name=None,\n",
    "               dtype=None,\n",
    "               **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize the basic LSTM cell.\n",
    "        args:\n",
    "            num_inputs: MI-LSTM의 입력의 개수. \n",
    "                이 파라미터에 따라 입력 게이트의 어텐션 레이어를 설정.\n",
    "                최소 1개이상.\n",
    "                1개일 경우, 어텐션 레이어를 제외하고 기본 LSTM과 동일.\n",
    "        \"\"\"        \n",
    "        super(MI_LSTMCell,self).__init__(num_units,\n",
    "               forget_bias=1.0,\n",
    "               state_is_tuple=True,\n",
    "               activation=None,\n",
    "               reuse=None,\n",
    "               name=None,\n",
    "               dtype=None,\n",
    "               **kwargs)\n",
    "        \n",
    "        if(type(num_inputs) is not int):\n",
    "            raise ValueError(\"num_inputs should be integer\")\n",
    "        if(num_inputs < 1):\n",
    "            raise ValueError(\"num_inputs should not be less than 0\")\n",
    "        self.num_inputs = num_inputs\n",
    "        self.alpha_weight=self.add_variable('alpha_weight',shape=[self._num_units,self._num_units])\n",
    "        self.alpha_bias=[]\n",
    "        for i in range(self.num_inputs):\n",
    "            self.alpha_bias.append(self.add_variable('alpha_bias'+str(i),shape=[1],initializer=tf.zeros_initializer()))\n",
    "\n",
    "    def __call__(self,inputs,state,scope=None):\n",
    "        \"\"\"Long short-term memory cell (LSTM).\"\"\"\n",
    "        with tf.compat.v1.variable_scope(scope or type(self).__name__ ):  # \"BasicLSTMCell\"\n",
    "        # Parameters of gates are concatenated into one multiply for efficiency.\n",
    "            if self._state_is_tuple:\n",
    "                c, h = state\n",
    "            else:\n",
    "                c, h = tf.split(1, 2, state)\n",
    "            inputs_list = tf.split(inputs,self.num_inputs,1)\n",
    "            concat = tf.compat.v1.layers.dense(tf.concat([inputs_list[0], h],axis=1), (3+self.num_inputs) * self._num_units)\n",
    "                                 \n",
    "            # 0 = forget_gate, 1 = output_gate, 2= main_new_input, 3 = main_input_gate, 4~ = input_gate_for_auxiliary\n",
    "            main_list = tf.split(concat, 3+self.num_inputs, 1)\n",
    "                        \n",
    "            #new_input_gate= list of all new_input.\n",
    "            new_input_gate=[tf.tanh(main_list[2])]\n",
    "            #linear layer for auxiliary inputs.\n",
    "            for i in range(1,self.num_inputs):\n",
    "                new_input_gate.append(tf.compat.v1.layers.dense(tf.concat([inputs_list[i], h],axis=1),self._num_units,activation=tf.tanh))\n",
    "\n",
    "            #making list of l. l = sigmoid(input_gate) * tanh(new_input)\n",
    "            new_l=[]\n",
    "            for i,new_input in enumerate(new_input_gate,3):\n",
    "                new_l.append(tf.sigmoid(main_list[i]) * new_input)\n",
    "\n",
    "\n",
    "            #making list of u.            \n",
    "            u=[]\n",
    "            for i,l in enumerate(new_l):\n",
    "                #temp = transpos(l) X W X Cell_State.\n",
    "                temp1=tf.matmul(l,self.alpha_weight)\n",
    "                temp1=tf.expand_dims(temp1,1)\n",
    "                temp2=tf.matmul(temp1,tf.expand_dims(c,2))\n",
    "                u.append(tf.tanh(tf.squeeze(temp2+self.alpha_bias[i],axis=2)))\n",
    "\n",
    "            #making list of alpha.\n",
    "            alpha=tf.nn.softmax(u,axis=0)\n",
    "\n",
    "            #making L.\n",
    "            L=[]\n",
    "            for i,l in enumerate(new_l):\n",
    "                L.append(alpha[i]*l)\n",
    "            L=tf.reduce_sum(L,axis=0)\n",
    "\n",
    "\n",
    "            #new state = c(t-1) * f + L. new h = tanh(c) + sigmoid(o)\n",
    "            new_c = (c * tf.sigmoid(main_list[0] + self._forget_bias)+L)\n",
    "            new_h = self._activation(new_c) * tf.sigmoid(main_list[1])\n",
    "\n",
    "            if self._state_is_tuple:\n",
    "                new_state = rnn.LSTMStateTuple(new_c, new_h)\n",
    "            else:\n",
    "                new_state = tf.concat(1, [new_c, new_h])\n",
    "        return new_h, new_state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "class Attention(keras.Model):\n",
    "    def __init__(self, input_dim, var_scope, reuse=True):\n",
    "        super(Attention, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        with tf.compat.v1.variable_scope(var_scope, reuse=reuse):\n",
    "            self.attention_w = layers.Dense(self.input_dim, name='W')\n",
    "            self.attention_u = layers.Dense(self.input_dim, name='U')\n",
    "            self.attention_v = layers.Dense(1, name='V')\n",
    "\n",
    "    def call(self, input_x, prev_state_tuple):\n",
    "        \"\"\"\n",
    "        Compute the attention weight for input series\n",
    "        hidden_state, cell_state (batch_size, hidden_dim)\n",
    "        input_x (batch_size, num_series, input_dim),\n",
    "        input_dim = num_steps for input attention\n",
    "        \"\"\"\n",
    "        prev_hidden_state, prev_cell_state = prev_state_tuple\n",
    "\n",
    "        # (batch_size, 1, hidden_dim * 2)\n",
    "        concat_state = tf.expand_dims(tf.concat([prev_hidden_state, prev_cell_state], axis=-1),\n",
    "                                      axis=1)\n",
    "\n",
    "        # (batch_size, num_series, input_dim)\n",
    "        score_ = self.attention_w(concat_state) + self.attention_u(input_x)\n",
    "\n",
    "        # (batch_size, num_series, 1)\n",
    "        # Equation (8)\n",
    "        score = self.attention_v(tf.nn.tanh(score_))\n",
    "\n",
    "        # (batch_size, num_series)\n",
    "        # Equation (9)\n",
    "        weight = tf.squeeze(tf.nn.softmax(score, axis=1), axis=-1)\n",
    "\n",
    "        return weight\n",
    "\n",
    "\n",
    "class LSTMCell(keras.Model):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_fc = layers.Dense(self.hidden_dim)\n",
    "\n",
    "    def call(self, input_x, prev_state_tuple):\n",
    "        \"\"\" Return next step's hidden state and cell state  \"\"\"\n",
    "        hidden_state, cell_state = prev_state_tuple\n",
    "\n",
    "        # (batch_size, hidden_dim + input_dim)\n",
    "        concat_input = tf.concat([hidden_state, input_x], axis=-1)\n",
    "\n",
    "        # (batch_size * 4, hidden_dim + input_dim)\n",
    "        concat_input_tiled = tf.tile(concat_input, [4, 1])\n",
    "\n",
    "        # Equation (3) - (6) without activation\n",
    "        forget_, input_, output_, cell_bar = tf.split(self.layer_fc(concat_input_tiled),\n",
    "                                                      axis=0,\n",
    "                                                      num_or_size_splits=4)\n",
    "\n",
    "        # (batch_size, hidden_dim)\n",
    "        # Equation (6)\n",
    "        cell_state = tf.nn.sigmoid(forget_) * cell_state + \\\n",
    "                     tf.nn.sigmoid(input_) * tf.nn.tanh(cell_bar)\n",
    "\n",
    "        # Equation (7)\n",
    "        hidden_state = tf.nn.sigmoid(output_) * tf.nn.tanh(cell_state)\n",
    "        return (hidden_state, cell_state)\n",
    "\n",
    "\n",
    "class Encoder(keras.Model):\n",
    "    def __init__(self, encoder_dim, num_steps):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder_dim = encoder_dim\n",
    "        self.attention_layer = Attention(num_steps, var_scope='input_attention')\n",
    "        self.lstm_cell = LSTMCell(encoder_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        inputs: (batch_size, num_steps, num_series)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        def one_step(prev_state_tuple, current_input):\n",
    "            \"\"\" Move along the time axis by one step  \"\"\"\n",
    "\n",
    "            # (batch_size, num_series, num_steps)\n",
    "            inputs_scan = tf.transpose(inputs, perm=[0, 2, 1])\n",
    "\n",
    "            # (batch_size, num_series)\n",
    "            weight = self.attention_layer(inputs_scan, prev_state_tuple)\n",
    "\n",
    "            weighted_current_input = weight * current_input\n",
    "\n",
    "            return self.lstm_cell(weighted_current_input, prev_state_tuple)\n",
    "\n",
    "        # Get the batch size from inputs\n",
    "        self.batch_size = tf.shape(inputs)[0]\n",
    "        self.num_steps = inputs.get_shape().as_list()[1]\n",
    "\n",
    "        self.init_hidden_state = tf.random.truncated_normal([self.batch_size, self.encoder_dim])\n",
    "        self.init_cell_state = tf.random.truncated_normal([self.batch_size, self.encoder_dim])\n",
    "\n",
    "        # (num_steps, batch_size, num_series)\n",
    "        inputs_ = tf.transpose(inputs, perm=[1, 0, 2])\n",
    "\n",
    "        # use scan to run over all time steps\n",
    "        state_tuple = tf.scan(one_step,\n",
    "                              elems=inputs_,\n",
    "                              initializer=(self.init_hidden_state,\n",
    "                                           self.init_cell_state))\n",
    "\n",
    "        # (batch_size, num_steps, encoder_dim)\n",
    "        all_hidden_state = tf.transpose(state_tuple[0], perm=[1, 0, 2])\n",
    "        return all_hidden_state\n",
    "\n",
    "\n",
    "class Decoder(keras.Model):\n",
    "    def __init__(self, decoder_dim, num_steps):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder_dim = decoder_dim\n",
    "        self.attention_layer = Attention(num_steps, var_scope='temporal_attention')\n",
    "        self.lstm_cell = LSTMCell(decoder_dim)\n",
    "        self.layer_fc_context = layers.Dense(1)\n",
    "        self.layer_prediction_fc_1 = layers.Dense(decoder_dim)\n",
    "        self.layer_prediction_fc_2 = layers.Dense(decoder_dim/2)\n",
    "        self.layer_prediction_fc_3 = layers.Dense(1)\n",
    "\n",
    "    def call(self, encoder_states, inputs, labels):\n",
    "        \"\"\"\n",
    "        encoder_states: (batch_size, num_steps, encoder_dim)\n",
    "        labels: (batch_size, num_steps)\n",
    "        \"\"\"\n",
    "\n",
    "        def one_step(accumulator, current_label):\n",
    "            \"\"\" Move along the time axis by one step  \"\"\"\n",
    "            #inputs_scan2 = tf.transpose(inputs, perm=[0, 2, 1])\n",
    "            \n",
    "            prev_state_tuple, context = accumulator\n",
    "            # (batch_size, num_steps)\n",
    "            # Equation (12) (13)\n",
    "            print(\"inputs : \" , inputs )\n",
    "            weight = self.attention_layer(inputs, prev_state_tuple)\n",
    "            print(\"weight : \" , weight )\n",
    "\n",
    "            # Equation (14)\n",
    "            # (batch_size, encoder_dim)\n",
    "            print(\"encoder_states : \" , encoder_states)\n",
    "            context = tf.reduce_sum(tf.expand_dims(weight, axis=-1) * encoder_states,\n",
    "                                    axis=1)\n",
    "\n",
    "            # Equation (15)\n",
    "            # (batch_size, 1)\n",
    "            y_tilde = self.layer_fc_context(tf.concat([current_label, context], axis=-1))\n",
    "\n",
    "            # Equation (16)\n",
    "            return self.lstm_cell(y_tilde, prev_state_tuple), context\n",
    "\n",
    "        # Get the batch size from inputs\n",
    "        self.batch_size = tf.shape(encoder_states)[0]\n",
    "        self.num_steps = encoder_states.get_shape().as_list()[1]\n",
    "        self.encoder_dim = encoder_states.get_shape().as_list()[-1]\n",
    "\n",
    "        init_hidden_state = tf.random.truncated_normal([self.batch_size, self.decoder_dim])\n",
    "        init_cell_state = tf.random.truncated_normal([self.batch_size, self.decoder_dim])\n",
    "        init_context = tf.random.truncated_normal([self.batch_size, self.encoder_dim])\n",
    "\n",
    "        # (num_steps, batch_size, num_series)\n",
    "        inputs_ = tf.transpose(encoder_states, perm=[1, 0, 2])\n",
    "\n",
    "        # use scan to run over all time steps\n",
    "        state_tuple, all_context = tf.scan(one_step,\n",
    "                                           elems=inputs_,\n",
    "                                           initializer=((init_hidden_state,\n",
    "                                                        init_cell_state),\n",
    "                                                        init_context))\n",
    "\n",
    "        # (batch_size, num_steps, decoder_dim)\n",
    "        all_hidden_state = tf.transpose(state_tuple[0], perm=[1, 0, 2])\n",
    "\n",
    "        # (batch_size, num_steps, encoder_dim)\n",
    "        all_context = tf.transpose(all_context, perm=[1, 0, 2])\n",
    "\n",
    "        last_hidden_state = all_hidden_state[:, -1, :]\n",
    "        last_context = all_context[:, -1, :]\n",
    "\n",
    "        # (batch_size, 1)\n",
    "        # Equation (22)\n",
    "        pred_ = self.layer_prediction_fc_1(tf.concat([last_hidden_state, last_context], axis=-1))\n",
    "        pred__ = self.layer_prediction_fc_2(pred_)\n",
    "        pred= self.layer_prediction_fc_3(pred__)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DARNN():\n",
    "    def __init__(self,  num_series, encoder_dim, decoder_dim, num_steps, stateful_encoder=False, stateful_decoder=False):\n",
    "        super(self.__class__, self).__init__()\n",
    "        encoder_steps=num_steps+1\n",
    "        self.encoder = Encoder(encoder_dim, encoder_steps)\n",
    "\n",
    "        self.decoder = Decoder(decoder_dim, num_steps)\n",
    "    def __call__(self, X_history, y_history):\n",
    "        out =self.decoder(self.encoder(X_history),X_history, y_history) \n",
    "        #TemporalAttentionDecoder.forward(id(self.decoder),InputAttentionEncoder.forward(id(self.encoder),X_history), X_history,y_history)\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    \"\"\"\n",
    "    모든 예측모델들의 기본 클래스\n",
    "    \"\"\"\n",
    "    def __init__(self,sess,name,windowsize,Pos,Neg):\n",
    "        self.sess=sess\n",
    "        self.name=name\n",
    "        self.T=windowsize\n",
    "        self.P=Pos\n",
    "        self.N=Neg\n",
    "\n",
    "        \n",
    "        self._build_net()\n",
    "\n",
    "    def _build_net(self):\n",
    "        pass\n",
    "\n",
    "class LSTM_Model(Model):\n",
    "    \"\"\"\n",
    "    Basic LSTM list for test.\n",
    "    \"\"\"\n",
    "    def _build_net(self):\n",
    "       \n",
    "        #tf. compat.v1.reset_default_graph()\n",
    "        self.Y=tf.compat.v1.placeholder(tf.float32,[None,self.T,1])\n",
    "        self.Xp=tf.compat.v1.placeholder(tf.float32,[None,self.P,self.T,1])\n",
    "        self.Xn=tf.compat.v1.placeholder(tf.float32,[None,self.N,self.T,1])\n",
    "        self.Xi=tf.compat.v1.placeholder(tf.float32,[None,self.T,1])\n",
    "        self.Target=tf.compat.v1.placeholder(tf.float32,[None,1])\n",
    "\n",
    "\n",
    "        Xps=tf.split(self.Xp,self.P,1)\n",
    "        Xns=tf.split(self.Xn,self.N,1)\n",
    "        Xp_list=[]\n",
    "        Xn_list=[]\n",
    "\n",
    "    \n",
    "        LSTM=tf.compat.v1.nn.rnn_cell.LSTMCell(64,name='lstm1')\n",
    "        \n",
    "        Y_1,_=tf.compat.v1.nn.dynamic_rnn(LSTM,self.Y,dtype=tf.float32)\n",
    "        Xi_1,_=tf.compat.v1.nn.dynamic_rnn(LSTM,self.Xi,dtype=tf.float32)\n",
    "        for i in range(len(Xps)):\n",
    "            o,_=tf.compat.v1.nn.dynamic_rnn(LSTM,tf.squeeze(Xps[i],axis=1),dtype=tf.float32)\n",
    "            Xp_list.append(o)\n",
    "        for i in range(len(Xns)):\n",
    "            o,_=tf.compat.v1.nn.dynamic_rnn(LSTM,tf.squeeze(Xns[i],axis=1),dtype=tf.float32)\n",
    "            Xn_list.append(o)\n",
    "        Xp_1=tf.reduce_mean(Xp_list,0)\n",
    "        Xn_1=tf.reduce_mean(Xn_list,0)\n",
    "\n",
    "        result=tf.concat([Y_1,Xp_1,Xn_1,Xi_1],axis=2)\n",
    "        print(\"result = \" , result)\n",
    "\n",
    "        #MI-LSTM\n",
    "        LSTM2=MI_LSTMCell(64,4,name='lstm2')\n",
    "        print(\"LSTM2 = \" , LSTM2)\n",
    "        Y_2,_ =tf.compat.v1.nn.dynamic_rnn(LSTM2,result,dtype=tf.float32)\n",
    "        print(\"Y_2 = \" , Y_2.shape)\n",
    "\n",
    "        #Attention_Layer\n",
    "        \n",
    "        \n",
    "        model = DARNN(64, 64, 64, self.T) \n",
    "        y_pred = model(Y_2, self.Y) \n",
    "        print(\"y_pred : \" , y_pred )\n",
    "        #y_pred = tf.squeeze(y_pred)\n",
    "        #print(\"y_pred : \" , y_pred )\n",
    "\n",
    "        #Non-linear units for producing final prediction.\n",
    "       \n",
    "\n",
    "        self.out=y_pred\n",
    "        #self.out=Y_2\n",
    "        \n",
    "        self.cost=tf.compat.v1.losses.mean_squared_error(labels=self.Target,predictions=self.out)\n",
    "        self.optimizer=tf.compat.v1.train.AdamOptimizer(0.001).minimize(self.cost)\n",
    "\n",
    "    def outputs(self,y,xp,xn,xi,target):\n",
    "        fd={self.Y:y,self.Xp:xp,self.Xn:xn,self.Xi:xi,self.Target:target}\n",
    "        return self.sess.run(self.out,feed_dict=fd)\n",
    "    \n",
    "\n",
    "\n",
    "    def training(self,y,xp,xn,xi,target):\n",
    "        fd={self.Y:y,self.Xp:xp,self.Xn:xn,self.Xi:xi,self.Target:target}\n",
    "        return self.sess.run([self.cost,self.optimizer],feed_dict=fd)\n",
    "\n",
    "    def returnCost(self,y,xp,xn,xi,target):\n",
    "        fd={self.Y:y,self.Xp:xp,self.Xn:xn,self.Xi:xi,self.Target:target}\n",
    "        return self.sess.run(self.cost,feed_dict=fd)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexPrice shape:  (3000, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-733669196d7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mnegative_correlation_sotck_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mtrain_test_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     batch_size)\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ae46c64248b5>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, folderPath, indexPath, timewindowsize, windowsizeForPCC, PostiveStockNumber, NegativeStockNumber, train_test_rate, batchSize)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexPrice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstockPrice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainSet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestSet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ae46c64248b5>\u001b[0m in \u001b[0;36mloadCSV\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcsv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcsvList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolderPath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_duration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_duration\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m   2462\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_date_conversions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2464\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2465\u001b[0m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malldata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexnamerow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_convert_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2532\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2533\u001b[0m             \u001b[0mclean_conv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2534\u001b[0;31m             \u001b[0mclean_dtypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2535\u001b[0m         )\n\u001b[1;32m   2536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_convert_to_ndarrays\u001b[0;34m(self, dct, na_values, na_fvalues, verbose, converters, dtypes)\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0;31m# general type inference and conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m                 cvals, na_count = self._infer_types(\n\u001b[0;32m-> 1709\u001b[0;31m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_na_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mcol_na_fvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_num_bool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1710\u001b[0m                 )\n\u001b[1;32m   1711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_infer_types\u001b[0;34m(self, values, na_values, try_num_bool)\u001b[0m\n\u001b[1;32m   1761\u001b[0m             \u001b[0;31m# exclude e.g DatetimeIndex here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1762\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1763\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_convert_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1764\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m                 \u001b[0;31m# e.g. encountering datetime string gets ValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.keras.backend.clear_session()\n",
    "#tf.compat.v1.reset_default_graph()\n",
    "#parameter list\n",
    "'''\n",
    "sess=tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(allow_soft_placement=True))\n",
    "name='lstm'\n",
    "timesize=20\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "#\n",
    "'''\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=16\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=256\n",
    "\n",
    "\n",
    "kospi=StockData(\n",
    "    'NASDAQ/Sample',\n",
    "    'NASDAQ/NDX.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "\n",
    "\n",
    "\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    \n",
    "result_dic={}\n",
    "    \n",
    "for i in range(100):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "    \n",
    "    #training batch\n",
    "    \n",
    "    for batch in kospi.getBatch('training'):        \n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    \n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(training_cost)\n",
    "    print(evalution_cost)\n",
    "    \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "    i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/user/Desktop/MI-LSTM-master'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexPrice shape:  (3000, 1)\n",
      "StockPrice shape:  (3000, 26)\n",
      "making dataset progress : finished\t\n",
      "WARNING:tensorflow:From <ipython-input-6-5e94407ee4da>:38: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-6-5e94407ee4da>:40: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "result =  Tensor(\"concat:0\", shape=(None, 16, 256), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-3-a8129d876eea>:55: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "LSTM2 =  <__main__.MI_LSTMCell object at 0x7fe53d94b350>\n",
      "WARNING:tensorflow:From <ipython-input-3-a8129d876eea>:76: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "Y_2 =  (None, 16, 64)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7fe53d8fe7d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7fe53d6fda10>, <gast.gast.Return object at 0x7fe53d7baf50>]\n",
      "WARNING: AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7fe53d8fe7d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7fe53d6fda10>, <gast.gast.Return object at 0x7fe53d7baf50>]\n",
      "inputs :  Tensor(\"rnn_22/transpose_1:0\", shape=(None, 16, 64), dtype=float32)\n",
      "weight :  Tensor(\"attention_1/Squeeze:0\", shape=(None, 16), dtype=float32)\n",
      "encoder_states :  Tensor(\"encoder/transpose_1:0\", shape=(None, 16, 64), dtype=float32)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7fe53d8a5e90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7fe53d3e4610>, <gast.gast.Return object at 0x7fe53d3e4890>]\n",
      "WARNING: AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7fe53d8a5e90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7fe53d3e4610>, <gast.gast.Return object at 0x7fe53d3e4890>]\n",
      "y_pred :  Tensor(\"decoder/dense_5/BiasAdd:0\", shape=(None, 1), dtype=float32)\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "11.363603100180626\n",
      "1.540133960545063\n",
      "epoch : 0, t_cost : 0.109265, e_cost : 0.035003, elapsed time : 24.48sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "2.233375327195972\n",
      "0.5472392998635769\n",
      "epoch : 1, t_cost : 0.021475, e_cost : 0.012437, elapsed time : 18.08sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "1.3814070464577526\n",
      "0.36175614641979337\n",
      "epoch : 2, t_cost : 0.013283, e_cost : 0.008222, elapsed time : 18.10sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "1.2083699980285019\n",
      "0.3127446649596095\n",
      "epoch : 3, t_cost : 0.011619, e_cost : 0.007108, elapsed time : 18.11sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "1.1514030238613486\n",
      "0.3091584958601743\n",
      "epoch : 4, t_cost : 0.011071, e_cost : 0.007026, elapsed time : 18.26sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "1.3119532261043787\n",
      "0.3033983623608947\n",
      "epoch : 5, t_cost : 0.012615, e_cost : 0.006895, elapsed time : 18.26sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "1.421617530286312\n",
      "0.3242070615524426\n",
      "epoch : 6, t_cost : 0.013669, e_cost : 0.007368, elapsed time : 18.29sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "1.2429755085613579\n",
      "0.2870619052555412\n",
      "epoch : 7, t_cost : 0.011952, e_cost : 0.006524, elapsed time : 18.22sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "1.23880180506967\n",
      "0.2608862417982891\n",
      "epoch : 8, t_cost : 0.011912, e_cost : 0.005929, elapsed time : 18.15sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "1.3541334795299917\n",
      "0.25196155661251396\n",
      "epoch : 9, t_cost : 0.013021, e_cost : 0.005726, elapsed time : 18.28sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "1.0760839784052223\n",
      "0.2308840057812631\n",
      "epoch : 10, t_cost : 0.010347, e_cost : 0.005247, elapsed time : 18.17sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "1.1986712848301977\n",
      "0.22086108243092895\n",
      "epoch : 11, t_cost : 0.011526, e_cost : 0.005020, elapsed time : 18.22sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8259276915341616\n",
      "0.27595630032010376\n",
      "epoch : 12, t_cost : 0.007942, e_cost : 0.006272, elapsed time : 18.22sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "0.9920226528774947\n",
      "0.1758148712106049\n",
      "epoch : 13, t_cost : 0.009539, e_cost : 0.003996, elapsed time : 18.20sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "0.818804943934083\n",
      "0.1369377807714045\n",
      "epoch : 14, t_cost : 0.007873, e_cost : 0.003112, elapsed time : 18.23sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "0.7390885669738054\n",
      "0.12561845814343542\n",
      "epoch : 15, t_cost : 0.007107, e_cost : 0.002855, elapsed time : 18.26sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "0.7332027265802026\n",
      "0.11496526683913544\n",
      "epoch : 16, t_cost : 0.007050, e_cost : 0.002613, elapsed time : 18.22sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "0.634300148813054\n",
      "0.10833210754208267\n",
      "epoch : 17, t_cost : 0.006099, e_cost : 0.002462, elapsed time : 18.22sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "0.5530863675521687\n",
      "0.10799740499351174\n",
      "epoch : 18, t_cost : 0.005318, e_cost : 0.002454, elapsed time : 18.28sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "0.6271143939811736\n",
      "0.09760194882983342\n",
      "epoch : 19, t_cost : 0.006030, e_cost : 0.002218, elapsed time : 18.21sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "0.48923955822829157\n",
      "0.09435926104197279\n",
      "epoch : 20, t_cost : 0.004704, e_cost : 0.002145, elapsed time : 18.25sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "0.5173909569857642\n",
      "0.08714917412726209\n",
      "epoch : 21, t_cost : 0.004975, e_cost : 0.001981, elapsed time : 18.31sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "0.43977224407717586\n",
      "0.0844877096824348\n",
      "epoch : 22, t_cost : 0.004229, e_cost : 0.001920, elapsed time : 18.23sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "0.45445857086451724\n",
      "0.08815400919411331\n",
      "epoch : 23, t_cost : 0.004370, e_cost : 0.002004, elapsed time : 18.20sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "0.38785866904072464\n",
      "0.08429192926269025\n",
      "epoch : 24, t_cost : 0.003729, e_cost : 0.001916, elapsed time : 18.24sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "0.44531710125738755\n",
      "0.09854204772273079\n",
      "epoch : 25, t_cost : 0.004282, e_cost : 0.002240, elapsed time : 18.22sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "0.40240813250420615\n",
      "0.0810529175796546\n",
      "epoch : 26, t_cost : 0.003869, e_cost : 0.001842, elapsed time : 18.18sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "0.43261546338908374\n",
      "0.0776832575793378\n",
      "epoch : 27, t_cost : 0.004160, e_cost : 0.001766, elapsed time : 18.20sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "0.37998707266524434\n",
      "0.07846081559546292\n",
      "epoch : 28, t_cost : 0.003654, e_cost : 0.001783, elapsed time : 18.26sec\n",
      "(53690, 16, 1) (53690, 10, 16, 1) (53690, 10, 16, 1) (53690, 16, 1) (53690, 1)\n",
      "(23010, 16, 1) (23010, 10, 16, 1) (23010, 10, 16, 1) (23010, 16, 1) (23010, 1)\n",
      "0.4139398956322111\n",
      "0.08205939532490447\n",
      "epoch : 29, t_cost : 0.003980, e_cost : 0.001865, elapsed time : 18.28sec\n",
      "\n",
      "#Best result at epoch 27\n",
      "t_cost : 0.004160, e_cost : 0.001766\n"
     ]
    }
   ],
   "source": [
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.keras.backend.clear_session()\n",
    "#tf.compat.v1.reset_default_graph()\n",
    "#parameter list\n",
    "'''\n",
    "sess=tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(allow_soft_placement=True))\n",
    "name='lstm'\n",
    "timesize=20\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "#\n",
    "'''\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=16\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "\n",
    "\n",
    "kospi=StockData(\n",
    "    'StockChart/SAMPLE',\n",
    "    'StockChart/KOSPI.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "\n",
    "\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    \n",
    "result_dic={}\n",
    "    \n",
    "for i in range(30):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "    \n",
    "    #training batch\n",
    "    \n",
    "    for batch in kospi.getBatch('training'):        \n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    \n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(training_cost)\n",
    "    print(evalution_cost)\n",
    "    \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "    i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## epoch : 10 , batchsize : 512 , timesize : 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexPrice shape:  (3000, 1)\n",
      "StockPrice shape:  (3000, 26)\n",
      "making dataset progress : finished\t\n",
      "WARNING:tensorflow:From <ipython-input-6-5e94407ee4da>:38: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-6-5e94407ee4da>:40: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "result =  Tensor(\"concat:0\", shape=(None, 4, 256), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-3-a8129d876eea>:55: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "LSTM2 =  <__main__.MI_LSTMCell object at 0x7fd51c90b5d0>\n",
      "WARNING:tensorflow:From <ipython-input-3-a8129d876eea>:76: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "Y_2 =  (None, 4, 64)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7fd51c873110>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7fd51c6d9d90>, <gast.gast.Return object at 0x7fd51c75bf10>]\n",
      "WARNING: AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7fd51c873110>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7fd51c6d9d90>, <gast.gast.Return object at 0x7fd51c75bf10>]\n",
      "inputs :  Tensor(\"rnn_22/transpose_1:0\", shape=(None, 4, 64), dtype=float32)\n",
      "weight :  Tensor(\"attention_1/Squeeze:0\", shape=(None, 4), dtype=float32)\n",
      "encoder_states :  Tensor(\"encoder/transpose_1:0\", shape=(None, 4, 64), dtype=float32)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7fd51c92ef90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7fd51c4100d0>, <gast.gast.Return object at 0x7fd51c410b50>]\n",
      "WARNING: AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7fd51c92ef90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7fd51c4100d0>, <gast.gast.Return object at 0x7fd51c410b50>]\n",
      "y_pred :  Tensor(\"decoder/dense_5/BiasAdd:0\", shape=(None, 1), dtype=float32)\n",
      "(53690, 4, 1) (53690, 10, 4, 1) (53690, 10, 4, 1) (53690, 4, 1) (53690, 1)\n",
      "(23010, 4, 1) (23010, 10, 4, 1) (23010, 10, 4, 1) (23010, 4, 1) (23010, 1)\n",
      "17.868059158325195\n",
      "5.904313430190086\n",
      "epoch : 0, t_cost : 0.171808, e_cost : 0.134189, elapsed time : 11.22sec\n",
      "(53690, 4, 1) (53690, 10, 4, 1) (53690, 10, 4, 1) (53690, 4, 1) (53690, 1)\n",
      "(23010, 4, 1) (23010, 10, 4, 1) (23010, 10, 4, 1) (23010, 4, 1) (23010, 1)\n",
      "6.1038724556565285\n",
      "1.010523329488933\n",
      "epoch : 1, t_cost : 0.058691, e_cost : 0.022966, elapsed time : 5.08sec\n",
      "(53690, 4, 1) (53690, 10, 4, 1) (53690, 10, 4, 1) (53690, 4, 1) (53690, 1)\n",
      "(23010, 4, 1) (23010, 10, 4, 1) (23010, 10, 4, 1) (23010, 4, 1) (23010, 1)\n",
      "1.1225434024818242\n",
      "0.34611545223742723\n",
      "epoch : 2, t_cost : 0.010794, e_cost : 0.007866, elapsed time : 5.11sec\n",
      "(53690, 4, 1) (53690, 10, 4, 1) (53690, 10, 4, 1) (53690, 4, 1) (53690, 1)\n",
      "(23010, 4, 1) (23010, 10, 4, 1) (23010, 10, 4, 1) (23010, 4, 1) (23010, 1)\n",
      "0.9596833174582571\n",
      "0.2133062221109867\n",
      "epoch : 3, t_cost : 0.009228, e_cost : 0.004848, elapsed time : 5.15sec\n",
      "(53690, 4, 1) (53690, 10, 4, 1) (53690, 10, 4, 1) (53690, 4, 1) (53690, 1)\n",
      "(23010, 4, 1) (23010, 10, 4, 1) (23010, 10, 4, 1) (23010, 4, 1) (23010, 1)\n",
      "0.8950542255770415\n",
      "0.1848302847938612\n",
      "epoch : 4, t_cost : 0.008606, e_cost : 0.004201, elapsed time : 5.08sec\n",
      "(53690, 4, 1) (53690, 10, 4, 1) (53690, 10, 4, 1) (53690, 4, 1) (53690, 1)\n",
      "(23010, 4, 1) (23010, 10, 4, 1) (23010, 10, 4, 1) (23010, 4, 1) (23010, 1)\n",
      "0.7314331757370383\n",
      "0.16134718211833388\n",
      "epoch : 5, t_cost : 0.007033, e_cost : 0.003667, elapsed time : 5.08sec\n",
      "(53690, 4, 1) (53690, 10, 4, 1) (53690, 10, 4, 1) (53690, 4, 1) (53690, 1)\n",
      "(23010, 4, 1) (23010, 10, 4, 1) (23010, 10, 4, 1) (23010, 4, 1) (23010, 1)\n",
      "0.6645605911035091\n",
      "0.15601584664545953\n",
      "epoch : 6, t_cost : 0.006390, e_cost : 0.003546, elapsed time : 5.10sec\n",
      "(53690, 4, 1) (53690, 10, 4, 1) (53690, 10, 4, 1) (53690, 4, 1) (53690, 1)\n",
      "(23010, 4, 1) (23010, 10, 4, 1) (23010, 10, 4, 1) (23010, 4, 1) (23010, 1)\n",
      "0.6870169979520142\n",
      "0.1574132569367066\n",
      "epoch : 7, t_cost : 0.006606, e_cost : 0.003578, elapsed time : 5.09sec\n",
      "(53690, 4, 1) (53690, 10, 4, 1) (53690, 10, 4, 1) (53690, 4, 1) (53690, 1)\n",
      "(23010, 4, 1) (23010, 10, 4, 1) (23010, 10, 4, 1) (23010, 4, 1) (23010, 1)\n",
      "0.7603310645790771\n",
      "0.1422596968477592\n",
      "epoch : 8, t_cost : 0.007311, e_cost : 0.003233, elapsed time : 5.10sec\n",
      "(53690, 4, 1) (53690, 10, 4, 1) (53690, 10, 4, 1) (53690, 4, 1) (53690, 1)\n",
      "(23010, 4, 1) (23010, 10, 4, 1) (23010, 10, 4, 1) (23010, 4, 1) (23010, 1)\n",
      "0.8800395268481225\n",
      "0.13360532734077424\n",
      "epoch : 9, t_cost : 0.008462, e_cost : 0.003036, elapsed time : 5.22sec\n",
      "\n",
      "#Best result at epoch 9\n",
      "t_cost : 0.008462, e_cost : 0.003036\n"
     ]
    }
   ],
   "source": [
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.keras.backend.clear_session()\n",
    "#tf.compat.v1.reset_default_graph()\n",
    "#parameter list\n",
    "'''\n",
    "sess=tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(allow_soft_placement=True))\n",
    "name='lstm'\n",
    "timesize=20\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "#\n",
    "'''\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=4\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "\n",
    "\n",
    "kospi=StockData(\n",
    "    'StockChart/SAMPLE',\n",
    "    'StockChart/KOSPI.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "\n",
    "\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    \n",
    "result_dic={}\n",
    "    \n",
    "for i in range(10):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "    \n",
    "    #training batch\n",
    "    \n",
    "    for batch in kospi.getBatch('training'):        \n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    \n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(training_cost)\n",
    "    print(evalution_cost)\n",
    "    \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "    i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## epoch : 100 , batchsize : 256 , timesize : 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexPrice shape:  (3000, 1)\n",
      "StockPrice shape:  (3000, 26)\n",
      "making dataset progress : finished\t\n",
      "WARNING:tensorflow:From <ipython-input-6-5e94407ee4da>:38: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-6-5e94407ee4da>:40: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "result =  Tensor(\"concat:0\", shape=(None, 8, 256), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-3-a8129d876eea>:55: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "LSTM2 =  <__main__.MI_LSTMCell object at 0x7f6e3428cd90>\n",
      "WARNING:tensorflow:From <ipython-input-3-a8129d876eea>:76: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "Y_2 =  (None, 8, 64)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f6e34047510>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f6e07e915d0>, <gast.gast.Return object at 0x7f6e07f6df10>]\n",
      "WARNING: AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f6e34047510>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f6e07e915d0>, <gast.gast.Return object at 0x7f6e07f6df10>]\n",
      "inputs :  Tensor(\"rnn_22/transpose_1:0\", shape=(None, 8, 64), dtype=float32)\n",
      "weight :  Tensor(\"attention_1/Squeeze:0\", shape=(None, 8), dtype=float32)\n",
      "encoder_states :  Tensor(\"encoder/transpose_1:0\", shape=(None, 8, 64), dtype=float32)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f6e07fd6510>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f6e07b67150>, <gast.gast.Return object at 0x7f6e07b67d90>]\n",
      "WARNING: AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f6e07fd6510>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f6e07b67150>, <gast.gast.Return object at 0x7f6e07b67d90>]\n",
      "y_pred :  Tensor(\"decoder/dense_5/BiasAdd:0\", shape=(None, 1), dtype=float32)\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "12.055350787006319\n",
      "1.1397891263477504\n",
      "epoch : 0, t_cost : 0.057681, e_cost : 0.012807, elapsed time : 24.65sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "1.6962703340686858\n",
      "0.6582358733285218\n",
      "epoch : 1, t_cost : 0.008116, e_cost : 0.007396, elapsed time : 18.56sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "1.4861938280519098\n",
      "0.5033522085286677\n",
      "epoch : 2, t_cost : 0.007111, e_cost : 0.005656, elapsed time : 18.56sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "1.3325331900268793\n",
      "0.5358950744848698\n",
      "epoch : 3, t_cost : 0.006376, e_cost : 0.006021, elapsed time : 18.53sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "1.2161180432885885\n",
      "0.567311555147171\n",
      "epoch : 4, t_cost : 0.005819, e_cost : 0.006374, elapsed time : 18.53sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "1.1134396390989423\n",
      "0.5587203771574423\n",
      "epoch : 5, t_cost : 0.005327, e_cost : 0.006278, elapsed time : 18.56sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "1.0045428903540596\n",
      "0.49661919043865055\n",
      "epoch : 6, t_cost : 0.004806, e_cost : 0.005580, elapsed time : 18.69sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.9012413780437782\n",
      "0.44932627223897725\n",
      "epoch : 7, t_cost : 0.004312, e_cost : 0.005049, elapsed time : 18.73sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.8119559821789153\n",
      "0.413634188065771\n",
      "epoch : 8, t_cost : 0.003885, e_cost : 0.004648, elapsed time : 18.57sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.7419006243580952\n",
      "0.36728325387230143\n",
      "epoch : 9, t_cost : 0.003550, e_cost : 0.004127, elapsed time : 18.56sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6843153169029392\n",
      "0.3350683269673027\n",
      "epoch : 10, t_cost : 0.003274, e_cost : 0.003765, elapsed time : 18.58sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6363553609116934\n",
      "0.28445410751737654\n",
      "epoch : 11, t_cost : 0.003045, e_cost : 0.003196, elapsed time : 18.65sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.584377684223\n",
      "0.2597724503139034\n",
      "epoch : 12, t_cost : 0.002796, e_cost : 0.002919, elapsed time : 18.60sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.5356677894014865\n",
      "0.25270630681188777\n",
      "epoch : 13, t_cost : 0.002563, e_cost : 0.002839, elapsed time : 18.71sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.497914171370212\n",
      "0.23329754313454032\n",
      "epoch : 14, t_cost : 0.002382, e_cost : 0.002621, elapsed time : 18.85sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.4722733865492046\n",
      "0.21033889742102474\n",
      "epoch : 15, t_cost : 0.002260, e_cost : 0.002363, elapsed time : 18.78sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.44889040966518223\n",
      "0.19472274906001985\n",
      "epoch : 16, t_cost : 0.002148, e_cost : 0.002188, elapsed time : 18.62sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.4301256852922961\n",
      "0.17685286735650152\n",
      "epoch : 17, t_cost : 0.002058, e_cost : 0.001987, elapsed time : 18.80sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.41195391782093793\n",
      "0.16287731507327408\n",
      "epoch : 18, t_cost : 0.001971, e_cost : 0.001830, elapsed time : 18.71sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.40519637367106043\n",
      "0.16455081137246452\n",
      "epoch : 19, t_cost : 0.001939, e_cost : 0.001849, elapsed time : 18.59sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.407609079265967\n",
      "0.137370272714179\n",
      "epoch : 20, t_cost : 0.001950, e_cost : 0.001543, elapsed time : 18.59sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3791985104326159\n",
      "0.12753512780182064\n",
      "epoch : 21, t_cost : 0.001814, e_cost : 0.001433, elapsed time : 18.59sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.36813552377861924\n",
      "0.12826406708336435\n",
      "epoch : 22, t_cost : 0.001761, e_cost : 0.001441, elapsed time : 18.59sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3637861073948443\n",
      "0.12517899041995406\n",
      "epoch : 23, t_cost : 0.001741, e_cost : 0.001407, elapsed time : 18.57sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.35186881438130513\n",
      "0.11800637721898966\n",
      "epoch : 24, t_cost : 0.001684, e_cost : 0.001326, elapsed time : 18.57sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.34421261301031336\n",
      "0.11671053466852754\n",
      "epoch : 25, t_cost : 0.001647, e_cost : 0.001311, elapsed time : 18.58sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.34030611475463957\n",
      "0.11700478463899344\n",
      "epoch : 26, t_cost : 0.001628, e_cost : 0.001315, elapsed time : 18.85sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.34090487254434265\n",
      "0.11225664676749147\n",
      "epoch : 27, t_cost : 0.001631, e_cost : 0.001261, elapsed time : 18.68sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3369318998302333\n",
      "0.11221710973768495\n",
      "epoch : 28, t_cost : 0.001612, e_cost : 0.001261, elapsed time : 18.66sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3338407629635185\n",
      "0.11175113683566451\n",
      "epoch : 29, t_cost : 0.001597, e_cost : 0.001256, elapsed time : 18.73sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3343617102364078\n",
      "0.10959855929831974\n",
      "epoch : 30, t_cost : 0.001600, e_cost : 0.001231, elapsed time : 18.78sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.33083574613556266\n",
      "0.10791902069468051\n",
      "epoch : 31, t_cost : 0.001583, e_cost : 0.001213, elapsed time : 18.80sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.32954052108107135\n",
      "0.10512834443943575\n",
      "epoch : 32, t_cost : 0.001577, e_cost : 0.001181, elapsed time : 18.68sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3182354853488505\n",
      "0.10557407763553783\n",
      "epoch : 33, t_cost : 0.001523, e_cost : 0.001186, elapsed time : 18.69sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.31675396850914694\n",
      "0.10429946496151388\n",
      "epoch : 34, t_cost : 0.001516, e_cost : 0.001172, elapsed time : 18.74sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3156512552232016\n",
      "0.10437779888161458\n",
      "epoch : 35, t_cost : 0.001510, e_cost : 0.001173, elapsed time : 18.69sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.31516303643002175\n",
      "0.10497120639774948\n",
      "epoch : 36, t_cost : 0.001508, e_cost : 0.001179, elapsed time : 18.64sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3130954260705039\n",
      "0.10503501465427689\n",
      "epoch : 37, t_cost : 0.001498, e_cost : 0.001180, elapsed time : 18.68sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3155330910230987\n",
      "0.10397621657466516\n",
      "epoch : 38, t_cost : 0.001510, e_cost : 0.001168, elapsed time : 18.75sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3190402886539232\n",
      "0.10509506217204034\n",
      "epoch : 39, t_cost : 0.001527, e_cost : 0.001181, elapsed time : 18.81sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3153256225923542\n",
      "0.10173315633437596\n",
      "epoch : 40, t_cost : 0.001509, e_cost : 0.001143, elapsed time : 18.69sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3088307890284341\n",
      "0.10172217569197528\n",
      "epoch : 41, t_cost : 0.001478, e_cost : 0.001143, elapsed time : 18.75sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3063025971350726\n",
      "0.10137803055113181\n",
      "epoch : 42, t_cost : 0.001466, e_cost : 0.001139, elapsed time : 18.69sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3059956045472063\n",
      "0.10090674430830404\n",
      "epoch : 43, t_cost : 0.001464, e_cost : 0.001134, elapsed time : 18.55sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3030695367488079\n",
      "0.10263928840868175\n",
      "epoch : 44, t_cost : 0.001450, e_cost : 0.001153, elapsed time : 18.57sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3018388344789855\n",
      "0.10306061952724122\n",
      "epoch : 45, t_cost : 0.001444, e_cost : 0.001158, elapsed time : 18.58sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.30384274272364564\n",
      "0.10224196963827126\n",
      "epoch : 46, t_cost : 0.001454, e_cost : 0.001149, elapsed time : 18.58sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.30384844285435975\n",
      "0.10405948117841035\n",
      "epoch : 47, t_cost : 0.001454, e_cost : 0.001169, elapsed time : 18.57sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.30186125336331315\n",
      "0.10302343318471685\n",
      "epoch : 48, t_cost : 0.001444, e_cost : 0.001158, elapsed time : 18.59sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2990770653996151\n",
      "0.10435262619284913\n",
      "epoch : 49, t_cost : 0.001431, e_cost : 0.001173, elapsed time : 18.59sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2977415325876791\n",
      "0.10527231651940383\n",
      "epoch : 50, t_cost : 0.001425, e_cost : 0.001183, elapsed time : 18.56sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2968549261568114\n",
      "0.10257576368167065\n",
      "epoch : 51, t_cost : 0.001420, e_cost : 0.001153, elapsed time : 18.58sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2979189038160257\n",
      "0.10326516677741893\n",
      "epoch : 52, t_cost : 0.001425, e_cost : 0.001160, elapsed time : 18.56sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.29516037536086515\n",
      "0.10325717602972873\n",
      "epoch : 53, t_cost : 0.001412, e_cost : 0.001160, elapsed time : 18.56sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2948396094434429\n",
      "0.10386810597265139\n",
      "epoch : 54, t_cost : 0.001411, e_cost : 0.001167, elapsed time : 18.56sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2949230401427485\n",
      "0.10449163313023746\n",
      "epoch : 55, t_cost : 0.001411, e_cost : 0.001174, elapsed time : 18.58sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2934409544686787\n",
      "0.10316135597531684\n",
      "epoch : 56, t_cost : 0.001404, e_cost : 0.001159, elapsed time : 18.56sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2922257542668376\n",
      "0.10342665846110322\n",
      "epoch : 57, t_cost : 0.001398, e_cost : 0.001162, elapsed time : 18.55sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.29238814997370355\n",
      "0.10209973799646832\n",
      "epoch : 58, t_cost : 0.001399, e_cost : 0.001147, elapsed time : 18.57sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2922299809579272\n",
      "0.10164820146746933\n",
      "epoch : 59, t_cost : 0.001398, e_cost : 0.001142, elapsed time : 18.73sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2921300547022838\n",
      "0.1013196567655541\n",
      "epoch : 60, t_cost : 0.001398, e_cost : 0.001138, elapsed time : 18.87sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2906671553500928\n",
      "0.10137491489876993\n",
      "epoch : 61, t_cost : 0.001391, e_cost : 0.001139, elapsed time : 18.82sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2900271031539887\n",
      "0.10007273580413312\n",
      "epoch : 62, t_cost : 0.001388, e_cost : 0.001124, elapsed time : 18.58sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.28938313518301584\n",
      "0.10050111880991608\n",
      "epoch : 63, t_cost : 0.001385, e_cost : 0.001129, elapsed time : 18.65sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.28932755676214583\n",
      "0.1004702631616965\n",
      "epoch : 64, t_cost : 0.001384, e_cost : 0.001129, elapsed time : 18.56sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2890954385220539\n",
      "0.09990983930765651\n",
      "epoch : 65, t_cost : 0.001383, e_cost : 0.001123, elapsed time : 18.55sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2878297363931779\n",
      "0.09978257791954093\n",
      "epoch : 66, t_cost : 0.001377, e_cost : 0.001121, elapsed time : 18.55sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2859304996090941\n",
      "0.10019509479752742\n",
      "epoch : 67, t_cost : 0.001368, e_cost : 0.001126, elapsed time : 18.58sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.28481849504169077\n",
      "0.09965183411259204\n",
      "epoch : 68, t_cost : 0.001363, e_cost : 0.001120, elapsed time : 18.58sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2847490070562344\n",
      "0.09926203323993832\n",
      "epoch : 69, t_cost : 0.001362, e_cost : 0.001115, elapsed time : 18.54sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.28441898452001624\n",
      "0.10007859897450544\n",
      "epoch : 70, t_cost : 0.001361, e_cost : 0.001124, elapsed time : 18.57sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.28447291496559046\n",
      "0.0996009806112852\n",
      "epoch : 71, t_cost : 0.001361, e_cost : 0.001119, elapsed time : 18.58sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2848152536316775\n",
      "0.09916364095988683\n",
      "epoch : 72, t_cost : 0.001363, e_cost : 0.001114, elapsed time : 18.55sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2834008915233426\n",
      "0.09918387146899477\n",
      "epoch : 73, t_cost : 0.001356, e_cost : 0.001114, elapsed time : 18.57sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2826268576900475\n",
      "0.09822553707635961\n",
      "epoch : 74, t_cost : 0.001352, e_cost : 0.001104, elapsed time : 18.58sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2813781432050746\n",
      "0.0981254251964856\n",
      "epoch : 75, t_cost : 0.001346, e_cost : 0.001103, elapsed time : 18.56sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2811375454766676\n",
      "0.09797323847305961\n",
      "epoch : 76, t_cost : 0.001345, e_cost : 0.001101, elapsed time : 18.55sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.28091360718826763\n",
      "0.09880320084630512\n",
      "epoch : 77, t_cost : 0.001344, e_cost : 0.001110, elapsed time : 18.57sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2809715959301684\n",
      "0.09949172881897539\n",
      "epoch : 78, t_cost : 0.001344, e_cost : 0.001118, elapsed time : 18.56sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2805501098919194\n",
      "0.09887804568279535\n",
      "epoch : 79, t_cost : 0.001342, e_cost : 0.001111, elapsed time : 18.65sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2805583183944691\n",
      "0.09921637421939522\n",
      "epoch : 80, t_cost : 0.001342, e_cost : 0.001115, elapsed time : 18.80sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2804559035866987\n",
      "0.09889403151464649\n",
      "epoch : 81, t_cost : 0.001342, e_cost : 0.001111, elapsed time : 18.56sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2799000318918843\n",
      "0.09899293156922795\n",
      "epoch : 82, t_cost : 0.001339, e_cost : 0.001112, elapsed time : 18.56sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.27860602212604135\n",
      "0.09913189022336155\n",
      "epoch : 83, t_cost : 0.001333, e_cost : 0.001114, elapsed time : 18.57sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.278351000190014\n",
      "0.09853295242646709\n",
      "epoch : 84, t_cost : 0.001332, e_cost : 0.001107, elapsed time : 18.68sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.27810777703416534\n",
      "0.09816799260443076\n",
      "epoch : 85, t_cost : 0.001331, e_cost : 0.001103, elapsed time : 18.73sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.27731488092103973\n",
      "0.09803582046879455\n",
      "epoch : 86, t_cost : 0.001327, e_cost : 0.001102, elapsed time : 18.69sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2782015870907344\n",
      "0.10467712100944482\n",
      "epoch : 87, t_cost : 0.001331, e_cost : 0.001176, elapsed time : 18.58sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2798996390483808\n",
      "0.09749068561359309\n",
      "epoch : 88, t_cost : 0.001339, e_cost : 0.001095, elapsed time : 18.57sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2798098878993187\n",
      "0.09854937795898877\n",
      "epoch : 89, t_cost : 0.001339, e_cost : 0.001107, elapsed time : 18.55sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2785262689285446\n",
      "0.09966521750902757\n",
      "epoch : 90, t_cost : 0.001333, e_cost : 0.001120, elapsed time : 18.57sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.27671799549716525\n",
      "0.0989396603545174\n",
      "epoch : 91, t_cost : 0.001324, e_cost : 0.001112, elapsed time : 18.57sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.275965654902393\n",
      "0.09804653085302562\n",
      "epoch : 92, t_cost : 0.001320, e_cost : 0.001102, elapsed time : 18.56sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.27620023488998413\n",
      "0.09806664806092158\n",
      "epoch : 93, t_cost : 0.001322, e_cost : 0.001102, elapsed time : 18.59sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.27447210854734294\n",
      "0.09821276785805821\n",
      "epoch : 94, t_cost : 0.001313, e_cost : 0.001104, elapsed time : 18.55sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.27507997132488526\n",
      "0.09884367574704811\n",
      "epoch : 95, t_cost : 0.001316, e_cost : 0.001111, elapsed time : 18.56sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.27530202115303837\n",
      "0.09959847363643348\n",
      "epoch : 96, t_cost : 0.001317, e_cost : 0.001119, elapsed time : 18.59sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.27496515537495725\n",
      "0.09907086938619614\n",
      "epoch : 97, t_cost : 0.001316, e_cost : 0.001113, elapsed time : 18.58sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2749905925593339\n",
      "0.10018984583439305\n",
      "epoch : 98, t_cost : 0.001316, e_cost : 0.001126, elapsed time : 18.58sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2752626973669976\n",
      "0.09995724458713084\n",
      "epoch : 99, t_cost : 0.001317, e_cost : 0.001123, elapsed time : 18.56sec\n",
      "\n",
      "#Best result at epoch 88\n",
      "t_cost : 0.001339, e_cost : 0.001095\n"
     ]
    }
   ],
   "source": [
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.keras.backend.clear_session()\n",
    "#tf.compat.v1.reset_default_graph()\n",
    "#parameter list\n",
    "'''\n",
    "sess=tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(allow_soft_placement=True))\n",
    "name='lstm'\n",
    "timesize=20\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "#\n",
    "'''\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=8\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=256\n",
    "\n",
    "\n",
    "kospi=StockData(\n",
    "    'StockChart/SAMPLE',\n",
    "    'StockChart/KOSPI.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "\n",
    "\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    \n",
    "result_dic={}\n",
    "    \n",
    "for i in range(100):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "    \n",
    "    #training batch\n",
    "    \n",
    "    for batch in kospi.getBatch('training'):        \n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    \n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(training_cost)\n",
    "    print(evalution_cost)\n",
    "    \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "    i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eopch : 100 , batchsize : 512 , timesize : 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexPrice shape:  (3000, 1)\n",
      "StockPrice shape:  (3000, 26)\n",
      "making dataset progress : finished\t\n",
      "WARNING:tensorflow:From <ipython-input-6-5e94407ee4da>:38: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-6-5e94407ee4da>:40: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "result =  Tensor(\"concat:0\", shape=(None, 8, 256), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-3-a8129d876eea>:55: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "LSTM2 =  <__main__.MI_LSTMCell object at 0x7f62de5b5bd0>\n",
      "WARNING:tensorflow:From <ipython-input-3-a8129d876eea>:76: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "Y_2 =  (None, 8, 64)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f62de4feb90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f62de2fe590>, <gast.gast.Return object at 0x7f62de2fe610>]\n",
      "WARNING: AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f62de4feb90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f62de2fe590>, <gast.gast.Return object at 0x7f62de2fe610>]\n",
      "inputs :  Tensor(\"rnn_22/transpose_1:0\", shape=(None, 8, 64), dtype=float32)\n",
      "weight :  Tensor(\"attention_1/Squeeze:0\", shape=(None, 8), dtype=float32)\n",
      "encoder_states :  Tensor(\"encoder/transpose_1:0\", shape=(None, 8, 64), dtype=float32)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f62de452650>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f62de037710>, <gast.gast.Return object at 0x7f62de037210>]\n",
      "WARNING: AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f62de452650>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f62de037710>, <gast.gast.Return object at 0x7f62de037210>]\n",
      "y_pred :  Tensor(\"decoder/dense_5/BiasAdd:0\", shape=(None, 1), dtype=float32)\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "14.11488427221775\n",
      "2.747168894857168\n",
      "epoch : 0, t_cost : 0.135720, e_cost : 0.062436, elapsed time : 15.57sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "2.4641558094881475\n",
      "0.4469312964938581\n",
      "epoch : 1, t_cost : 0.023694, e_cost : 0.010158, elapsed time : 9.42sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.8924568854272366\n",
      "0.5703237135894597\n",
      "epoch : 2, t_cost : 0.008581, e_cost : 0.012962, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.9384843641892076\n",
      "0.3886103704571724\n",
      "epoch : 3, t_cost : 0.009024, e_cost : 0.008832, elapsed time : 9.46sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.9341743069235235\n",
      "0.37524388160090894\n",
      "epoch : 4, t_cost : 0.008982, e_cost : 0.008528, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.8650052188895643\n",
      "0.508345645503141\n",
      "epoch : 5, t_cost : 0.008317, e_cost : 0.011553, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.7845186139456928\n",
      "0.4167632901808247\n",
      "epoch : 6, t_cost : 0.007543, e_cost : 0.009472, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.7129311574390158\n",
      "0.3658793275244534\n",
      "epoch : 7, t_cost : 0.006855, e_cost : 0.008315, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.667577160638757\n",
      "0.34458805120084435\n",
      "epoch : 8, t_cost : 0.006419, e_cost : 0.007832, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6326450239866972\n",
      "0.3169602326815948\n",
      "epoch : 9, t_cost : 0.006083, e_cost : 0.007204, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6086539200041443\n",
      "0.3003586420090869\n",
      "epoch : 10, t_cost : 0.005852, e_cost : 0.006826, elapsed time : 9.42sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.5919143971987069\n",
      "0.2840445468900725\n",
      "epoch : 11, t_cost : 0.005691, e_cost : 0.006456, elapsed time : 9.41sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.5814796928316355\n",
      "0.2762302753981203\n",
      "epoch : 12, t_cost : 0.005591, e_cost : 0.006278, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.5804583670105785\n",
      "0.3199927171226591\n",
      "epoch : 13, t_cost : 0.005581, e_cost : 0.007273, elapsed time : 9.42sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.5764026711694896\n",
      "0.22586331865750253\n",
      "epoch : 14, t_cost : 0.005542, e_cost : 0.005133, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.5702748560579494\n",
      "0.3035547441104427\n",
      "epoch : 15, t_cost : 0.005483, e_cost : 0.006899, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.5656875588465482\n",
      "0.25106361717917025\n",
      "epoch : 16, t_cost : 0.005439, e_cost : 0.005706, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.563467079307884\n",
      "0.31366777466610074\n",
      "epoch : 17, t_cost : 0.005418, e_cost : 0.007129, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.5511142153991386\n",
      "0.33277526107849553\n",
      "epoch : 18, t_cost : 0.005299, e_cost : 0.007563, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.5460206964053214\n",
      "0.1834672376862727\n",
      "epoch : 19, t_cost : 0.005250, e_cost : 0.004170, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.5177479138365015\n",
      "0.5819407184026204\n",
      "epoch : 20, t_cost : 0.004978, e_cost : 0.013226, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.5362321886932477\n",
      "0.5344580203527585\n",
      "epoch : 21, t_cost : 0.005156, e_cost : 0.012147, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.5636909485328943\n",
      "0.117100301082246\n",
      "epoch : 22, t_cost : 0.005420, e_cost : 0.002661, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.5824633789015934\n",
      "0.18435351946391165\n",
      "epoch : 23, t_cost : 0.005601, e_cost : 0.004190, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6276902051176876\n",
      "0.10397442529210821\n",
      "epoch : 24, t_cost : 0.006035, e_cost : 0.002363, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6804693344165571\n",
      "0.08877451077569276\n",
      "epoch : 25, t_cost : 0.006543, e_cost : 0.002018, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.8207850562175736\n",
      "0.11103066022042185\n",
      "epoch : 26, t_cost : 0.007892, e_cost : 0.002523, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.8136552951764315\n",
      "0.11743543768534437\n",
      "epoch : 27, t_cost : 0.007824, e_cost : 0.002669, elapsed time : 9.46sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.7468568378826603\n",
      "0.08044022141257301\n",
      "epoch : 28, t_cost : 0.007181, e_cost : 0.001828, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.7337834519566968\n",
      "0.06939267454436049\n",
      "epoch : 29, t_cost : 0.007056, e_cost : 0.001577, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6736331046558917\n",
      "0.07869170035701245\n",
      "epoch : 30, t_cost : 0.006477, e_cost : 0.001788, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.4597381692728959\n",
      "0.06639032671228051\n",
      "epoch : 31, t_cost : 0.004421, e_cost : 0.001509, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.40526088315527886\n",
      "0.06163012783508748\n",
      "epoch : 32, t_cost : 0.003897, e_cost : 0.001401, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.39139674935722724\n",
      "0.058881705859676\n",
      "epoch : 33, t_cost : 0.003763, e_cost : 0.001338, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3755293855792843\n",
      "0.059701412508729845\n",
      "epoch : 34, t_cost : 0.003611, e_cost : 0.001357, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3567765650805086\n",
      "0.058356318942969665\n",
      "epoch : 35, t_cost : 0.003431, e_cost : 0.001326, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3404136764584109\n",
      "0.058278823911678046\n",
      "epoch : 36, t_cost : 0.003273, e_cost : 0.001325, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3267782946350053\n",
      "0.05911913141608238\n",
      "epoch : 37, t_cost : 0.003142, e_cost : 0.001344, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.31724791740998626\n",
      "0.05945104421698488\n",
      "epoch : 38, t_cost : 0.003050, e_cost : 0.001351, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3068033750168979\n",
      "0.05986033956287429\n",
      "epoch : 39, t_cost : 0.002950, e_cost : 0.001360, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2971115148393437\n",
      "0.06120160227874294\n",
      "epoch : 40, t_cost : 0.002857, e_cost : 0.001391, elapsed time : 9.46sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.28911214420804754\n",
      "0.06250844546593726\n",
      "epoch : 41, t_cost : 0.002780, e_cost : 0.001421, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2832796256407164\n",
      "0.061201288539450616\n",
      "epoch : 42, t_cost : 0.002724, e_cost : 0.001391, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2805107011809014\n",
      "0.0630738087638747\n",
      "epoch : 43, t_cost : 0.002697, e_cost : 0.001433, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2761421106988564\n",
      "0.06257233288488351\n",
      "epoch : 44, t_cost : 0.002655, e_cost : 0.001422, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2755812321556732\n",
      "0.06397095185820945\n",
      "epoch : 45, t_cost : 0.002650, e_cost : 0.001454, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.268825072911568\n",
      "0.062340605683857575\n",
      "epoch : 46, t_cost : 0.002585, e_cost : 0.001417, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2633218531263992\n",
      "0.06518709822557867\n",
      "epoch : 47, t_cost : 0.002532, e_cost : 0.001482, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2653723089606501\n",
      "0.06261958656250499\n",
      "epoch : 48, t_cost : 0.002552, e_cost : 0.001423, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2673608321347274\n",
      "0.06700871689827181\n",
      "epoch : 49, t_cost : 0.002571, e_cost : 0.001523, elapsed time : 9.46sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.27283063856884837\n",
      "0.06723481460358016\n",
      "epoch : 50, t_cost : 0.002623, e_cost : 0.001528, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2794563644565642\n",
      "0.06796547130215913\n",
      "epoch : 51, t_cost : 0.002687, e_cost : 0.001545, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.28456355462549254\n",
      "0.0722312844300177\n",
      "epoch : 52, t_cost : 0.002736, e_cost : 0.001642, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2862386840279214\n",
      "0.0704684880329296\n",
      "epoch : 53, t_cost : 0.002752, e_cost : 0.001602, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2739547824021429\n",
      "0.07687204531976022\n",
      "epoch : 54, t_cost : 0.002634, e_cost : 0.001747, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2938189755077474\n",
      "0.0738615149166435\n",
      "epoch : 55, t_cost : 0.002825, e_cost : 0.001679, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2995654893456958\n",
      "0.07671685848617926\n",
      "epoch : 56, t_cost : 0.002880, e_cost : 0.001744, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.30078440660145134\n",
      "0.07982487572007813\n",
      "epoch : 57, t_cost : 0.002892, e_cost : 0.001814, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.29240518307778984\n",
      "0.08396305618225597\n",
      "epoch : 58, t_cost : 0.002812, e_cost : 0.001908, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.29368456528754905\n",
      "0.08471216511679813\n",
      "epoch : 59, t_cost : 0.002824, e_cost : 0.001925, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.31808004301274195\n",
      "0.0859544838021975\n",
      "epoch : 60, t_cost : 0.003058, e_cost : 0.001954, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2819565540412441\n",
      "0.08428424227167852\n",
      "epoch : 61, t_cost : 0.002711, e_cost : 0.001916, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.32237389648798853\n",
      "0.09645030304091051\n",
      "epoch : 62, t_cost : 0.003100, e_cost : 0.002192, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.31581653864122927\n",
      "0.10087902846862562\n",
      "epoch : 63, t_cost : 0.003037, e_cost : 0.002293, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3309204818215221\n",
      "0.10060903822886758\n",
      "epoch : 64, t_cost : 0.003182, e_cost : 0.002287, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3191105620935559\n",
      "0.09409920996404253\n",
      "epoch : 65, t_cost : 0.003068, e_cost : 0.002139, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3489933034288697\n",
      "0.10490621801000088\n",
      "epoch : 66, t_cost : 0.003356, e_cost : 0.002384, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3624208318069577\n",
      "0.10186234506545588\n",
      "epoch : 67, t_cost : 0.003485, e_cost : 0.002315, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.4168959205853753\n",
      "0.11658804802573286\n",
      "epoch : 68, t_cost : 0.004009, e_cost : 0.002650, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.37399064045166597\n",
      "0.08527700370177627\n",
      "epoch : 69, t_cost : 0.003596, e_cost : 0.001938, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.4262804519967176\n",
      "0.0825012244458776\n",
      "epoch : 70, t_cost : 0.004099, e_cost : 0.001875, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.4428789524245076\n",
      "0.08119196811458096\n",
      "epoch : 71, t_cost : 0.004258, e_cost : 0.001845, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.47224824893055484\n",
      "0.08110004564514384\n",
      "epoch : 72, t_cost : 0.004541, e_cost : 0.001843, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.47802009916631505\n",
      "0.07505029323510826\n",
      "epoch : 73, t_cost : 0.004596, e_cost : 0.001706, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.43236516119213775\n",
      "0.07348016774631105\n",
      "epoch : 74, t_cost : 0.004157, e_cost : 0.001670, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.4526814297423698\n",
      "0.062103354546707124\n",
      "epoch : 75, t_cost : 0.004353, e_cost : 0.001411, elapsed time : 9.46sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.35370497085386887\n",
      "0.0613510258262977\n",
      "epoch : 76, t_cost : 0.003401, e_cost : 0.001394, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.32816650142194703\n",
      "0.05711613496532664\n",
      "epoch : 77, t_cost : 0.003155, e_cost : 0.001298, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.24558835965581238\n",
      "0.0530881259473972\n",
      "epoch : 78, t_cost : 0.002361, e_cost : 0.001207, elapsed time : 9.46sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.20463626214768738\n",
      "0.05097543858573772\n",
      "epoch : 79, t_cost : 0.001968, e_cost : 0.001159, elapsed time : 9.42sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.1832532639382407\n",
      "0.04963925795163959\n",
      "epoch : 80, t_cost : 0.001762, e_cost : 0.001128, elapsed time : 9.42sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.17084965074900538\n",
      "0.04935283388476819\n",
      "epoch : 81, t_cost : 0.001643, e_cost : 0.001122, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.16659796534804627\n",
      "0.049725574237527326\n",
      "epoch : 82, t_cost : 0.001602, e_cost : 0.001130, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.16869174837484024\n",
      "0.051294461358338594\n",
      "epoch : 83, t_cost : 0.001622, e_cost : 0.001166, elapsed time : 9.51sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.17511608614586294\n",
      "0.05319225994753651\n",
      "epoch : 84, t_cost : 0.001684, e_cost : 0.001209, elapsed time : 9.53sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.1821148139424622\n",
      "0.05600351534667425\n",
      "epoch : 85, t_cost : 0.001751, e_cost : 0.001273, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.18854467681376263\n",
      "0.057784439326496795\n",
      "epoch : 86, t_cost : 0.001813, e_cost : 0.001313, elapsed time : 9.49sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.19481731529231183\n",
      "0.05966829403769225\n",
      "epoch : 87, t_cost : 0.001873, e_cost : 0.001356, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.19969092460814863\n",
      "0.05976163808372803\n",
      "epoch : 88, t_cost : 0.001920, e_cost : 0.001358, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.20824877632549033\n",
      "0.06360326174763031\n",
      "epoch : 89, t_cost : 0.002002, e_cost : 0.001446, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2189538474776782\n",
      "0.06442371223238297\n",
      "epoch : 90, t_cost : 0.002105, e_cost : 0.001464, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2293841339997016\n",
      "0.062025526305660605\n",
      "epoch : 91, t_cost : 0.002206, e_cost : 0.001410, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.226952328463085\n",
      "0.0663900000799913\n",
      "epoch : 92, t_cost : 0.002182, e_cost : 0.001509, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.248791808669921\n",
      "0.06623423332348466\n",
      "epoch : 93, t_cost : 0.002392, e_cost : 0.001505, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.22379655617987737\n",
      "0.06680228063487448\n",
      "epoch : 94, t_cost : 0.002152, e_cost : 0.001518, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.23335442401003093\n",
      "0.06341884296853095\n",
      "epoch : 95, t_cost : 0.002244, e_cost : 0.001441, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.23466401122277603\n",
      "0.06515008892165497\n",
      "epoch : 96, t_cost : 0.002256, e_cost : 0.001481, elapsed time : 9.44sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.22914705175207928\n",
      "0.07020555730559863\n",
      "epoch : 97, t_cost : 0.002203, e_cost : 0.001596, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2334690531133674\n",
      "0.07488103982177563\n",
      "epoch : 98, t_cost : 0.002245, e_cost : 0.001702, elapsed time : 9.43sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2246346196043305\n",
      "0.07724380164290778\n",
      "epoch : 99, t_cost : 0.002160, e_cost : 0.001756, elapsed time : 9.44sec\n",
      "\n",
      "#Best result at epoch 81\n",
      "t_cost : 0.001643, e_cost : 0.001122\n"
     ]
    }
   ],
   "source": [
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.keras.backend.clear_session()\n",
    "#tf.compat.v1.reset_default_graph()\n",
    "#parameter list\n",
    "'''\n",
    "sess=tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(allow_soft_placement=True))\n",
    "name='lstm'\n",
    "timesize=20\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "#\n",
    "'''\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=8\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "\n",
    "\n",
    "kospi=StockData(\n",
    "    'StockChart/SAMPLE',\n",
    "    'StockChart/KOSPI.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "\n",
    "\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    \n",
    "result_dic={}\n",
    "    \n",
    "for i in range(100):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "    \n",
    "    #training batch\n",
    "    \n",
    "    for batch in kospi.getBatch('training'):        \n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    \n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(training_cost)\n",
    "    print(evalution_cost)\n",
    "    \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "    i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eopch : 100 , batchsize : 512 , timesize : 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result =  Tensor(\"concat:0\", shape=(None, 8, 256), dtype=float32)\n",
      "LSTM2 =  <__main__.MI_LSTMCell object at 0x7f60d6a1a790>\n",
      "Y_2 =  (None, 8, 64)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f60d6971d10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f60d70f7190>, <gast.gast.Return object at 0x7f60d70f7310>]\n",
      "WARNING: AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f60d6971d10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f60d70f7190>, <gast.gast.Return object at 0x7f60d70f7310>]\n",
      "inputs :  Tensor(\"rnn_22/transpose_1:0\", shape=(None, 8, 64), dtype=float32)\n",
      "weight :  Tensor(\"attention_1/Squeeze:0\", shape=(None, 8), dtype=float32)\n",
      "encoder_states :  Tensor(\"encoder/transpose_1:0\", shape=(None, 8, 64), dtype=float32)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f60d6902710>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f62dc406090>, <gast.gast.Return object at 0x7f62dc406250>]\n",
      "WARNING: AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f60d6902710>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f62dc406090>, <gast.gast.Return object at 0x7f62dc406250>]\n",
      "y_pred :  Tensor(\"decoder/dense_5/BiasAdd:0\", shape=(None, 1), dtype=float32)\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "14.278627317398787\n",
      "2.6659235917031765\n",
      "epoch : 0, t_cost : 0.137294, e_cost : 0.060589, elapsed time : 15.65sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "1.695581511594355\n",
      "0.28421577613335103\n",
      "epoch : 1, t_cost : 0.016304, e_cost : 0.006459, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6699989147018641\n",
      "0.22639192920178175\n",
      "epoch : 2, t_cost : 0.006442, e_cost : 0.005145, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6152805672027171\n",
      "0.21137945621740073\n",
      "epoch : 3, t_cost : 0.005916, e_cost : 0.004804, elapsed time : 9.49sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6214137212373316\n",
      "0.21226085361558944\n",
      "epoch : 4, t_cost : 0.005975, e_cost : 0.004824, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.638869774993509\n",
      "0.22272975137457252\n",
      "epoch : 5, t_cost : 0.006143, e_cost : 0.005062, elapsed time : 9.49sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6501397772226483\n",
      "0.22887768794316798\n",
      "epoch : 6, t_cost : 0.006251, e_cost : 0.005202, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6722959564067423\n",
      "0.24943047435954213\n",
      "epoch : 7, t_cost : 0.006464, e_cost : 0.005669, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.7178785486612469\n",
      "0.3068082876270637\n",
      "epoch : 8, t_cost : 0.006903, e_cost : 0.006973, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.697611081181094\n",
      "0.28497546759899706\n",
      "epoch : 9, t_cost : 0.006708, e_cost : 0.006477, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6544781307457015\n",
      "0.25218666600994766\n",
      "epoch : 10, t_cost : 0.006293, e_cost : 0.005732, elapsed time : 9.49sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6551278295228258\n",
      "0.20864347531460226\n",
      "epoch : 11, t_cost : 0.006299, e_cost : 0.004742, elapsed time : 9.50sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6709059518761933\n",
      "0.20225796510931104\n",
      "epoch : 12, t_cost : 0.006451, e_cost : 0.004597, elapsed time : 9.49sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6900401778984815\n",
      "0.17895103187765926\n",
      "epoch : 13, t_cost : 0.006635, e_cost : 0.004067, elapsed time : 9.49sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6859417732339352\n",
      "0.1603806633502245\n",
      "epoch : 14, t_cost : 0.006596, e_cost : 0.003645, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6892310725525022\n",
      "0.1625332828843966\n",
      "epoch : 15, t_cost : 0.006627, e_cost : 0.003694, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6586636215215549\n",
      "0.11964043258922175\n",
      "epoch : 16, t_cost : 0.006333, e_cost : 0.002719, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6226080231135711\n",
      "0.10516798973549157\n",
      "epoch : 17, t_cost : 0.005987, e_cost : 0.002390, elapsed time : 9.46sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6054963441565633\n",
      "0.10279155982425436\n",
      "epoch : 18, t_cost : 0.005822, e_cost : 0.002336, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6886728320969269\n",
      "0.11316286656074226\n",
      "epoch : 19, t_cost : 0.006622, e_cost : 0.002572, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.8779524537967518\n",
      "0.12463258189382032\n",
      "epoch : 20, t_cost : 0.008442, e_cost : 0.002833, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.965375587111339\n",
      "0.11813219275791198\n",
      "epoch : 21, t_cost : 0.009282, e_cost : 0.002685, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.863633549073711\n",
      "0.08973102364689112\n",
      "epoch : 22, t_cost : 0.008304, e_cost : 0.002039, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "1.0387381406035274\n",
      "0.10763660876546055\n",
      "epoch : 23, t_cost : 0.009988, e_cost : 0.002446, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.7159219569293782\n",
      "0.09738499007653445\n",
      "epoch : 24, t_cost : 0.006884, e_cost : 0.002213, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.7751162484637462\n",
      "0.10244039486860856\n",
      "epoch : 25, t_cost : 0.007453, e_cost : 0.002328, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.6339620883809403\n",
      "0.09593054134165868\n",
      "epoch : 26, t_cost : 0.006096, e_cost : 0.002180, elapsed time : 9.46sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.5809281616820954\n",
      "0.08847887464798987\n",
      "epoch : 27, t_cost : 0.005586, e_cost : 0.002011, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.48783272731816396\n",
      "0.07420660165371373\n",
      "epoch : 28, t_cost : 0.004691, e_cost : 0.001687, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.4494086080812849\n",
      "0.07634541357401758\n",
      "epoch : 29, t_cost : 0.004321, e_cost : 0.001735, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.41962831176351756\n",
      "0.07897666632197797\n",
      "epoch : 30, t_cost : 0.004035, e_cost : 0.001795, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.38310685520991683\n",
      "0.07370197353884578\n",
      "epoch : 31, t_cost : 0.003684, e_cost : 0.001675, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.35412077442742884\n",
      "0.06983623298583552\n",
      "epoch : 32, t_cost : 0.003405, e_cost : 0.001587, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3287087489152327\n",
      "0.06789803146966733\n",
      "epoch : 33, t_cost : 0.003161, e_cost : 0.001543, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.32371023698942736\n",
      "0.06768235811614431\n",
      "epoch : 34, t_cost : 0.003113, e_cost : 0.001538, elapsed time : 9.49sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3105951822944917\n",
      "0.06881694626645185\n",
      "epoch : 35, t_cost : 0.002986, e_cost : 0.001564, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.30201197211863473\n",
      "0.06476511782966554\n",
      "epoch : 36, t_cost : 0.002904, e_cost : 0.001472, elapsed time : 9.51sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.29367420787457377\n",
      "0.06801870124763809\n",
      "epoch : 37, t_cost : 0.002824, e_cost : 0.001546, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2954714982188307\n",
      "0.06571341573726386\n",
      "epoch : 38, t_cost : 0.002841, e_cost : 0.001493, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2896739769494161\n",
      "0.0684951484145131\n",
      "epoch : 39, t_cost : 0.002785, e_cost : 0.001557, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.29566904582316056\n",
      "0.06734199365018867\n",
      "epoch : 40, t_cost : 0.002843, e_cost : 0.001530, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.30206440459005535\n",
      "0.07254219957394525\n",
      "epoch : 41, t_cost : 0.002904, e_cost : 0.001649, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2881870145210996\n",
      "0.062231069401605055\n",
      "epoch : 42, t_cost : 0.002771, e_cost : 0.001414, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.28234105778392404\n",
      "0.06624970177654177\n",
      "epoch : 43, t_cost : 0.002715, e_cost : 0.001506, elapsed time : 9.46sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.29306771932169795\n",
      "0.06415522287716158\n",
      "epoch : 44, t_cost : 0.002818, e_cost : 0.001458, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2899485761881806\n",
      "0.06324811815284193\n",
      "epoch : 45, t_cost : 0.002788, e_cost : 0.001437, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.29758726578438655\n",
      "0.06178434219327755\n",
      "epoch : 46, t_cost : 0.002861, e_cost : 0.001404, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.29999253799906\n",
      "0.06989348621573299\n",
      "epoch : 47, t_cost : 0.002885, e_cost : 0.001588, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3011175421997905\n",
      "0.06118365938891657\n",
      "epoch : 48, t_cost : 0.002895, e_cost : 0.001391, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.299944453057833\n",
      "0.0717659798101522\n",
      "epoch : 49, t_cost : 0.002884, e_cost : 0.001631, elapsed time : 9.49sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.29590550519060344\n",
      "0.06365828844718635\n",
      "epoch : 50, t_cost : 0.002845, e_cost : 0.001447, elapsed time : 9.50sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2853912518476136\n",
      "0.06987907068105415\n",
      "epoch : 51, t_cost : 0.002744, e_cost : 0.001588, elapsed time : 9.49sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2909731464460492\n",
      "0.07135859021218494\n",
      "epoch : 52, t_cost : 0.002798, e_cost : 0.001622, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.27652771421708167\n",
      "0.07812679940252565\n",
      "epoch : 53, t_cost : 0.002659, e_cost : 0.001776, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28975150239421055\n",
      "0.0674635595350992\n",
      "epoch : 54, t_cost : 0.002786, e_cost : 0.001533, elapsed time : 9.49sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2850285260938108\n",
      "0.07511035786592402\n",
      "epoch : 55, t_cost : 0.002741, e_cost : 0.001707, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.27540589758427814\n",
      "0.07587430335115641\n",
      "epoch : 56, t_cost : 0.002648, e_cost : 0.001724, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.27208891068585217\n",
      "0.07817391864955425\n",
      "epoch : 57, t_cost : 0.002616, e_cost : 0.001777, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2756488428567536\n",
      "0.07813796307891607\n",
      "epoch : 58, t_cost : 0.002650, e_cost : 0.001776, elapsed time : 9.49sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.27450022945413366\n",
      "0.07949474191991612\n",
      "epoch : 59, t_cost : 0.002639, e_cost : 0.001807, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.27461881656199694\n",
      "0.08052682134439237\n",
      "epoch : 60, t_cost : 0.002641, e_cost : 0.001830, elapsed time : 9.46sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.27126912283711135\n",
      "0.086716075980803\n",
      "epoch : 61, t_cost : 0.002608, e_cost : 0.001971, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2769131645327434\n",
      "0.0819350662350189\n",
      "epoch : 62, t_cost : 0.002663, e_cost : 0.001862, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.27111795311793685\n",
      "0.07922982529271394\n",
      "epoch : 63, t_cost : 0.002607, e_cost : 0.001801, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.30415817664470524\n",
      "0.0705367834016215\n",
      "epoch : 64, t_cost : 0.002925, e_cost : 0.001603, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3024875873234123\n",
      "0.07800023499294184\n",
      "epoch : 65, t_cost : 0.002909, e_cost : 0.001773, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.30524918978335336\n",
      "0.0770479109196458\n",
      "epoch : 66, t_cost : 0.002935, e_cost : 0.001751, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3273922011721879\n",
      "0.0810298717697151\n",
      "epoch : 67, t_cost : 0.003148, e_cost : 0.001842, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.36117177712731063\n",
      "0.07414110860554501\n",
      "epoch : 68, t_cost : 0.003473, e_cost : 0.001685, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.379264620190952\n",
      "0.0858156789036002\n",
      "epoch : 69, t_cost : 0.003647, e_cost : 0.001950, elapsed time : 9.50sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.4069168474525213\n",
      "0.06610419071512297\n",
      "epoch : 70, t_cost : 0.003913, e_cost : 0.001502, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.42637068434851244\n",
      "0.0635816041030921\n",
      "epoch : 71, t_cost : 0.004100, e_cost : 0.001445, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.4229763062321581\n",
      "0.060004061087965965\n",
      "epoch : 72, t_cost : 0.004067, e_cost : 0.001364, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.35442977014463395\n",
      "0.056289833097252995\n",
      "epoch : 73, t_cost : 0.003408, e_cost : 0.001279, elapsed time : 9.46sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.3940918931621127\n",
      "0.05384058560593985\n",
      "epoch : 74, t_cost : 0.003789, e_cost : 0.001224, elapsed time : 9.52sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.33132435934385285\n",
      "0.05257132518454455\n",
      "epoch : 75, t_cost : 0.003186, e_cost : 0.001195, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.302964236761909\n",
      "0.04981532273814082\n",
      "epoch : 76, t_cost : 0.002913, e_cost : 0.001132, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2604547882801853\n",
      "0.0486036445654463\n",
      "epoch : 77, t_cost : 0.002504, e_cost : 0.001105, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.22798540553776547\n",
      "0.04741907096467912\n",
      "epoch : 78, t_cost : 0.002192, e_cost : 0.001078, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.21462575055193156\n",
      "0.04673049916164018\n",
      "epoch : 79, t_cost : 0.002064, e_cost : 0.001062, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.21155864832689986\n",
      "0.04644453091896139\n",
      "epoch : 80, t_cost : 0.002034, e_cost : 0.001056, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.21061038511106744\n",
      "0.046245486359111965\n",
      "epoch : 81, t_cost : 0.002025, e_cost : 0.001051, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.20869576174300164\n",
      "0.046009553072508425\n",
      "epoch : 82, t_cost : 0.002007, e_cost : 0.001046, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.20202666125260293\n",
      "0.045706884091487154\n",
      "epoch : 83, t_cost : 0.001943, e_cost : 0.001039, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.19905193761223927\n",
      "0.04583962546894327\n",
      "epoch : 84, t_cost : 0.001914, e_cost : 0.001042, elapsed time : 9.46sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.19739124382613227\n",
      "0.045319134689634666\n",
      "epoch : 85, t_cost : 0.001898, e_cost : 0.001030, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.20062077266629785\n",
      "0.04627612858894281\n",
      "epoch : 86, t_cost : 0.001929, e_cost : 0.001052, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.20402190659660846\n",
      "0.045898621290689334\n",
      "epoch : 87, t_cost : 0.001962, e_cost : 0.001043, elapsed time : 9.50sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.22224316885694861\n",
      "0.046465438994346187\n",
      "epoch : 88, t_cost : 0.002137, e_cost : 0.001056, elapsed time : 9.49sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.22022037947317585\n",
      "0.04751899096299894\n",
      "epoch : 89, t_cost : 0.002118, e_cost : 0.001080, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.21757041616365314\n",
      "0.049377637944417074\n",
      "epoch : 90, t_cost : 0.002092, e_cost : 0.001122, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.21806824411032721\n",
      "0.05019733007065952\n",
      "epoch : 91, t_cost : 0.002097, e_cost : 0.001141, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.22350224759429693\n",
      "0.052105273614870384\n",
      "epoch : 92, t_cost : 0.002149, e_cost : 0.001184, elapsed time : 9.46sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.22730105445953086\n",
      "0.05318635658477433\n",
      "epoch : 93, t_cost : 0.002186, e_cost : 0.001209, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2405582147766836\n",
      "0.05536990950349718\n",
      "epoch : 94, t_cost : 0.002313, e_cost : 0.001258, elapsed time : 9.45sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.24903644376900047\n",
      "0.055707942898152396\n",
      "epoch : 95, t_cost : 0.002395, e_cost : 0.001266, elapsed time : 9.48sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2495279020513408\n",
      "0.05414727775496431\n",
      "epoch : 96, t_cost : 0.002399, e_cost : 0.001231, elapsed time : 9.47sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2440444008097984\n",
      "0.0540755107649602\n",
      "epoch : 97, t_cost : 0.002347, e_cost : 0.001229, elapsed time : 9.46sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.263913020666223\n",
      "0.060394315514713526\n",
      "epoch : 98, t_cost : 0.002538, e_cost : 0.001373, elapsed time : 9.50sec\n",
      "(53690, 8, 1) (53690, 10, 8, 1) (53690, 10, 8, 1) (53690, 8, 1) (53690, 1)\n",
      "(23010, 8, 1) (23010, 10, 8, 1) (23010, 10, 8, 1) (23010, 8, 1) (23010, 1)\n",
      "0.2532229468342848\n",
      "0.058924008597387\n",
      "epoch : 99, t_cost : 0.002435, e_cost : 0.001339, elapsed time : 9.50sec\n",
      "\n",
      "#Best result at epoch 85\n",
      "t_cost : 0.001898, e_cost : 0.001030\n",
      "[<matplotlib.lines.Line2D object at 0x7f62dc8db8d0>]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAe+ElEQVR4nO3de5Bc5Xnn8e9zzum5amZ0YQToApKQsBFgwMgYX+M1tgvsXQuvwYZ4N1RKKexs2Dhxslmc1LI2ldpdsllYX6jElGEjk12DDfZ61pGNHXDsMtiKBowRAguPxEUSwmqNpNHcp7vn2T/OmZ6enhHT0szo8ur3qVKp+5y3u9/DEb8+/fTb72vujoiIhCs60R0QEZG5paAXEQmcgl5EJHAKehGRwCnoRUQCl5zoDlQ744wzfMWKFSe6GyIip5Qnn3xyv7u3T7XvpAv6FStW0NnZeaK7ISJySjGzl4+0T6UbEZHAKehFRAKnoBcRCZyCXkQkcAp6EZHAKehFRAKnoBcRCVxNQW9mV5vZdjPrMrNbp9hfb2YPZvs3m9mKin1vMrOfmdk2M9tqZg2z1/1xe3sGufMH29mZ75uLpxcROWVNG/RmFgN3A9cAa4EbzWxtVbMNwEF3Xw3cBdyRPTYB/h74lLtfCLwHKMxa7yvke4f54mNdvLi/fy6eXkTklFXLFf0VQJe773T3EeABYH1Vm/XAxuz2Q8BVZmbAB4Bn3P2XAO7e7e6l2en6RHFkABRKWkhFRKRSLUG/FNhVcX93tm3KNu5eBHqARcD5gJvZI2b2lJn92VQvYGY3m1mnmXXm8/mjPQYAkig9lNKogl5EpNJcfxmbAO8EPpH9/REzu6q6kbvf4+7r3H1de/uUc/JM/0JxekVfHB099t6KiASolqDfAyyvuL8s2zZlm6wu3wZ0k179/8Td97v7ALAJePNMOz2VJCvdFFW6ERGZoJag3wKsMbOVZlYH3AB0VLXpAG7Kbl8HPObpquOPABebWVP2BvBbwHOz0/WJklilGxGRqUw7TbG7F83sFtLQjoH73H2bmd0OdLp7B3AvcL+ZdQEHSN8McPeDZnYn6ZuFA5vc/R/m5EDGrugV9CIiE9Q0H727byItu1Ruu63i9hBw/REe+/ekQyznVBypRi8iMpVgfhmby0bdqEYvIjJRMEEfa9SNiMiUggl61ehFRKYWXNCXVLoREZkgmKAvT4GgK3oRkQmCCXozI4mMkmr0IiITBBP0kF7Vq0YvIjJRUEGfRKbhlSIiVcIK+jjSFAgiIlXCCvrIKJRUoxcRqRRU0MeR6YpeRKRKUEGfiyN9GSsiUiWooI8jo6jSjYjIBEEFfRJreKWISLWwgl41ehGRSYIK+jiKKGgcvYjIBEEFfS7WFAgiItWCCnpNgSAiMllQQZ+LIk2BICJSJaig1w+mREQmCyrok9goqEYvIjJBWEGvK3oRkUmCCnoNrxQRmSyooNcKUyIik9UU9GZ2tZltN7MuM7t1iv31ZvZgtn+zma3Itq8ws0Ezezr787ez2/2JNAWCiMhkyXQNzCwG7gbeD+wGtphZh7s/V9FsA3DQ3Veb2Q3AHcDHs3073P3SWe73lLTClIjIZLVc0V8BdLn7TncfAR4A1le1WQ9szG4/BFxlZjZ73ayNVpgSEZmslqBfCuyquL872zZlG3cvAj3AomzfSjP7hZn92MzeNdULmNnNZtZpZp35fP6oDqBSEhlF1ehFRCaY6y9j9wLnuPtlwGeA/2NmrdWN3P0ed1/n7uva29uP+cVilW5ERCapJej3AMsr7i/Ltk3ZxswSoA3odvdhd+8GcPcngR3A+TPt9JFohSkRkclqCfotwBozW2lmdcANQEdVmw7gpuz2dcBj7u5m1p59mYuZrQLWADtnp+uTaYUpEZHJph114+5FM7sFeASIgfvcfZuZ3Q50unsHcC9wv5l1AQdI3wwA3g3cbmYFYBT4lLsfmIsDgbEava7oRUQqTRv0AO6+CdhUte22ittDwPVTPO5h4OEZ9rFmSawpEEREqgX1y9g4Smv07gp7EZExQQV9LkqH7uuqXkRkXFBBH8dp0KtOLyIyLqigTyIFvYhItcCCPj2ckn40JSJSFlbQZ6UbrTIlIjIuqKCP9WWsiMgkQQV9LivdqEYvIjIuqKAfu6LXNAgiIuOCCvpEwytFRCYJK+jHRt0o6EVEyoIK+rHSTUGlGxGRsqCCPhdr1I2ISLWggn78il5BLyIyJqigz8Wq0YuIVAsq6MvDK/XLWBGRsqCCvjypmUo3IiJlYQW9SjciIpOEFfQaXikiMklQQa9JzUREJgsq6HOaAkFEZJKggj4uz16p0o2IyJiggl6jbkREJgsr6DUFgojIJDUFvZldbWbbzazLzG6dYn+9mT2Y7d9sZiuq9p9jZn1m9qez0+2pladAUNCLiJRNG/RmFgN3A9cAa4EbzWxtVbMNwEF3Xw3cBdxRtf9O4Hsz7+7ry5UXB1eNXkRkTC1X9FcAXe6+091HgAeA9VVt1gMbs9sPAVeZmQGY2bXAi8C22enykcUadSMiMkktQb8U2FVxf3e2bco27l4EeoBFZjYP+I/A52fe1emVv4xV0IuIlM31l7GfA+5y977Xa2RmN5tZp5l15vP5Y34xrTAlIjJZUkObPcDyivvLsm1TtdltZgnQBnQDbwWuM7O/AuYDo2Y25O5frnywu98D3AOwbt26Y05pTYEgIjJZLUG/BVhjZitJA/0G4Ler2nQANwE/A64DHnN3B9411sDMPgf0VYf8bIoiIzJd0YuIVJo26N29aGa3AI8AMXCfu28zs9uBTnfvAO4F7jezLuAA6ZvBCZFEkWr0IiIVarmix903AZuqtt1WcXsIuH6a5/jcMfTvqMWRUVTpRkSkLKhfxkL661hd0YuIjAsv6CPTXDciIhWCC/pYNXoRkQmCC/pcbJQ0TbGISFlwQR+rdCMiMkFwQZ+LVboREakUXNDHkekHUyIiFYIL+iQyTYEgIlIhvKCPdUUvIlIpuKCPo0grTImIVAgu6JNIwytFRCoFGfQaXikiMi68oNdcNyIiE4QX9JoCQURkggCDXtMUi4hUCi7o9YMpEZGJggt6TYEgIjJRcEGvFaZERCYKLug16kZEZKLwgl41ehGRCYIL+jiKKOgHUyIiZcEFvVaYEhGZKLig1wpTIiITBRf0SaQvY0VEKoUX9HGkL2NFRCrUFPRmdrWZbTezLjO7dYr99Wb2YLZ/s5mtyLZfYWZPZ39+aWYfmd3uT5ZERkE1ehGRsmmD3sxi4G7gGmAtcKOZra1qtgE46O6rgbuAO7LtzwLr3P1S4GrgK2aWzFbnp5JEEe4wqqt6ERGgtiv6K4Aud9/p7iPAA8D6qjbrgY3Z7YeAq8zM3H3A3YvZ9gZgztM3iQ1AdXoRkUwtQb8U2FVxf3e2bco2WbD3AIsAzOytZrYN2Ap8qiL4y8zsZjPrNLPOfD5/9EdRIY7Ggl7lGxEROA5fxrr7Zne/EHgL8Fkza5iizT3uvs7d17W3t8/o9ZJIV/QiIpVqCfo9wPKK+8uybVO2yWrwbUB3ZQN3fx7oAy461s7Wohz0GksvIgLUFvRbgDVmttLM6oAbgI6qNh3ATdnt64DH3N2zxyQAZnYu8EbgpVnp+RHEcXpIKt2IiKSmHQHj7kUzuwV4BIiB+9x9m5ndDnS6ewdwL3C/mXUBB0jfDADeCdxqZgVgFPh37r5/Lg5kTC67otdYehGRVE1DHd19E7CpatttFbeHgOuneNz9wP0z7ONRiVW6ERGZILhfxubKpRsFvYgIBBj0cbl0oxq9iAgEGPRjo240J72ISCq8oM9KN/oyVkQkFV7Ql6/oVboREYEAgz7W8EoRkQmCC3pNaiYiMlF4QR9lwyv1ZayICBBi0MeavVJEpFJ4Qa9fxoqITBBc0MeaplhEZILggj6ncfQiIhMEF/RaYUpEZKLggj6nUTciIhMEF/RxrB9MiYhUCi7oy1MgqHQjIgIEHPS6ohcRSQUY9OkhaZpiEZFUcEE/XqNX6UZEBAIM+kQ/mBIRmSDcoFfpRkQECDDoNQWCiMhEwQW9mZFEphq9iEgmuKCH9KpepRsRkVRNQW9mV5vZdjPrMrNbp9hfb2YPZvs3m9mKbPv7zexJM9ua/f3e2e3+1HJxpNKNiEhm2qA3sxi4G7gGWAvcaGZrq5ptAA66+2rgLuCObPt+4F+5+8XATcD9s9Xx15Ne0at0IyICtV3RXwF0uftOdx8BHgDWV7VZD2zMbj8EXGVm5u6/cPdXs+3bgEYzq5+Njr+eJDJd0YuIZGoJ+qXAror7u7NtU7Zx9yLQAyyqavNR4Cl3H65+ATO72cw6zawzn8/X2vcjSmLTFAgiIpnj8mWsmV1IWs755FT73f0ed1/n7uva29tn/HpJFGkKBBGRTC1BvwdYXnF/WbZtyjZmlgBtQHd2fxnwbeB33H3HTDtci/SKXjV6ERGoLei3AGvMbKWZ1QE3AB1VbTpIv2wFuA54zN3dzOYD/wDc6u6Pz1anpxOrRi8iUjZt0Gc191uAR4DngW+4+zYzu93MPpw1uxdYZGZdwGeAsSGYtwCrgdvM7Onsz+JZP4oqicbRi4iUJbU0cvdNwKaqbbdV3B4Crp/icX8J/OUM+3jUkkjj6EVExgT5y9gkNi0OLiKSCTLo40jDK0VExgQZ9LkoUo1eRCQTZNCno25UuhERgUCDPq3R64peRARCDXoNrxQRKQsy6GMNrxQRKQsy6HOaAkFEpCzIoNcKUyIi44IMeq0wJSIyLsig1w+mRETGBRn0SWQUtJSgiAgQatBrhSkRkbIwgz6KdEUvIpIJMuhVoxcRGRdk0GsKBBGRcWEGvZYSFBEpCzToI0qjjrvCXkQk0KA3ANXpRUQINOjjOA16lW9ERAIN+lyUHpaCXkQk0KCPs9JNUWPpRUTCDPpEpRsRkbIwgz4r3ejLWBGRGoPezK42s+1m1mVmt06xv97MHsz2bzazFdn2RWb2IzPrM7Mvz27Xj2xs1I2mQRARqSHozSwG7gauAdYCN5rZ2qpmG4CD7r4auAu4I9s+BPwn4E9nrcc1GCvd6IpeRKS2K/orgC533+nuI8ADwPqqNuuBjdnth4CrzMzcvd/df0oa+MdN+ctYBb2ISE1BvxTYVXF/d7ZtyjbuXgR6gEW1dsLMbjazTjPrzOfztT7siMZq9FpOUETkJPky1t3vcfd17r6uvb19xs83PupGNXoRkVqCfg+wvOL+smzblG3MLAHagO7Z6OCxSMrj6HVFLyJSS9BvAdaY2UozqwNuADqq2nQAN2W3rwMe8xM4o5hq9CIi45LpGrh70cxuAR4BYuA+d99mZrcDne7eAdwL3G9mXcAB0jcDAMzsJaAVqDOza4EPuPtzs38o43KxxtGLiIyZNugB3H0TsKlq220Vt4eA64/w2BUz6N8x0RQIIiLjToovY2dbTlMgiIiUBRn0cXn2Sl3Ri4gEGfQadSMiMi7MoJ+jKRB+8cpBvvazlxgcKc3q84qIzKWavow91ZQnNZvFoN/XO8Tvbeyku3+Eu3/UxR+973yuv3wZSRzke6WIBCTIlBqbAqF3qDArz+fu/IdvPkPfcJH/cf0lLJ3fyGe/tZUPffGn7Mj3zcpriIjMlSCDfumCRs5rb+ZLj3ZxaGBkxs+38YmX+PELef7iQxfw0cuX8fDvv52//TeXk+8b5tovP85jv/rNLPRaRGRuBBn0uTjiCzdcxv6+Yf7821uZyY90t7/Wy3/53q/4F29o599eeS4AZsbVF51Fxy3v4JxFTWzY2MndP+qa0euIiMyVIIMe4KKlbXzmA+ezaetrPPxU9dQ80zvQP8J//d7zXHv347Q2JPzVdZdgZhPaLFvQxEOfejsfvmQJ//2R7Xzpsa7Z6r6IyKwJ8svYMZ9893n80/Y8//k7z3J2WwNvW7WIKLJJ7dydXQcGeW7vYV7c30/Xvj6+9+xeBgslPnzJEv74fefT3lI/5Ws01sXc9bFLSaKIO3/4Ai0NCb/7jpVzfWgiIjULOujjyLjzY5dw7d2P84mvbmbZgkY+ctlSli9solAaZaQ4yrN7DvPznd3sOTRYflx7Sz3vX3sm//69q1m9uGXa14ki446PXkzfcIHP/7/naMzFXKcROSJykrCTra68bt067+zsnNXnHBwp8YPnXuOhJ3fzeNd+KkddLmjKceWqRbz9vEVcsnw+K89opqUhd0yvM1QosWHjFh7v6iYXGysWNfPGs1v55LtXcdHStlk6GhGRyczsSXdfN+W+0yHoKx3sH6FvuEhdEpFExoKmuinLOcdqcKTEpq17+fW+Pnbk+9jy0gF6Bgt8fN1y/uQDbzhiCUhEZCZeL+iDLt1MZUFzHQua6+bs+RvrYj56+bLy/Z7BAl969Nf83RMv8d1n9vKJt57D775jJWe1NcxZH0REKp12V/Qnys58H3f+8AU2bd1LHBkfvPhsFjbX0TdUpFAa5ffepfKOiBw7lW5OIrsODHDvT1/k4ad2AzCvPqFvuEgcGQ/e/DbecNb0X/6KiFRT0J/kXuke4PqvPEFpFL75qbex8ozmE90lETnFKOhPAV37evnYV35OQxLxpd9+M28+Z/6kH2hVerm7nx+/kOcnL+Q5PFTkvPZ5rF48j7etWsTaJa3HsecicjJQ0J8itr3awye+uplDAwXOXdTE+kuXcuGSVloaEubVJ+zM9/OzHd38bGc3rxwYAOCchU20t9SzI9/HoYECkcHvv+c8Pn3V+dQlEe7OT369n+dePcxl58zn0uXzacjFAAyMFDk0UODM1oby8osicmpS0J9CDg8V+P6zr/Gdp/fwxI5uqk9Pa0PCW1ct4h3nLeI9b1jMiqzM4+7ke4f56x9s5xudu7loaSsfuWwZX//nV+jaNz7DZl0SseqMZvK9w3T3j0zYdt7ieVxwVgsXnN3K2iWtnN3WeNyOW0RmRkF/iuruG2ZvzxC9Q0V6hwqc3dbI2iWt0159f//Z1/jzb2/lQP8IFy5pZcM7V/Lu89t5+pVD/HxnNzvyfZzV1siyBY3Mb8rxcvcAXfv6eOE3vew+OP4L4QuXtLL+0iV86E1LmFef0D9cpG+4yOHBAoeHChweLNLWmGP5wkaWLWgqf1I4nRVKo7zcPcDenkEuXNLGwqqhvL1DBQZGShRHnWJplL7hIn1D6X/XyjWOiyVnqFBiuDjKcLFU/iX3vt5hdub72ZnvY7g4ypL5jSyZ38CZrQ20NeZoa8yxuLWBNy1t49xFTZgZpVHnpe5+XjkwQGxGLo4wg/19w+w7PMyhwQLLFjRy/pktLFvQyNOvHOKfXthH50sHeevKhXzyt85jyXy96Z/sFPSnoYP9I+ztGeKCs1tet9ZfrXeowPbXevnFK4f47ta9/HLXoZofu7C5jvZ59SxuraetMUdzXUJTfUxdEmEYZjDqzkgxDa0kMha3NtDeUk9zXcLBgREO9I8wMFJiXn3MvPqE+lxM71CBQwMF+oeLJHFEXRIRGeztGWL3gUH29Q5x/pktvO28RbxlxULc04Vi8r3DRJExrz6huT6hIYnSx8cR9bmIhiSmIRfxm8PDbN3Tw7Ov9jA66lyyfD6XLJtPXWI8saObJ7q6yfcNc8HZLVy8tI2z2hp5ubufnfl+dh8cZLBQZKgwSs9ggZe7+ylULGF5wdmtXH7ufF7rGeK5Vw/zas/QUZ3HavPqE1a1N7PqjGYa62JePTTEq4cG2dc7zOGhwoRPgPObcixpa2Tn/j6GCke3fnJTXczFS9t48uWDmMG/vmwZV563kNaGHC0NORY25zhjXnqej+bfl8wdBb0cs5f29/Por/bh7uXAbGvM0dqYo6Uh4dDACLsODLLrwACvHU7DdSx0+oeL9A+XGCmNgoPjmBn1WdCOFEc5PFSc9Jq52CaEJaSrhjXXJ5RGneFiidKoc2ZrA8sXNLFoXh3PvtrDrgODk57raLQ2JESRcWhg4oI1S7Or5uf39tI3PN7f5rqY5QubaKqLacjFWQjP4/wz57G4pYGndx3kp137eWZ3D0vnp5/G3nhWK62NCbkoIomNprqE1ob0v+vYEpjuaTmtPomoT2Lqk4hckr5B5WI7YrCOjjp9I0V2Hxjkl7sP8ctdh3i1Z4g1i+fxxrNaWNWelvlGio67s3BeHYtbGmhpSNh1YIAXftPHKwf6WXt2G29ZuYD6JGbPoUG+8uMdPLBlFyPFyW8WudjSN/iWes6YV8+CpjpaGxJaGnI01yfpMeQimuri8ieOloYc9UmUHWNcPtYkOvKxHU+F0igDwyUGCkUGR0oUSp5+oiqNMjhSon+4yGD2aWvsomXs027/SJHSqDM6ml7U1OciGnPpv4/Ixs6v82rPEDvyfby4v59CcZSGrM37157J5z584TH1W0EvJ62hQol87zD9I0UWNtUxv6mOuiR9E+gbLjJcLKWhURdPCAF3nxQKuw8O8NQrh6hPIha31NPeUo876f+Aw0WGi6MUSqMUSumbxVBhlMFCiYVNdVy8tI3lC9PyxMvdAzy96xAjxVGuXLWI5QsbMTNGsxJIvneYFWc0s7il/qQIpuOhb7hIvne4XLY70D/C/r4R9vcN0903TL53mP19IxwcGCmXGo92JU+z9A09jowkSj+1RZFhpGtApBXL9JNhZGCk28yMbFG58iea9LnS5xh1GMnOvZM+dix0i6NOadSzfxdpaB/rCqQNuYjmuoQ4MiJL+zlSTP+NDRZKEz5tLW6p57z2eaxqb6YhFzNUSP89vmlZGze9fcUxvf6Mg97Mrga+AMTAV939v1Xtrwe+BlwOdAMfd/eXsn2fBTYAJeAP3f2R13stBb3Iqc/dGSqkwTlcLNE3XKRnsEDPYIHeoWJ6JVwaZbhQyv5O748Fb7HkjHr6yWM0+zToThbCY7fHt426U37LtTTwS9lzRZGRi426OMLMsudMH5vEEXGUvinUZZ+a6pKI5vqEprqYxlxMLk4/fdXF6SeT5vqExro4LQEm4+1zNcxW69nrzub8WuXDnslcN2YWA3cD7wd2A1vMrMPdn6totgE46O6rzewG4A7g42a2FrgBuBBYAvyjmZ3v7qWZHZKInMzMjMa6mMa6GMix+ER36CRh2ZX+8VbLhOlXAF3uvtPdR4AHgPVVbdYDG7PbDwFXWfqZdj3wgLsPu/uLQFf2fCIicpzUEvRLgV0V93dn26Zs4+5FoAdYVONjMbObzazTzDrz+XztvRcRkWmdFEsgufs97r7O3de1t7ef6O6IiASllqDfAyyvuL8s2zZlGzNLgDbSL2VreayIiMyhWoJ+C7DGzFaaWR3pl6sdVW06gJuy29cBj3k6nKcDuMHM6s1sJbAG+OfZ6bqIiNRi2lE37l40s1uAR0iHV97n7tvM7Hag0907gHuB+82sCzhA+mZA1u4bwHNAEfgDjbgRETm+9IMpEZEAvN44+pPiy1gREZk7J90VvZnlgZdn8BRnAPtnqTunitPxmOH0PG4d8+njaI/7XHefctjiSRf0M2VmnUf6+BKq0/GY4fQ8bh3z6WM2j1ulGxGRwCnoRUQCF2LQ33OiO3ACnI7HDKfnceuYTx+zdtzB1ehFRGSiEK/oRUSkgoJeRCRwwQS9mV1tZtvNrMvMbj3R/ZkLZrbczH5kZs+Z2TYz+3S2faGZ/dDMfp39veBE93UumFlsZr8ws+9m91ea2ebsnD+YzcUUDDObb2YPmdmvzOx5M3vb6XCuzeyPs3/fz5rZ182sIcRzbWb3mdk+M3u2YtuU59dSX8yO/xkze/PRvFYQQV+xCtY1wFrgxmx1q9AUgT9x97XAlcAfZMd5K/Cou68BHs3uh+jTwPMV9+8A7nL31cBB0pXOQvIF4Pvu/kbgEtJjD/pcm9lS4A+Bde5+Een8WmOr1oV2rv8OuLpq25HO7zWkk0KuAW4G/uZoXiiIoKe2VbBOee6+192fym73kv6Pv5SJK3xtBK49MT2cO2a2DPgQ8NXsvgHvJV3RDAI7bjNrA95NOmEg7j7i7oc4Dc416WSLjdmU503AXgI81+7+E9JJICsd6fyuB77mqZ8D883s7FpfK5Sgr2klq5CY2QrgMmAzcKa77812vQaceYK6NZf+J/BnwGh2fxFwKFvRDMI75yuBPPC/snLVV82smcDPtbvvAf4aeIU04HuAJwn7XFc60vmdUcaFEvSnFTObBzwM/JG7H67cl60DENSYWTP7l8A+d3/yRPflOEqANwN/4+6XAf1UlWkCPdcLSK9eVwJLgGYmlzdOC7N5fkMJ+tNmJSszy5GG/P92929lm38z9jEu+3vfierfHHkH8GEze4m0LPde0vr1/OzjPYR3zncDu919c3b/IdLgD/1cvw940d3z7l4AvkV6/kM+15WOdH5nlHGhBH0tq2Cd8rK69L3A8+5+Z8WuyhW+bgK+c7z7Npfc/bPuvszdV5Ce28fc/RPAj0hXNIPAjtvdXwN2mdkbsk1XkS7gE/S5Ji3ZXGlmTdm/97HjDvZcVznS+e0AficbfXMl0FNR4pmeuwfxB/gg8AKwA/iLE92fOTrGd5J+lHsGeDr780HSevWjwK+BfwQWnui+zuF/g/cA381uryJdmrIL+CZQf6L7N8vHeinQmZ3v/wssOB3ONfB54FfAs8D9QH2I5xr4Oun3EAXST3AbjnR+ASMdWbgD2Eo6Kqnm19IUCCIigQuldCMiIkegoBcRCZyCXkQkcAp6EZHAKehFRAKnoBcRCZyCXkQkcP8fvXbZYC5AJ/kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.keras.backend.clear_session()\n",
    "#tf.compat.v1.reset_default_graph()\n",
    "#parameter list\n",
    "'''\n",
    "sess=tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(allow_soft_placement=True))\n",
    "name='lstm'\n",
    "timesize=20\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "#\n",
    "'''\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=8\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "\n",
    "'''\n",
    "kospi=StockData(\n",
    "    'StockChart/SAMPLE',\n",
    "    'StockChart/KOSPI.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "'''\n",
    "\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    \n",
    "result_dic={}\n",
    "evalution_costplt=[]\n",
    "for i in range(100):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "    \n",
    "    #training batch\n",
    "    \n",
    "    for batch in kospi.getBatch('training'):        \n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    \n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(training_cost)\n",
    "    print(evalution_cost)\n",
    "    \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "    evalution_costplt.append(evalution_cost)\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "    i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))\n",
    "print(plt.plot(evalution_costplt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<matplotlib.lines.Line2D object at 0x7f60d70e5550>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.013394969479784117"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD5CAYAAAAp8/5SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAexUlEQVR4nO3de3Sc9X3n8fdXM5oZybqOJBtbvoyMgWAu4SIJSNJ0WzY90CZ4syUtlCS0cWCzKbvZpDldmj3NppzTdtl0Q9ITTjcESAihISlp9ng3NPQk5GzTLhgLAwFDnMjCxrfYut+l0eW7f8xjWxYyHttjPzPPfF7n6Mxz+UnznTn253me33P5mbsjIiLRVRF2ASIicnYp6EVEIk5BLyIScQp6EZGIU9CLiEScgl5EJOLi+TQysxuALwEx4EF3/2+L1ieBbwBXA/3A77r77mDd5cBXgDpgHuhw96kTvVdzc7NnMplT/iAiIuXs+eef73P3lqXWnTTozSwG3A+8B9gHbDOzLe7+6oJmm4FBd99gZrcA9wK/a2Zx4JvAh9z9JTNrAmbe6v0ymQxdXV15fTAREckxsz0nWpdP100n0O3uPe6eBR4HNi1qswl4JJh+ArjezAz4DeCn7v4SgLv3u/vcqX4AERE5ffkEfSuwd8H8vmDZkm3cfRYYBpqACwE3s6fMbLuZ/fGZlywiIqcirz76M/z77wI6gAngR2b2vLv/aGEjM7sTuBNg7dq1Z7kkEZHyks8e/X5gzYL51cGyJdsE/fL15E7K7gP+yd373H0CeBK4avEbuPsD7t7u7u0tLUueSxARkdOUT9BvAy4wszYzSwC3AFsWtdkC3B5M3ww87bmnpT0FXGZm1cEG4FeBVxERkXPmpF037j5rZneRC+0Y8LC77zCze4Aud98CPAQ8ambdwAC5jQHuPmhmXyC3sXDgSXf//ln6LCIisgQrtscUt7e3uy6vFBE5NcH5z/al1kXmztj9Q5N8/qmfsX9oMuxSRESKSmSCfnx6lvt/vItndvWHXYqISFGJTNBvaKmhvqqSba8PhF2KiEhRiUzQV1QYHZlGtu1W0IuILBSZoAfoyKTp6Rund3Q67FJERIpGtIK+LQ1Al/bqRUSOilTQX7qqnlRlBc8p6EVEjopU0CfiFVyxpoGu3YNhlyIiUjQiFfQAnZk0Ow4MMzY9G3YpIiJFIXJB39GWZt5h+x7t1YuIQASD/qq1jcQqTJdZiogEIhf0y5JxLllVx3O6cUpEBIhg0EPuevoX9w4xPatRC0VEIhr0jUzPzvPK/pGwSxERCV0kg749k7txSv30IiIRDfrmmiTrW5bpAWciIkQ06CF3PX3XnkHm54trYBURkXMtskHfkUkzPDnDzw+Phl2KiEioIh30ANv0OAQRKXORDfo16SpW1CXVTy8iZS+yQW9mdGTSbNs9QLENgC4ici5FNugBOtvSHByeYt+gBgwXkfIV6aDv0PX0IiLRDvqLVtRSm4or6EWkrEU66CsqjPZ1jbryRkTKWqSDHnLPp+8+PMbAeDbsUkREQhH5oO9UP72IlLnIB/1lq+tJxCt0Pb2IlK28gt7MbjCznWbWbWZ3L7E+aWbfDtZvNbNMsDxjZpNm9mLw8z8LW/7JJeMxrljToD16ESlbJw16M4sB9wM3AhuBW81s46Jmm4FBd98A3Afcu2DdLne/Ivj5WIHqPiUdmUZeOTDCRFYDhotI+clnj74T6Hb3HnfPAo8Dmxa12QQ8Ekw/AVxvZla4Ms9MRybN3LzzwhtDYZciInLO5RP0rcDeBfP7gmVLtnH3WWAYaArWtZnZC2b2f83sV86w3tNy9bpGKgyNIysiZSl+lv/+QWCtu/eb2dXA/zKzS9z9uDH+zOxO4E6AtWvXFryI2lQlF6+sUz+9iJSlfPbo9wNrFsyvDpYt2cbM4kA90O/u0+7eD+DuzwO7gAsXv4G7P+Du7e7e3tLScuqfIg8dmTQvvDHEzNz8Wfn7IiLFKp+g3wZcYGZtZpYAbgG2LGqzBbg9mL4ZeNrd3cxagpO5mNl64AKgpzCln5rOtjSTM3O8sn84jLcXEQnNSYM+6HO/C3gKeA34jrvvMLN7zOymoNlDQJOZdQOfAo5cgvlu4Kdm9iK5k7Qfc/dQ+k/aM40AdOlxCCJSZvLqo3f3J4EnFy377ILpKeADS/zed4HvnmGNBbG8NkWmqZrndg9wx7vXh12OiMg5E/k7YxfqyKTp2j2gAcNFpKyUV9C3pRmcmGFX71jYpYiInDNlFfRHHnD2nC6zFJEyUlZBv66pmuaapE7IikhZKaugNzM62xp1h6yIlJWyCnrInZDdPzTJgSENGC4i5aEsgx40EImIlI+yC/qLV9ZRm4yr+0ZEykbZBX2swrhqXaP26EWkbJRd0ENuIJKfHxpjaEIDhotI9JVp0Of66XWZpYiUg7IM+revaSARq1D3jYiUhbIM+lRljMtX1+sOWREpC2UZ9JB77s3L+4aZzM6FXYqIyFlVtkHfmUkzO++8sFf99CISbWUb9Feta8RMJ2RFJPrKNujrqyq5aEWtTsiKSOSVbdBDbhzZ7XsGmdWA4SISYWUd9B2ZNOPZOV49OBJ2KSIiZ03ZBz2g596ISKSVddCfV59iTbpKJ2RFJNLKOught1e/bfcA7howXESiqeyDvjOTpn88S0/feNiliIicFWUf9B1twUAk6qcXkYgq+6Bf37yM5pqEnnsjIpFV9kFvZrSvS+vGKRGJrLIPeoD2TCN7Byb55fBU2KWIiBScgp7cHbKgAcNFJJoU9MDGlXUsS8QU9CISSXkFvZndYGY7zazbzO5eYn3SzL4drN9qZplF69ea2ZiZfbowZRdWPFbBVesadYesiETSSYPezGLA/cCNwEbgVjPbuKjZZmDQ3TcA9wH3Llr/BeAfzrzcs6cjk2bnoVGGJ2fCLkVEpKDy2aPvBLrdvcfds8DjwKZFbTYBjwTTTwDXm5kBmNm/AV4HdhSm5LOjPdOIO2zfo8chiEi05BP0rcDeBfP7gmVLtnH3WWAYaDKzGuA/A3/2Vm9gZneaWZeZdfX29uZbe0FduaaRypjpenoRiZyzfTL2c8B97j72Vo3c/QF3b3f39paWlrNc0tKqEjEuba3XHbIiEjnxPNrsB9YsmF8dLFuqzT4ziwP1QD9wDXCzmf13oAGYN7Mpd//yGVd+FnRm0nztX3YzNTNHqjIWdjkiIgWRzx79NuACM2szswRwC7BlUZstwO3B9M3A057zK+6ecfcM8EXgL4o15CF3QjY7N89Le4fCLkVEpGBOGvRBn/tdwFPAa8B33H2Hmd1jZjcFzR4i1yffDXwKeNMlmKWgPdMI6MYpEYmWfLpucPcngScXLfvsgukp4AMn+RufO436zqmG6gQXrqhhmwYiEZEI0Z2xi3RkcgOGz81rIBIRiQYF/SKdbWlGp2d5TQOGi0hEKOgXOTJguPrpRSQqFPSLrGqoorWhSkEvIpGhoF9CR6aRbbsHNWC4iESCgn4JHW1peken2dM/EXYpIiJnTEG/hM6gn17PvRGRKFDQL2HD8hoaqyv13BsRiQQF/RLMjPaMBgwXkWhQ0J9AZybN7v4JDo9qwHARKW0K+hM48tybLj0OQURKnIL+BC5traeqMqZxZEWk5CnoT6AyVsGVaxvUTy8iJU9B/xY6MmleOzjC6JQGDBeR0qWgfwudbWnmHZ7XgOEiUsIU9G/hijUNxCpM3TciUtIU9G9hWTLOpavqNBCJiJQ0Bf1JdGTSvLh3iOnZubBLERE5LQr6k+hoS5OdneflfcNhlyIicloU9CfRoQeciUiJU9CfRHpZgg3La/SAMxEpWQr6PHRkGunaM8i8BgwXkRKkoM9DRybN6NQsOw+Nhl2KiMgpU9DnQQOGi0gpU9DnYXVjFSvrU3rAmYiUJAV9HsyMjmAgEg0YLiKlRkGfp45MI4dGptk7MBl2KSIip0RBn6eONvXTi0hpyivozewGM9tpZt1mdvcS65Nm9u1g/VYzywTLO83sxeDnJTN7f2HLP3cuXF5LfVWlgl5ESs5Jg97MYsD9wI3ARuBWM9u4qNlmYNDdNwD3AfcGy18B2t39CuAG4CtmFi9U8edSRYXRvq5Rd8iKSMnJZ4++E+h29x53zwKPA5sWtdkEPBJMPwFcb2bm7hPuPhssTwElfSazoy1NT+84fWPTYZciIpK3fIK+Fdi7YH5fsGzJNkGwDwNNAGZ2jZntAF4GPrYg+I8yszvNrMvMunp7e0/9U5wjR66n79JevYiUkLN+Mtbdt7r7JUAH8CdmllqizQPu3u7u7S0tLWe7pNN2WWs9yXiFnk8vIiUln6DfD6xZML86WLZkm6APvh7oX9jA3V8DxoBLT7fYsCXiFVyxRgOGi0hpySfotwEXmFmbmSWAW4Ati9psAW4Ppm8GnnZ3D34nDmBm64C3AbsLUnlIOtvS7Dgwwvj0m3qgRESK0kmDPuhTvwt4CngN+I677zCze8zspqDZQ0CTmXUDnwKOXIL5LuAlM3sR+B7wcXfvK/SHOJc6Mmnm5p3tb6j7RkRKQ16XOrr7k8CTi5Z9dsH0FPCBJX7vUeDRM6yxqFy1rpEKg22vD/ArFxTv+QQRkSN0Z+wpqknGuWRVva6nF5GSoaA/De2ZRl7cO0R2dj7sUkRETkpBfxo6M2mmZuZ55YAGDBeR4qegPw3tRwYi0fPpRaQEKOhPQ0ttkvXNy3Q9vYiUBAX9acoNRKIBw0Wk+CnoT1N7ppHhyRm6e8fCLkVE5C0p6E9TZzAQicaRFZFip6A/TWvT1SyvTaqfXkSKnoL+NJkZHW1pXXkjIkVPQX8GOjNpDgxPsW9wIuxSREROSEF/Bo4MRKLuGxEpZgr6M3DRebXUJuMaiEREipqC/gzEKoyrM43qpxeRoqagP0MdmTS/ODzG4Hg27FJERJakoD9DR66nVz+9iBQrBf0Zunx1PYl4hYJeRIqWgv4MJeMx3r66nud0QlZEipSCvgA6Mml27B9mIqsBw0Wk+CjoC6CjLc3svPPiG0NhlyIi8iYK+gK4el0jZmgcWREpSgr6AqhLVXLxeXU6ISsiRUlBXyCdbWm27xliZk4DhotIcVHQF0h7ppHJmTlePTASdikiIsdR0BdIpx5wJiJFSkFfIMvrUqxrqtaIUyJSdBT0BdSRSdO1ZxB3DRguIsVDQV9AnZk0A+NZdmnAcBEpInkFvZndYGY7zazbzO5eYn3SzL4drN9qZplg+XvM7Hkzezl4/fXCll9c2jONADz3uh6HICLF46RBb2Yx4H7gRmAjcKuZbVzUbDMw6O4bgPuAe4PlfcD73P0y4Hbg0UIVXozampfRXJOgSydkRaSI5LNH3wl0u3uPu2eBx4FNi9psAh4Jpp8Arjczc/cX3P1AsHwHUGVmyUIUXozMjI5MWnfIikhRySfoW4G9C+b3BcuWbOPus8Aw0LSozW8D2919evEbmNmdZtZlZl29vb351l6UrmlLs29wku//9GDYpYiIAOfoZKyZXUKuO+ffLbXe3R9w93Z3b29paTkXJZ01v9Oxho5MI594/AV++OqhsMsREckr6PcDaxbMrw6WLdnGzOJAPdAfzK8Gvgd82N13nWnBxa46Eefh3+/gklV1fPyx7fzkF6V9hCIipS+foN8GXGBmbWaWAG4Btixqs4XcyVaAm4Gn3d3NrAH4PnC3u/9LoYoudrWpSh75SCfnL6/hjm908WxPf9gliUgZO2nQB33udwFPAa8B33H3HWZ2j5ndFDR7CGgys27gU8CRSzDvAjYAnzWzF4Of5QX/FEWooTrBNzd3srqxms1f38b2N3TJpYiEw4rtLs729nbv6uoKu4yCOTwyxe985Rn6x7N8645rubS1PuySRCSCzOx5d29fap3ujD3LlteleOyOa6lLVfKhh7ay85ejYZckImVGQX8OtDZU8bd3XEMiXsFtD26lR49IEJFzSEF/jqxrWsZjH70WcH7vq1vZOzARdkkiUiYU9OfQhuU1PLr5GqZm57j1q89yYGgy7JJEpAwo6M+xi1fW8ehHrmF4YobbHtzK4dGpsEsSkYhT0IfgstX1fP0jHRwameKDD25lYDwbdkkiEmEK+pBcvS7NQ7d3sKd/gg8+uJXhiZmwSxKRiFLQh+i685t44MPtdB8e4/avPcfY9GzYJYlIBCnoQ/arF7Zw/21X8cr+YT7ytW1MZufCLklEIkZBXwTes3EFX7zlCrr2DHDHN7qYmlHYi0jhKOiLxHsvX8Xnb347/9zdx8cf2052dj7skkQkIhT0ReS3r17Nn7//Up7+2WE+8fgLzM4p7EXkzCnoi8xt16zjT9+7kX945Zd8+u9eYm6+uB46JyKlJx52AfJmm9/VxtTMHJ9/aiepyhh/8f7LqKiwsMsSkRKloC9Sf/hrG5iemeOvn+4mGa/gczddgpnCXkROnYK+iH3yPRcyOTPHV3/yOqnKGHff+DaFvYicMgV9ETMzPvObFzM9O89X/qmHVGWMT77nwrDLEpESo6AvcmbG5953CVMzc3zpR78gVRnj3/+r88MuS0RKiIK+BFRUGH/5by9nenaee3/wM1KVFfzBO9vCLktESoSCvkTEKoz/8YG3Mz0zz5/971dJVca4tXNt2GWJSAnQdfQlJB6r4K9vvZJfu6iFz3zvZb73wr6wSxKREqCgLzGJeAV/88Grecf5TfzRd17i+z89GHZJIlLkFPQlKFUZ46sfbufqdY184vEX+OGrh8IuSUSKmIK+RFUn4jz8+x1csqqOjz+2nZ/8ojfskkSkSCnoS1htqpJHPtLJ+ctruOMbXTzb0x92SSJShBT0Ja6hOsE3N3eyurGazV/fxvY3BsMuSUSKjII+AppqkvztR6+hpTbJ7Q8/xyv7h8MuSUSKiII+IpbXpXjsjmupS1XyoYe2svOXo2GXJCJFIq+gN7MbzGynmXWb2d1LrE+a2beD9VvNLBMsbzKzH5vZmJl9ubCly2KtDVV8645rScQruO3BrfT0joVdkogUgZMGvZnFgPuBG4GNwK1mtnFRs83AoLtvAO4D7g2WTwF/Cny6YBXLW1rbVM1jH70WcG780k+47cFn+fLTv+D5PQPMaMQqkbKUzyMQOoFud+8BMLPHgU3AqwvabAI+F0w/AXzZzMzdx4F/NrMNhStZTmbD8hr+7mPv4BvP7OaZXf381T/+HIDqRIz2TJrr1jdx7fo0l7XWE4+p904k6vIJ+lZg74L5fcA1J2rj7rNmNgw0AX2FKFJOXVvzMv7r+y4BYHA8y9bX+3lmVz/P9PRz7w9+BkBNMk5HppHrzm/iuvXNbFxVR0wjWYlETlE81MzM7gTuBFi7Vg/qKrTGZQluuHQlN1y6EoC+sWme7ckF/7M9/fx4Z+5mq7pUnM623N7+dec3cfF5dRrCUCQC8gn6/cCaBfOrg2VLtdlnZnGgHsj77h13fwB4AKC9vV2jYZ9lzTVJ3nv5Kt57+SoADo9M8UxP/9Hw/+FruUcqNFRXck1brqvnuvObuWB5jYJfpATlE/TbgAvMrI1coN8C/N6iNluA24FngJuBp91dgV0iltel2HRFK5uuaAXg4PDk0dB/pqefp3bkgj+9LJHb21/fxHXnN3F+S42GNhQpAZZPHpvZbwJfBGLAw+7+52Z2D9Dl7lvMLAU8ClwJDAC3LDh5uxuoAxLAEPAb7v7qEm8D5Pbou7q6zuxTSUHtG5w4GvrP7urnwPAUkDsyONLNc936Jtqalyn4RUJiZs+7e/uS64ptx1tBX9zcnb0DkzzT03c0/A+NTAOwoi55dG//2vVNrE1XK/hFzhEFvZw17s7rfeM8c/Tk7gB9Y7ngX1Wf4trzm7i8tZ6VDVW0NlSxsj5FellCGwCRAlPQyznj7uzqHTvW1dMzwMB49rg2yXgFq4LQX1lfRWtDipXBfGtDFSsbqqhJFsUFYSIl462CXv+bpKDMjA3La9mwvJYPXZfB3ekfz3JwaIr9Q5McHJ7k4HAwPTTJ/9vVx6GRKeYX7W/UpuJHjwAWHg2srK9iVUOK8+pTJOOxcD6kSIlR0MtZZWY01yRprkly2er6JdvMzs1zaHSag0OTwcZgKpie4uDwJC/tG37TUQHkTgavakixqr6KlcHrqoZj0y21Sd0AJoKCXopAPFZBa7DXvuRxJzCZnVt0NJDbCOwfmqS7d4yf/KKX8ezc8X+3wlhRl8ptDBqqWF6bJL0sSVNNguaaBE3BdNOyJFUJHR1IdCnopSRUJWKsb6lhfUvNkuvdnZHJWQ4M57qHDgxNcSA4OjgwNMn2NwbpHZ1mambpB7tVJ2JHQ79pWSI3XZObbq5Jkg6WNdckaaxOkIjrGUFSOhT0EglmRn11JfXVlVy8su6E7Says/SPZekfz9I/Nk3/WJa+8dzrwHiWvrFpDg5P8cqBYfrHsswuPnkQqEvFaa45dkSQew02DouWNVQnyroLaSI7S99olt6xaXpHp+lb8DqZnaOlNsnyuhQr6pIsrz32qqOswlHQS1mpTsSpTsdZk64+aVt3Z2RqNrdBOLJhGM/mNhRj0/QFy3r6xti2O8vARJalLmKrsNxdxelluQ1AQ3UldalK6qri1FdVUldVmXtNHZmOUxfMpyqLM+ymZuYWBHb2TQG+8HVxl9oR6WUJqipj9I5Nk51985FWXSp+dAOwojZFS/C6YsFGYXldsmi/o2KioBc5ATOjPgjh9S0nbz837wxOBBuC4Cjh6MZhwRFE9+ExRqZmGJ6cOWFX0hGJeEWwEXjzRiE3H18wffy6mlT8lI4kpmfn6D9haB+/fHR6dsm/0VBdSXNNkpaaJJetbqClJklzbSJ4zS1vqc11hVUGj8h2d4YnZzg0Ms2hkSkOjwavI1McGpnm8OgUW18f4PDoFDNzb96S1ldVHhf8K+pSrFh0lLC8LlnWV2kp6EUKJFZx7AojqM3rd6Zn5xiZnD0a/COTM4xMzR6bnpxZsG6WgfEsr/eNH203d4KupSNqU/HjjxSCjUBVIna0q+pIkA9Pzpzwb7TU5j7XxavqeHcQ1s01iaPLW2qTNC1Lnta5CzOjoTrXxXXReSf+3tydwYkZDo9OHdsoLNgwHBqZpmfXGL1j00tuEBqqK1kRhP6RLqIjRwfNNbkjrfqqBA3VlUc3QlGhoBcJUTIeo6U2Rktt8pR/190Zz84d3SgstaEYDjYUI8GG4o2BCYYnZ5jIztFYXUlLbZILV9Tyzg3HArt5QZA31xRP14iZHe0Ce9t5J243HxxZHRqZ5tDoFL3BRuHQ6BSHR6Y5NDpN9+E+Do9On3BDWZOM01BdmfsJwv/46QQNVZU0Lju2cWioqizagXwU9CIlysyoScapSeZuLpOcigoLToon2ciJT8zPzzsDE1kOjUzRN5ZlaCJ3VDM0McPgRJbhiRmGJnPTB4YmGZqcYWgi+6ab+xaqTcapr66ksToRHCEsPb1wY1F/DjYQCnoRKUsVx3W15Wd+3hmdnmU42BgcCf+hiQUbiGDZ4MQM+wYnj25A3nIDkcodQdxwyXn8l99aPCT3mVPQi4jkqaLi2An6tU0nv3LriPl5Z3RqlqHJ3AZg8dHD0ESum+28+rNzZKagFxE5yyoqjt3nsa4phPc/928pIiLnkoJeRCTiFPQiIhGnoBcRiTgFvYhIxCnoRUQiTkEvIhJxCnoRkYgzX+oB2iEys15gzxn8iWagr0DllDp9F8fT93GMvovjReH7WOfuSz5Qu+iC/kyZWZe7n2jo0bKi7+J4+j6O0XdxvKh/H+q6ERGJOAW9iEjERTHoHwi7gCKi7+J4+j6O0XdxvEh/H5HroxcRkeNFcY9eREQWiEzQm9kNZrbTzLrN7O6w6wmTma0xsx+b2atmtsPMPhF2TWEzs5iZvWBm/yfsWsJmZg1m9oSZ/czMXjOz68KuKUxm9sng/8krZvYtM0uFXVOhRSLozSwG3A/cCGwEbjWzwo/HVTpmgT9y943AtcAflvn3AfAJ4LWwiygSXwJ+4O5vA95OGX8vZtYK/Eeg3d0vBWLALeFWVXiRCHqgE+h29x53zwKPA5tCrik07n7Q3bcH06Pk/iO3hltVeMxsNfBbwINh1xI2M6sH3g08BODuWXcfCreq0MWBKjOLA9XAgZDrKbioBH0rsHfB/D7KONgWMrMMcCWwNdxKQvVF4I+B+bALKQJtQC/wtaAr60EzWxZ2UWFx9/3AXwFvAAeBYXf/x3CrKryoBL0swcxqgO8C/8ndR8KuJwxm9l7gsLs/H3YtRSIOXAX8jbtfCYwDZXtOy8wayR39twGrgGVm9sFwqyq8qAT9fmDNgvnVwbKyZWaV5EL+MXf/+7DrCdE7gZvMbDe5Lr1fN7NvhltSqPYB+9z9yBHeE+SCv1z9a+B1d+919xng74F3hFxTwUUl6LcBF5hZm5klyJ1M2RJyTaExMyPXB/uau38h7HrC5O5/4u6r3T1D7t/F0+4euT22fLn7L4G9ZnZRsOh64NUQSwrbG8C1ZlYd/L+5ngienI6HXUAhuPusmd0FPEXurPnD7r4j5LLC9E7gQ8DLZvZisOwz7v5kiDVJ8fgPwGPBTlEP8Ach1xMad99qZk8A28ldrfYCEbxLVnfGiohEXFS6bkRE5AQU9CIiEaegFxGJOAW9iEjEKehFRCJOQS8iEnEKehGRiFPQi4hE3P8HMpS2wkR+JWsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(plt.plot(evalution_costplt))\n",
    "np.mean(evalution_costplt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eopch : 100 , batchsize : 512 , timesize : 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexPrice shape:  (40559, 1)\n",
      "StockPrice shape:  (40559, 81)\n",
      "making dataset progress : finished\t59\n",
      "WARNING:tensorflow:From <ipython-input-6-5e94407ee4da>:38: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-6-5e94407ee4da>:40: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "result =  Tensor(\"concat:0\", shape=(None, 16, 256), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-3-a8129d876eea>:55: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "LSTM2 =  <__main__.MI_LSTMCell object at 0x7f92293f4650>\n",
      "WARNING:tensorflow:From <ipython-input-3-a8129d876eea>:76: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "Y_2 =  (None, 16, 64)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f94801a9690>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f92291a13d0>, <gast.gast.Return object at 0x7f92291a1450>]\n",
      "WARNING: AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f94801a9690>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f92291a13d0>, <gast.gast.Return object at 0x7f92291a1450>]\n",
      "inputs :  Tensor(\"rnn_22/transpose_1:0\", shape=(None, 16, 64), dtype=float32)\n",
      "weight :  Tensor(\"attention_1/Squeeze:0\", shape=(None, 16), dtype=float32)\n",
      "encoder_states :  Tensor(\"encoder/transpose_1:0\", shape=(None, 16, 64), dtype=float32)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f92292eca50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f9228dcff90>, <gast.gast.Return object at 0x7f9228dcfed0>]\n",
      "WARNING: AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f92292eca50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f9228dcff90>, <gast.gast.Return object at 0x7f9228dcfed0>]\n",
      "y_pred :  Tensor(\"decoder/dense_5/BiasAdd:0\", shape=(None, 1), dtype=float32)\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "16.92835489375284\n",
      "383.526218463041\n",
      "epoch : 0, t_cost : 0.003774, e_cost : 0.199545, elapsed time : 796.94sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "5.191064181719412\n",
      "215.13176869906601\n",
      "epoch : 1, t_cost : 0.001157, e_cost : 0.111931, elapsed time : 791.31sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "3.5147523740160977\n",
      "147.05044661644206\n",
      "epoch : 2, t_cost : 0.000783, e_cost : 0.076509, elapsed time : 791.99sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "2.2345347261543793\n",
      "103.30094555855612\n",
      "epoch : 3, t_cost : 0.000498, e_cost : 0.053747, elapsed time : 792.23sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "1.3649703126638997\n",
      "125.11618849074148\n",
      "epoch : 4, t_cost : 0.000304, e_cost : 0.065097, elapsed time : 792.02sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "1.035768516171629\n",
      "67.35869813546742\n",
      "epoch : 5, t_cost : 0.000231, e_cost : 0.035046, elapsed time : 792.16sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.8209606873897428\n",
      "54.934910373573075\n",
      "epoch : 6, t_cost : 0.000183, e_cost : 0.028582, elapsed time : 792.37sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.6677151957319438\n",
      "46.64543831804622\n",
      "epoch : 7, t_cost : 0.000149, e_cost : 0.024269, elapsed time : 791.94sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.6287708975942223\n",
      "41.93431250123831\n",
      "epoch : 8, t_cost : 0.000140, e_cost : 0.021818, elapsed time : 792.31sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.5710500822660833\n",
      "39.80596717210574\n",
      "epoch : 9, t_cost : 0.000127, e_cost : 0.020711, elapsed time : 792.10sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.5493273347665308\n",
      "38.51089902292006\n",
      "epoch : 10, t_cost : 0.000122, e_cost : 0.020037, elapsed time : 792.22sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.5255453049867356\n",
      "39.766085648057924\n",
      "epoch : 11, t_cost : 0.000117, e_cost : 0.020690, elapsed time : 792.43sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.5239475618213874\n",
      "37.21703594415885\n",
      "epoch : 12, t_cost : 0.000117, e_cost : 0.019364, elapsed time : 792.17sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.5029574775462606\n",
      "36.853362598521926\n",
      "epoch : 13, t_cost : 0.000112, e_cost : 0.019174, elapsed time : 792.54sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.4926622333341584\n",
      "38.78091352645424\n",
      "epoch : 14, t_cost : 0.000110, e_cost : 0.020177, elapsed time : 792.32sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.4811348101488875\n",
      "35.546494725494995\n",
      "epoch : 15, t_cost : 0.000107, e_cost : 0.018495, elapsed time : 792.51sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.46802535597453243\n",
      "38.72907309338916\n",
      "epoch : 16, t_cost : 0.000104, e_cost : 0.020150, elapsed time : 792.44sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.4515710147079517\n",
      "36.10501192281663\n",
      "epoch : 17, t_cost : 0.000101, e_cost : 0.018785, elapsed time : 792.09sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.45137286796943954\n",
      "37.58181552159658\n",
      "epoch : 18, t_cost : 0.000101, e_cost : 0.019553, elapsed time : 792.17sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.4467327298875716\n",
      "39.092801812890684\n",
      "epoch : 19, t_cost : 0.000100, e_cost : 0.020340, elapsed time : 792.44sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.4489097594946543\n",
      "40.2427644875861\n",
      "epoch : 20, t_cost : 0.000100, e_cost : 0.020938, elapsed time : 792.36sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.4438011844322318\n",
      "39.3330414574084\n",
      "epoch : 21, t_cost : 0.000099, e_cost : 0.020465, elapsed time : 793.04sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.43606496216943924\n",
      "37.678716161244665\n",
      "epoch : 22, t_cost : 0.000097, e_cost : 0.019604, elapsed time : 793.23sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.43110959563955475\n",
      "39.3935438593835\n",
      "epoch : 23, t_cost : 0.000096, e_cost : 0.020496, elapsed time : 794.67sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.42715697508174344\n",
      "37.572580197756906\n",
      "epoch : 24, t_cost : 0.000095, e_cost : 0.019549, elapsed time : 793.16sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.41647503169497213\n",
      "100.25813000174094\n",
      "epoch : 25, t_cost : 0.000093, e_cost : 0.052163, elapsed time : 793.12sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.4144861585414219\n",
      "55.02720309560027\n",
      "epoch : 26, t_cost : 0.000092, e_cost : 0.028630, elapsed time : 793.02sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.41455637497620046\n",
      "52.17781338664645\n",
      "epoch : 27, t_cost : 0.000092, e_cost : 0.027148, elapsed time : 793.81sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.4094090320313626\n",
      "41.91470112541356\n",
      "epoch : 28, t_cost : 0.000091, e_cost : 0.021808, elapsed time : 792.14sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.409714998626896\n",
      "54.74537457605038\n",
      "epoch : 29, t_cost : 0.000091, e_cost : 0.028484, elapsed time : 792.26sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.4026848217567931\n",
      "51.74872778239296\n",
      "epoch : 30, t_cost : 0.000090, e_cost : 0.026924, elapsed time : 792.35sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3989938036975218\n",
      "49.544343830530124\n",
      "epoch : 31, t_cost : 0.000089, e_cost : 0.025777, elapsed time : 792.32sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.39348900170352863\n",
      "23.583022727645584\n",
      "epoch : 32, t_cost : 0.000088, e_cost : 0.012270, elapsed time : 792.37sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3930342189546536\n",
      "36.08504851012185\n",
      "epoch : 33, t_cost : 0.000088, e_cost : 0.018775, elapsed time : 792.24sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3885279309006364\n",
      "39.443397881073906\n",
      "epoch : 34, t_cost : 0.000087, e_cost : 0.020522, elapsed time : 792.44sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.39270649595528084\n",
      "32.80001780515158\n",
      "epoch : 35, t_cost : 0.000088, e_cost : 0.017066, elapsed time : 791.96sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3844812892139089\n",
      "29.418449187403894\n",
      "epoch : 36, t_cost : 0.000086, e_cost : 0.015306, elapsed time : 792.01sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.38667939421929987\n",
      "43.39225173431623\n",
      "epoch : 37, t_cost : 0.000086, e_cost : 0.022577, elapsed time : 791.82sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.383415080078521\n",
      "38.301307161968\n",
      "epoch : 38, t_cost : 0.000085, e_cost : 0.019928, elapsed time : 791.78sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.37593442197248805\n",
      "58.540998341868544\n",
      "epoch : 39, t_cost : 0.000084, e_cost : 0.030458, elapsed time : 791.40sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.38376309470777414\n",
      "43.49567448544258\n",
      "epoch : 40, t_cost : 0.000086, e_cost : 0.022630, elapsed time : 792.31sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3726765529822842\n",
      "41.67431798137477\n",
      "epoch : 41, t_cost : 0.000083, e_cost : 0.021683, elapsed time : 791.56sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3739610250459009\n",
      "61.66110813725754\n",
      "epoch : 42, t_cost : 0.000083, e_cost : 0.032082, elapsed time : 791.57sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.37230337325763685\n",
      "43.44507636173512\n",
      "epoch : 43, t_cost : 0.000083, e_cost : 0.022604, elapsed time : 792.33sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.36881422407805076\n",
      "64.97008912310775\n",
      "epoch : 44, t_cost : 0.000082, e_cost : 0.033803, elapsed time : 792.23sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3742040767315302\n",
      "82.0401945586018\n",
      "epoch : 45, t_cost : 0.000083, e_cost : 0.042685, elapsed time : 792.23sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.36867879358169375\n",
      "49.80866667806549\n",
      "epoch : 46, t_cost : 0.000082, e_cost : 0.025915, elapsed time : 792.16sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.37021517020821193\n",
      "65.28560716013453\n",
      "epoch : 47, t_cost : 0.000083, e_cost : 0.033968, elapsed time : 792.47sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3630152829209692\n",
      "46.50590217437275\n",
      "epoch : 48, t_cost : 0.000081, e_cost : 0.024197, elapsed time : 792.43sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.366020159594882\n",
      "39.441990167168115\n",
      "epoch : 49, t_cost : 0.000082, e_cost : 0.020521, elapsed time : 792.55sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.36153605436948055\n",
      "68.1317038444904\n",
      "epoch : 50, t_cost : 0.000081, e_cost : 0.035448, elapsed time : 792.28sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.36338363293225484\n",
      "36.80328208089486\n",
      "epoch : 51, t_cost : 0.000081, e_cost : 0.019148, elapsed time : 792.12sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3583239252398016\n",
      "40.522754678833735\n",
      "epoch : 52, t_cost : 0.000080, e_cost : 0.021084, elapsed time : 791.71sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.36052350475119965\n",
      "48.758816286535875\n",
      "epoch : 53, t_cost : 0.000080, e_cost : 0.025369, elapsed time : 792.28sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3642285872847424\n",
      "28.375495468470035\n",
      "epoch : 54, t_cost : 0.000081, e_cost : 0.014764, elapsed time : 792.30sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.34909597296109496\n",
      "20.709087490598904\n",
      "epoch : 55, t_cost : 0.000078, e_cost : 0.010775, elapsed time : 792.29sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3536475342784797\n",
      "19.37462657714059\n",
      "epoch : 56, t_cost : 0.000079, e_cost : 0.010080, elapsed time : 792.21sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.35162150119504076\n",
      "23.53578373722121\n",
      "epoch : 57, t_cost : 0.000078, e_cost : 0.012245, elapsed time : 793.16sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.35046908885578887\n",
      "18.34789968908808\n",
      "epoch : 58, t_cost : 0.000078, e_cost : 0.009546, elapsed time : 792.57sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.34930207144861924\n",
      "18.732771666625922\n",
      "epoch : 59, t_cost : 0.000078, e_cost : 0.009746, elapsed time : 792.32sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.35125722758812117\n",
      "18.615479911219154\n",
      "epoch : 60, t_cost : 0.000078, e_cost : 0.009685, elapsed time : 792.29sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3486328292096914\n",
      "22.822544049784483\n",
      "epoch : 61, t_cost : 0.000078, e_cost : 0.011874, elapsed time : 791.96sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3445400243358563\n",
      "18.697769909529597\n",
      "epoch : 62, t_cost : 0.000077, e_cost : 0.009728, elapsed time : 791.97sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3446869389617859\n",
      "18.081901284414926\n",
      "epoch : 63, t_cost : 0.000077, e_cost : 0.009408, elapsed time : 792.27sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3410128618215822\n",
      "21.340885408066242\n",
      "epoch : 64, t_cost : 0.000076, e_cost : 0.011103, elapsed time : 792.33sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.34375493379093314\n",
      "18.609586186568777\n",
      "epoch : 65, t_cost : 0.000077, e_cost : 0.009682, elapsed time : 792.36sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3410771379453763\n",
      "22.236652068590047\n",
      "epoch : 66, t_cost : 0.000076, e_cost : 0.011570, elapsed time : 792.03sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3408533937304128\n",
      "17.601558631642547\n",
      "epoch : 67, t_cost : 0.000076, e_cost : 0.009158, elapsed time : 791.85sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.341594247516241\n",
      "24.006593366641027\n",
      "epoch : 68, t_cost : 0.000076, e_cost : 0.012490, elapsed time : 792.35sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.34237202367739883\n",
      "20.357155477555352\n",
      "epoch : 69, t_cost : 0.000076, e_cost : 0.010592, elapsed time : 792.16sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.34553688062351284\n",
      "27.17106843250076\n",
      "epoch : 70, t_cost : 0.000077, e_cost : 0.014137, elapsed time : 792.43sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.34637403133820044\n",
      "26.546916076789785\n",
      "epoch : 71, t_cost : 0.000077, e_cost : 0.013812, elapsed time : 792.31sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3460332729878246\n",
      "17.998729048849782\n",
      "epoch : 72, t_cost : 0.000077, e_cost : 0.009365, elapsed time : 792.28sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3448386575910263\n",
      "23.895777669411473\n",
      "epoch : 73, t_cost : 0.000077, e_cost : 0.012433, elapsed time : 792.16sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.347624392572925\n",
      "36.3818556013357\n",
      "epoch : 74, t_cost : 0.000077, e_cost : 0.018929, elapsed time : 791.88sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3475867656979972\n",
      "21.085018145327922\n",
      "epoch : 75, t_cost : 0.000077, e_cost : 0.010970, elapsed time : 792.31sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.34409379031467324\n",
      "25.678766235163494\n",
      "epoch : 76, t_cost : 0.000077, e_cost : 0.013360, elapsed time : 792.09sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.34099468763452023\n",
      "38.08987193865323\n",
      "epoch : 77, t_cost : 0.000076, e_cost : 0.019818, elapsed time : 792.44sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3425220189715219\n",
      "18.88237712713817\n",
      "epoch : 78, t_cost : 0.000076, e_cost : 0.009824, elapsed time : 792.12sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.34622152340989487\n",
      "22.73249141105407\n",
      "epoch : 79, t_cost : 0.000077, e_cost : 0.011828, elapsed time : 792.10sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.34943365457775144\n",
      "21.288359488396964\n",
      "epoch : 80, t_cost : 0.000078, e_cost : 0.011076, elapsed time : 792.14sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3446393617382455\n",
      "18.783947100615478\n",
      "epoch : 81, t_cost : 0.000077, e_cost : 0.009773, elapsed time : 792.53sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3506131444555649\n",
      "20.38916789085488\n",
      "epoch : 82, t_cost : 0.000078, e_cost : 0.010608, elapsed time : 792.35sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3422241133971511\n",
      "17.599480604869314\n",
      "epoch : 83, t_cost : 0.000076, e_cost : 0.009157, elapsed time : 792.33sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.34543030679469666\n",
      "18.70757145824973\n",
      "epoch : 84, t_cost : 0.000077, e_cost : 0.009733, elapsed time : 792.25sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.34699378249661095\n",
      "16.652588842320256\n",
      "epoch : 85, t_cost : 0.000077, e_cost : 0.008664, elapsed time : 792.35sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.351152301392176\n",
      "17.42968135121191\n",
      "epoch : 86, t_cost : 0.000078, e_cost : 0.009069, elapsed time : 792.04sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.34586344317585827\n",
      "17.824948695862986\n",
      "epoch : 87, t_cost : 0.000077, e_cost : 0.009274, elapsed time : 791.97sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.34467589603127635\n",
      "16.634370607065648\n",
      "epoch : 88, t_cost : 0.000077, e_cost : 0.008655, elapsed time : 792.06sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.34054387193737057\n",
      "17.111329599629244\n",
      "epoch : 89, t_cost : 0.000076, e_cost : 0.008903, elapsed time : 791.61sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.33709980047706267\n",
      "16.79882212524535\n",
      "epoch : 90, t_cost : 0.000075, e_cost : 0.008740, elapsed time : 792.40sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.33650925883057425\n",
      "26.791899479452695\n",
      "epoch : 91, t_cost : 0.000075, e_cost : 0.013940, elapsed time : 792.47sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.34198016008394916\n",
      "16.049440770224464\n",
      "epoch : 92, t_cost : 0.000076, e_cost : 0.008350, elapsed time : 792.10sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.34150434745379243\n",
      "19.481681016470247\n",
      "epoch : 93, t_cost : 0.000076, e_cost : 0.010136, elapsed time : 792.34sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3409259816530721\n",
      "16.59921596946151\n",
      "epoch : 94, t_cost : 0.000076, e_cost : 0.008636, elapsed time : 792.37sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.341787998021573\n",
      "23.62780346143336\n",
      "epoch : 95, t_cost : 0.000076, e_cost : 0.012293, elapsed time : 792.32sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3433426255573977\n",
      "19.34648445477069\n",
      "epoch : 96, t_cost : 0.000077, e_cost : 0.010066, elapsed time : 792.18sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3400125581706561\n",
      "25.49389755698212\n",
      "epoch : 97, t_cost : 0.000076, e_cost : 0.013264, elapsed time : 792.40sec\n",
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.33662410178794744\n",
      "23.51176387976011\n",
      "epoch : 98, t_cost : 0.000075, e_cost : 0.012233, elapsed time : 792.49sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2296860, 16, 1) (2296860, 10, 16, 1) (2296860, 10, 16, 1) (2296860, 16, 1) (2296860, 1)\n",
      "(984369, 16, 1) (984369, 10, 16, 1) (984369, 10, 16, 1) (984369, 16, 1) (984369, 1)\n",
      "0.3363704316930125\n",
      "15.375081258451246\n",
      "epoch : 99, t_cost : 0.000075, e_cost : 0.008000, elapsed time : 792.31sec\n",
      "\n",
      "#Best result at epoch 99\n",
      "t_cost : 0.000075, e_cost : 0.008000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ddcd6e7db3ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n#Best result at epoch {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestEpoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't_cost : {:0.6f}, e_cost : {:0.6f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbestEpoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbestEpoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalution_costplt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.keras.backend.clear_session()\n",
    "#tf.compat.v1.reset_default_graph()\n",
    "#parameter list\n",
    "'''\n",
    "sess=tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(allow_soft_placement=True))\n",
    "name='lstm'\n",
    "timesize=20\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "#\n",
    "'''\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=16\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "\n",
    "kospi=StockData(\n",
    "    'NASDAQ/Sample',\n",
    "    'NASDAQ/NDX.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    \n",
    "result_dic={}\n",
    "evalution_costplt1=[]\n",
    "for i in range(100):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "    \n",
    "    #training batch\n",
    "    \n",
    "    for batch in kospi.getBatch('training'):        \n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    \n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(training_cost)\n",
    "    print(evalution_cost)\n",
    "    \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "    evalution_costplt1.append(evalution_cost)\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "    i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))\n",
    "print(plt.plot(evalution_costplt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<matplotlib.lines.Line2D object at 0x7f921cd7bb10>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02191540688550784"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(plt.plot(evalution_costplt1))\n",
    "np.mean(evalution_costplt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.keras.backend.clear_session()\n",
    "#tf.compat.v1.reset_default_graph()\n",
    "#parameter list\n",
    "'''\n",
    "sess=tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(allow_soft_placement=True))\n",
    "name='lstm'\n",
    "timesize=20\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "#\n",
    "'''\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=16\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "\n",
    "\n",
    "kospi=StockData(\n",
    "    'NASDAQ/Sample',\n",
    "    'NASDAQ/NDX.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "\n",
    "\n",
    "\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    \n",
    "result_dic={}\n",
    "    \n",
    "for i in range(1000):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "    \n",
    "    #training batch\n",
    "    \n",
    "    for batch in kospi.getBatch('training'):        \n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    \n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(training_cost)\n",
    "    print(evalution_cost)\n",
    "    \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "    i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eopch : 100 , batchsize : 512 , timesize : 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexPrice shape:  (3000, 1)\n",
      "StockPrice shape:  (3000, 26)\n",
      "making dataset progress : finished\t\n",
      "result =  Tensor(\"concat:0\", shape=(None, 32, 256), dtype=float32)\n",
      "LSTM2 =  <__main__.MI_LSTMCell object at 0x7f921f7e1310>\n",
      "Y_2 =  (None, 32, 64)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f921f4d9510>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f921f5116d0>, <gast.gast.Return object at 0x7f921f511750>]\n",
      "WARNING: AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f921f4d9510>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f921f5116d0>, <gast.gast.Return object at 0x7f921f511750>]\n",
      "inputs :  Tensor(\"rnn_22/transpose_1:0\", shape=(None, 32, 64), dtype=float32)\n",
      "weight :  Tensor(\"attention_1/Squeeze:0\", shape=(None, 32), dtype=float32)\n",
      "encoder_states :  Tensor(\"encoder/transpose_1:0\", shape=(None, 32, 64), dtype=float32)\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f9494136f50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f94800ecbd0>, <gast.gast.Return object at 0x7f94800ecc50>]\n",
      "WARNING: AutoGraph could not transform <bound method LSTMCell.call of <__main__.LSTMCell object at 0x7f9494136f50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: expected exactly one node node, found [<gast.gast.FunctionDef object at 0x7f94800ecbd0>, <gast.gast.Return object at 0x7f94800ecc50>]\n",
      "y_pred :  Tensor(\"decoder/dense_5/BiasAdd:0\", shape=(None, 1), dtype=float32)\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "9.975976465269923\n",
      "0.8339061513543129\n",
      "epoch : 0, t_cost : 0.095923, e_cost : 0.018952, elapsed time : 43.51sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "2.2625446026213467\n",
      "0.5854147891514003\n",
      "epoch : 1, t_cost : 0.021755, e_cost : 0.013305, elapsed time : 37.16sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "1.4537170813418925\n",
      "0.5017889500595629\n",
      "epoch : 2, t_cost : 0.013978, e_cost : 0.011404, elapsed time : 37.16sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "1.243356559658423\n",
      "0.45458045904524624\n",
      "epoch : 3, t_cost : 0.011955, e_cost : 0.010331, elapsed time : 37.17sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "1.2369465911760926\n",
      "0.5222563012503088\n",
      "epoch : 4, t_cost : 0.011894, e_cost : 0.011869, elapsed time : 37.14sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "1.012715145945549\n",
      "0.5325424303300679\n",
      "epoch : 5, t_cost : 0.009738, e_cost : 0.012103, elapsed time : 37.17sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "1.1974642677232623\n",
      "0.2896007547387853\n",
      "epoch : 6, t_cost : 0.011514, e_cost : 0.006582, elapsed time : 37.30sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "1.0922026771586388\n",
      "0.32045586477033794\n",
      "epoch : 7, t_cost : 0.010502, e_cost : 0.007283, elapsed time : 37.19sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.7929108038078994\n",
      "0.2567202822538093\n",
      "epoch : 8, t_cost : 0.007624, e_cost : 0.005835, elapsed time : 37.13sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.8554044987540692\n",
      "0.32224426709581167\n",
      "epoch : 9, t_cost : 0.008225, e_cost : 0.007324, elapsed time : 37.21sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.9302836048882455\n",
      "0.3162144882371649\n",
      "epoch : 10, t_cost : 0.008945, e_cost : 0.007187, elapsed time : 37.18sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "1.147602156503126\n",
      "0.2113942971918732\n",
      "epoch : 11, t_cost : 0.011035, e_cost : 0.004804, elapsed time : 37.16sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.9061287082731724\n",
      "0.23695346736349165\n",
      "epoch : 12, t_cost : 0.008713, e_cost : 0.005385, elapsed time : 37.19sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.9538443733472377\n",
      "0.2214962843572721\n",
      "epoch : 13, t_cost : 0.009172, e_cost : 0.005034, elapsed time : 37.23sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.67465299309697\n",
      "0.19700397655833513\n",
      "epoch : 14, t_cost : 0.006487, e_cost : 0.004477, elapsed time : 37.19sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.6264249408850446\n",
      "0.18321663362439722\n",
      "epoch : 15, t_cost : 0.006023, e_cost : 0.004164, elapsed time : 37.18sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.6386179832043126\n",
      "0.1755892332876101\n",
      "epoch : 16, t_cost : 0.006141, e_cost : 0.003991, elapsed time : 37.23sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.7021839056396857\n",
      "0.16774898779112846\n",
      "epoch : 17, t_cost : 0.006752, e_cost : 0.003812, elapsed time : 37.19sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.7886759128887206\n",
      "0.15154926636023447\n",
      "epoch : 18, t_cost : 0.007583, e_cost : 0.003444, elapsed time : 37.20sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.7091879871441051\n",
      "0.14131060935324058\n",
      "epoch : 19, t_cost : 0.006819, e_cost : 0.003212, elapsed time : 37.19sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.7731829610420391\n",
      "0.1335413254564628\n",
      "epoch : 20, t_cost : 0.007434, e_cost : 0.003035, elapsed time : 37.14sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.663137812516652\n",
      "0.12181146658258513\n",
      "epoch : 21, t_cost : 0.006376, e_cost : 0.002768, elapsed time : 37.19sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.6724826460704207\n",
      "0.11072315939236432\n",
      "epoch : 22, t_cost : 0.006466, e_cost : 0.002516, elapsed time : 37.26sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.585311686154455\n",
      "0.10085484106093645\n",
      "epoch : 23, t_cost : 0.005628, e_cost : 0.002292, elapsed time : 37.20sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.5235603409819305\n",
      "0.08911015396006405\n",
      "epoch : 24, t_cost : 0.005034, e_cost : 0.002025, elapsed time : 37.21sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.5322883308399469\n",
      "0.08514223020756617\n",
      "epoch : 25, t_cost : 0.005118, e_cost : 0.001935, elapsed time : 37.16sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.448157474049367\n",
      "0.08395208767615259\n",
      "epoch : 26, t_cost : 0.004309, e_cost : 0.001908, elapsed time : 37.20sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.495573224266991\n",
      "0.08380372560350224\n",
      "epoch : 27, t_cost : 0.004765, e_cost : 0.001905, elapsed time : 37.23sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.48914155235979706\n",
      "0.07691310904920101\n",
      "epoch : 28, t_cost : 0.004703, e_cost : 0.001748, elapsed time : 37.21sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.5188159680692479\n",
      "0.07635713886702433\n",
      "epoch : 29, t_cost : 0.004989, e_cost : 0.001735, elapsed time : 37.17sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.4353083038586192\n",
      "0.0729668746353127\n",
      "epoch : 30, t_cost : 0.004186, e_cost : 0.001658, elapsed time : 37.22sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.4974664571345784\n",
      "0.0737389923306182\n",
      "epoch : 31, t_cost : 0.004783, e_cost : 0.001676, elapsed time : 37.20sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.5037055071443319\n",
      "0.07832881226204336\n",
      "epoch : 32, t_cost : 0.004843, e_cost : 0.001780, elapsed time : 37.18sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.5150790379848331\n",
      "0.0742903727805242\n",
      "epoch : 33, t_cost : 0.004953, e_cost : 0.001688, elapsed time : 37.18sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.5951357640442438\n",
      "0.07866927952272817\n",
      "epoch : 34, t_cost : 0.005722, e_cost : 0.001788, elapsed time : 37.20sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.616015525883995\n",
      "0.08670786290895194\n",
      "epoch : 35, t_cost : 0.005923, e_cost : 0.001971, elapsed time : 37.22sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.6086030234582722\n",
      "0.08389459212776273\n",
      "epoch : 36, t_cost : 0.005852, e_cost : 0.001907, elapsed time : 37.21sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.67665604443755\n",
      "0.09062152320984751\n",
      "epoch : 37, t_cost : 0.006506, e_cost : 0.002060, elapsed time : 37.20sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.40018729359144345\n",
      "0.07942635577637702\n",
      "epoch : 38, t_cost : 0.003848, e_cost : 0.001805, elapsed time : 37.26sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.5240947292768396\n",
      "0.08017587568610907\n",
      "epoch : 39, t_cost : 0.005039, e_cost : 0.001822, elapsed time : 37.21sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.5964728493709117\n",
      "0.07696751202456653\n",
      "epoch : 40, t_cost : 0.005735, e_cost : 0.001749, elapsed time : 37.14sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.4977209785138257\n",
      "0.08190429414389655\n",
      "epoch : 41, t_cost : 0.004786, e_cost : 0.001861, elapsed time : 37.15sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.5545802927808836\n",
      "0.0754610869626049\n",
      "epoch : 42, t_cost : 0.005333, e_cost : 0.001715, elapsed time : 37.16sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.5044649979681708\n",
      "0.07201201526913792\n",
      "epoch : 43, t_cost : 0.004851, e_cost : 0.001637, elapsed time : 37.11sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.5963585807476193\n",
      "0.07385704875923693\n",
      "epoch : 44, t_cost : 0.005734, e_cost : 0.001679, elapsed time : 37.18sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.5736544333049096\n",
      "0.07961722603067756\n",
      "epoch : 45, t_cost : 0.005516, e_cost : 0.001809, elapsed time : 37.15sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.5138448795187287\n",
      "0.06974330748198554\n",
      "epoch : 46, t_cost : 0.004941, e_cost : 0.001585, elapsed time : 37.11sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.5455312198610045\n",
      "0.06941928784362972\n",
      "epoch : 47, t_cost : 0.005245, e_cost : 0.001578, elapsed time : 37.23sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.4631012458121404\n",
      "0.07869165198644623\n",
      "epoch : 48, t_cost : 0.004453, e_cost : 0.001788, elapsed time : 37.22sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.4694340671412647\n",
      "0.06449047834030353\n",
      "epoch : 49, t_cost : 0.004514, e_cost : 0.001466, elapsed time : 37.17sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.37047565972898155\n",
      "0.06354008556809276\n",
      "epoch : 50, t_cost : 0.003562, e_cost : 0.001444, elapsed time : 37.18sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.4149071497959085\n",
      "0.06638789910357445\n",
      "epoch : 51, t_cost : 0.003989, e_cost : 0.001509, elapsed time : 37.15sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3308872290654108\n",
      "0.06399725752999075\n",
      "epoch : 52, t_cost : 0.003182, e_cost : 0.001454, elapsed time : 37.21sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.3417848020908423\n",
      "0.05577737360727042\n",
      "epoch : 53, t_cost : 0.003286, e_cost : 0.001268, elapsed time : 37.17sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.2928307466208935\n",
      "0.055489502381533384\n",
      "epoch : 54, t_cost : 0.002816, e_cost : 0.001261, elapsed time : 37.22sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.31534330308204517\n",
      "0.05579029268119484\n",
      "epoch : 55, t_cost : 0.003032, e_cost : 0.001268, elapsed time : 37.20sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.3253028852632269\n",
      "0.05754922624328174\n",
      "epoch : 56, t_cost : 0.003128, e_cost : 0.001308, elapsed time : 37.20sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.33484344772296026\n",
      "0.05260838591493666\n",
      "epoch : 57, t_cost : 0.003220, e_cost : 0.001196, elapsed time : 37.17sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.3067063011112623\n",
      "0.05789837188785896\n",
      "epoch : 58, t_cost : 0.002949, e_cost : 0.001316, elapsed time : 37.19sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.27764127403497696\n",
      "0.05197237586253323\n",
      "epoch : 59, t_cost : 0.002670, e_cost : 0.001181, elapsed time : 37.17sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.24600218457635492\n",
      "0.05211731599410996\n",
      "epoch : 60, t_cost : 0.002365, e_cost : 0.001184, elapsed time : 37.17sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.317318796121981\n",
      "0.05351527268067002\n",
      "epoch : 61, t_cost : 0.003051, e_cost : 0.001216, elapsed time : 37.23sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.31585947988787666\n",
      "0.060889738058904186\n",
      "epoch : 62, t_cost : 0.003037, e_cost : 0.001384, elapsed time : 37.23sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.30272176692960784\n",
      "0.06903368973871693\n",
      "epoch : 63, t_cost : 0.002911, e_cost : 0.001569, elapsed time : 37.15sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.3021972901769914\n",
      "0.05755907585262321\n",
      "epoch : 64, t_cost : 0.002906, e_cost : 0.001308, elapsed time : 37.16sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.3562788898125291\n",
      "0.06484203325817361\n",
      "epoch : 65, t_cost : 0.003426, e_cost : 0.001474, elapsed time : 37.21sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.4094832765404135\n",
      "0.08093163999728858\n",
      "epoch : 66, t_cost : 0.003937, e_cost : 0.001839, elapsed time : 37.17sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.44600336923031136\n",
      "0.0777801945223473\n",
      "epoch : 67, t_cost : 0.004288, e_cost : 0.001768, elapsed time : 37.16sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.4767213489394635\n",
      "0.06770753630553372\n",
      "epoch : 68, t_cost : 0.004584, e_cost : 0.001539, elapsed time : 37.15sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.4077506201574579\n",
      "0.06363288615830243\n",
      "epoch : 69, t_cost : 0.003921, e_cost : 0.001446, elapsed time : 37.20sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.45976445695851\n",
      "0.07002581428969279\n",
      "epoch : 70, t_cost : 0.004421, e_cost : 0.001591, elapsed time : 37.26sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.29205809283303097\n",
      "0.05612703470978886\n",
      "epoch : 71, t_cost : 0.002808, e_cost : 0.001276, elapsed time : 37.17sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.24991236120695248\n",
      "0.05920318909920752\n",
      "epoch : 72, t_cost : 0.002403, e_cost : 0.001346, elapsed time : 37.23sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.2646510510821827\n",
      "0.049636926618404686\n",
      "epoch : 73, t_cost : 0.002545, e_cost : 0.001128, elapsed time : 37.14sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.25124147813767195\n",
      "0.04928652287344448\n",
      "epoch : 74, t_cost : 0.002416, e_cost : 0.001120, elapsed time : 37.19sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.25200400716857985\n",
      "0.04951393834198825\n",
      "epoch : 75, t_cost : 0.002423, e_cost : 0.001125, elapsed time : 37.22sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.23083355405833572\n",
      "0.0489079509570729\n",
      "epoch : 76, t_cost : 0.002220, e_cost : 0.001112, elapsed time : 37.16sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.22730949253309518\n",
      "0.048492052766960114\n",
      "epoch : 77, t_cost : 0.002186, e_cost : 0.001102, elapsed time : 37.17sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.2234938339679502\n",
      "0.04922619977151044\n",
      "epoch : 78, t_cost : 0.002149, e_cost : 0.001119, elapsed time : 37.17sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.239013516693376\n",
      "0.05180848063901067\n",
      "epoch : 79, t_cost : 0.002298, e_cost : 0.001177, elapsed time : 37.13sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.18723683047574013\n",
      "0.04912099050125107\n",
      "epoch : 80, t_cost : 0.001800, e_cost : 0.001116, elapsed time : 37.19sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.17865265649743378\n",
      "0.052652067242888734\n",
      "epoch : 81, t_cost : 0.001718, e_cost : 0.001197, elapsed time : 37.15sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.18350029352586716\n",
      "0.05522498066420667\n",
      "epoch : 82, t_cost : 0.001764, e_cost : 0.001255, elapsed time : 37.12sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.17520320077892393\n",
      "0.05884537196834572\n",
      "epoch : 83, t_cost : 0.001685, e_cost : 0.001337, elapsed time : 37.17sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.18674771103542298\n",
      "0.06379547453252599\n",
      "epoch : 84, t_cost : 0.001796, e_cost : 0.001450, elapsed time : 37.14sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.19501330243656412\n",
      "0.06581732747144997\n",
      "epoch : 85, t_cost : 0.001875, e_cost : 0.001496, elapsed time : 37.08sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.20483122498262674\n",
      "0.07438898287364282\n",
      "epoch : 86, t_cost : 0.001970, e_cost : 0.001691, elapsed time : 37.15sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.19747767504304647\n",
      "0.07390170870348811\n",
      "epoch : 87, t_cost : 0.001899, e_cost : 0.001680, elapsed time : 37.23sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.2232172754011117\n",
      "0.07439192425226793\n",
      "epoch : 88, t_cost : 0.002146, e_cost : 0.001691, elapsed time : 37.13sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.19553921843180433\n",
      "0.07251170786912553\n",
      "epoch : 89, t_cost : 0.001880, e_cost : 0.001648, elapsed time : 37.18sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.23749865166610107\n",
      "0.07976335304556414\n",
      "epoch : 90, t_cost : 0.002284, e_cost : 0.001813, elapsed time : 37.20sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.1868779068463482\n",
      "0.0705550140410196\n",
      "epoch : 91, t_cost : 0.001797, e_cost : 0.001604, elapsed time : 37.23sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.20163819583831355\n",
      "0.07727174236788414\n",
      "epoch : 92, t_cost : 0.001939, e_cost : 0.001756, elapsed time : 37.19sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.252178889233619\n",
      "0.08063234126893803\n",
      "epoch : 93, t_cost : 0.002425, e_cost : 0.001833, elapsed time : 37.19sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.19939858029829338\n",
      "0.07536412015906535\n",
      "epoch : 94, t_cost : 0.001917, e_cost : 0.001713, elapsed time : 37.19sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.17819114704616368\n",
      "0.06980632463819347\n",
      "epoch : 95, t_cost : 0.001713, e_cost : 0.001587, elapsed time : 37.18sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.21381067793117836\n",
      "0.08399382067727856\n",
      "epoch : 96, t_cost : 0.002056, e_cost : 0.001909, elapsed time : 37.17sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.1922112131724134\n",
      "0.0775257030618377\n",
      "epoch : 97, t_cost : 0.001848, e_cost : 0.001762, elapsed time : 37.16sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.2059201183146797\n",
      "0.08026717568282038\n",
      "epoch : 98, t_cost : 0.001980, e_cost : 0.001824, elapsed time : 37.12sec\n",
      "(53690, 32, 1) (53690, 10, 32, 1) (53690, 10, 32, 1) (53690, 32, 1) (53690, 1)\n",
      "(23010, 32, 1) (23010, 10, 32, 1) (23010, 10, 32, 1) (23010, 32, 1) (23010, 1)\n",
      "0.1915146823739633\n",
      "0.07881246760371141\n",
      "epoch : 99, t_cost : 0.001841, e_cost : 0.001791, elapsed time : 37.16sec\n",
      "\n",
      "#Best result at epoch 77\n",
      "t_cost : 0.002186, e_cost : 0.001102\n",
      "[<matplotlib.lines.Line2D object at 0x7f93ec7e0650>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.002795698191852848"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxc1X338c9PM1pHlmRLsi2vsrEB2ywGhMMeErM/KSYNJCZpYlJSSgNN2qRpoWnShCd9NdAkJHlCaNkSNwtLCCQmIRC2UJZikAGDVyzvljdZtrVay4x+zx9zZY+kkTXYskcefd+vl16ee+6Zq3MZoa/OOffeY+6OiIhIoqx0N0BERIYehYOIiPShcBARkT4UDiIi0ofCQURE+ginuwGDoayszCsrK9PdDBGRY8qSJUt2uXt5sn0ZEQ6VlZVUV1enuxkiIscUM9vY3z4NK4mISB8KBxER6UPhICIifSgcRESkD4WDiIj0oXAQEZE+FA4iItLHsA6HNzbs5j+eXkWsS48tFxFJNKzD4e1Ne7nrhbW0dkTT3RQRkSFlWIdDJDd+g3hLeyzNLRERGVqGeTiEAGhRz0FEpIfhHQ453T0HhYOISKLhHQ4aVhIRSWqYh0MwrKSeg4hID8M8HIKeg+YcRER6GN7hkKNhJRGRZIZ3OGhYSUQkqWEdDgU5GlYSEUlmWIdDKMvIzw6p5yAi0suwDgeIT0q3dGjOQUQkkcIhVz0HEZHeUgoHM7vMzFabWY2Z3ZJkf66ZPRzsX2xmlUF5qZm9YGbNZvajhPojzOzthK9dZvb9YN91ZlaXsO9zg3OqyUVywgoHEZFewgNVMLMQcBdwMbAFeMPMFrn7ioRq1wN73H2amc0Hbgc+AbQBXwNOCr4AcPcmYHbC91gCPJZwvIfd/eZDPqv3Id5z0LCSiEiiVHoOc4Aad1/n7h3AQ8C8XnXmAQuD148Cc83M3L3F3V8mHhJJmdnxwGjgpffd+kEQn3NQz0FEJFEq4TAe2JywvSUoS1rH3aNAA1CaYhvmE+8pJK648zEze8fMHjWzicneZGY3mFm1mVXX1dWl+K36iuRqWElEpLehMCE9H3gwYfsJoNLdTwGe4UCPpAd3v8fdq9y9qry8/JC/eSRHw0oiIr2lEg61QOJf7xOCsqR1zCwMFAP1Ax3YzE4Fwu6+pLvM3evdvT3YvA84I4U2HjINK4mI9JVKOLwBTDezKWaWQ/wv/UW96iwCFgSvrwae7zVM1J9r6dlrwMwqEjavBFamcJxD1n21UmrNFREZHga8Wsndo2Z2M/A0EAIecPflZnYbUO3ui4D7gZ+ZWQ2wm3iAAGBmG4AiIMfMrgIuSbjS6ePAFb2+5RfM7EogGhzrusM4vwFFcsN0ObR1dpGfEzqS30pE5JgxYDgAuPuTwJO9yr6e8LoNuKaf91Ye5LhTk5TdCtyaSrsGQ2HCUqEKBxGRuKEwIZ1WBVoqVESkj2EfDloqVESkL4VDwrCSiIjEKRyCnkOzhpVERPZTOARzDq0aVhIR2U/hoKVCRUT6GPbhUJirpUJFRHob9uGgS1lFRPoa9uGQE84iJ5SlpUJFRBIM+3AAKNBSoSIiPSgciF+xpEtZRUQOUDgQv2JJl7KKiBygcEBrOoiI9KZwIH45q+YcREQOUDgABVoqVESkB4UD8WElTUiLiBygcCB+tVKr5hxERPZTOBBMSGtYSURkP4UDEMkJ0RHroiPale6miIgMCSmFg5ldZmarzazGzG5Jsj/XzB4O9i82s8qgvNTMXjCzZjP7Ua/3/Ck45tvB1+iDHetI6l7TQUNLIiJxA4aDmYWAu4DLgZnAtWY2s1e164E97j4NuBO4PShvA74G/EM/h/+Uu88OvnYOcKwj5sCTWTW0JCICqfUc5gA17r7O3TuAh4B5verMAxYGrx8F5pqZuXuLu79MPCRSlfRY7+P971uB1nQQEekhlXAYD2xO2N4SlCWt4+5RoAEoTeHYPwmGlL6WEAApHcvMbjCzajOrrqurS+Fb9U9LhYqI9JTOCelPufvJwPnB16ffz5vd/R53r3L3qvLy8sNqiJYKFRHpKZVwqAUmJmxPCMqS1jGzMFAM1B/soO5eG/zbBPyS+PDVIR3rcHUvFaqeg4hIXCrh8AYw3cymmFkOMB9Y1KvOImBB8Ppq4Hl39/4OaGZhMysLXmcDHwGWHcqxBkOhrlYSEekhPFAFd4+a2c3A00AIeMDdl5vZbUC1uy8C7gd+ZmY1wG7iAQKAmW0AioAcM7sKuATYCDwdBEMIeBa4N3hLv8c6UrRUqIhITwOGA4C7Pwk82avs6wmv24Br+nlvZT+HPaOf+v0e60gp3D8hrTkHERHQHdIA5GVnkWUaVhIR6aZwAMxMS4WKiCRQOAQKtFSoiMh+CodAJDdMs4aVREQAhcN+hblhWjWsJCICKBz201KhIiIHKBwChVoqVERkP4VDoEBLhYqI7KdwCERyw7oJTkQkoHAIRHJC6jmIiAQUDoFIbpjWjhhdXUf0GX8iIscEhUPgwFKh6j2IiCgcAgVa00FEZD+FQ2BccT4AW/fuS3NLRETST+EQqCyLALCuriXNLRERST+FQ2DCyHzCWcaGeoWDiIjCIZAdymLiqALW71I4iIgoHBJMKYuwfldrupshIpJ2CocElaURNuxqwV33OojI8JZSOJjZZWa22sxqzOyWJPtzzezhYP9iM6sMykvN7AUzazazHyXULzCz35vZKjNbbmbfTth3nZnVmdnbwdfnDv80UzOlrIB9nTF2NLYfrW8pIjIkDRgOZhYC7gIuB2YC15rZzF7Vrgf2uPs04E7g9qC8Dfga8A9JDv0ddz8ROA0418wuT9j3sLvPDr7ue19ndBimlBUCaN5BRIa9VHoOc4Aad1/n7h3AQ8C8XnXmAQuD148Cc83M3L3F3V8mHhL7uXuru78QvO4A3gQmHMZ5DIrKsgJA4SAikko4jAc2J2xvCcqS1nH3KNAAlKbSADMrAf4MeC6h+GNm9o6ZPWpmE/t53w1mVm1m1XV1dal8qwGNK84nJ5yly1lFZNhL64S0mYWBB4Efuvu6oPgJoNLdTwGe4UCPpAd3v8fdq9y9qry8fFDak5VlVJYW6EY4ERn2UgmHWiDxr/cJQVnSOsEv/GKgPoVj3wOscffvdxe4e727d88I3weckcJxBk1laUQ9BxEZ9lIJhzeA6WY2xcxygPnAol51FgELgtdXA8/7ANeDmtm3iIfI3/Uqr0jYvBJYmUIbB82U8gib6luJDfDo7obWTr71uxVsVJCISAYKD1TB3aNmdjPwNBACHnD35WZ2G1Dt7ouA+4GfmVkNsJt4gABgZhuAIiDHzK4CLgEaga8Cq4A3zQzgR8GVSV8wsyuBaHCs6wbpXFMypTRCR6yLrXv3MXFUQdI663e1cP1P32DdrhYqSvK5/rwpR7OJIiJH3IDhAODuTwJP9ir7esLrNuCaft5b2c9hrZ/6twK3ptKuI6H7AXzrd7UkDYf/XVvPjT9fQlbQ+hY94ltEMpDukO5lakI49La9oY0FD7xO+YhcfnvTeeSEs7Q4kIhkJIVDL+UjconkhJKGw1ub9tAR6+I715zKpNICCnPD6jmISEZSOPRiZlSWRZKGw8rtTWQZnDBmBACR3BAt7bGj3UQRkSNO4ZBEZVnyy1lXbWuksixCfk58SdFITljLiopIRlI4JDGlNMKWPfvoiHb1KF+1vYkZFUX7tzWsJCKZSuGQxJSyCLEuZ9PuA72H5vYom3a3MmPsiP1lEYWDiGQohUMSp0woBqB6w579Zau3NwFw4tgDPYdIbkjDSiKSkRQOSUwbXUj5iFxeXXvgCSArtzUCcGJFQs8hJ6wJaRHJSAqHJMyMc44r5dW19ftXhVu1vZEReWHGl+TvrxfJDes+BxHJSAqHfpxzXCm7mtup2dkMwKptTcwYW0TwqA/gwIS0lhUVkUyjcOjHOceVAfBKzS7cnVXbm3oMKUG859Dl0NbZlewQIiLHLIVDPyaOKmDCyHxeXVvPlj37aG6P9piMBijMjd/voElpEck0CoeDOPe4Ml5bV8/yrX0noyHecwA9fE9EMo/C4SDOmVZKY1uUX7+5BUt4bEa37nBQz0FEMo3C4SDOnhpfBvvZlTuYPKpgfxh0i+So5yAimUnhcBCji/KYNroQd/rMN0D8JjhAl7OKSMZROAzg3OPivYfe8w0Qv5QVoFk3wolIhlE4DOCcafFLWhMfuNete5ipVcNKIpJhUgoHM7vMzFabWY2Z3ZJkf66ZPRzsX2xmlUF5qZm9YGbNZvajXu85w8zeDd7zQwvuLjOzUWb2jJmtCf4defineegumjGGH8yfzdwTR/fZpwlpEclUA4aDmYWAu4DLgZnAtWY2s1e164E97j4NuBO4PShvA74G/EOSQ98N/BUwPfi6LCi/BXjO3acDzwXbaRPKMubNHk841Pc/VSRY10HPVxKRTJNKz2EOUOPu69y9A3gImNerzjxgYfD6UWCumZm7t7j7y8RDYj8zqwCK3P01jz974r+Bq5Ica2FC+ZATDmWRl611pEUk86QSDuOBzQnbW4KypHXcPQo0AKUDHHNLP8cc4+7bgtfbgTHJDmBmN5hZtZlV19XVpXAaR0ZhrlaDE5HMM6QnpINeRdKn2rn7Pe5e5e5V5eXlR7llBxTkaMEfEck8qYRDLTAxYXtCUJa0jpmFgWKgnv7VBsdJdswdwbBT9/DTzhTamDZaDU5EMlEq4fAGMN3MpphZDjAfWNSrziJgQfD6auB5P8hzrINho0YzOyu4SukzwG+THGtBQvmQVKjV4EQkA4UHquDuUTO7GXgaCAEPuPtyM7sNqHb3RcD9wM/MrAbYTTxAADCzDUARkGNmVwGXuPsK4PPAT4F84A/BF8C3gUfM7HpgI/DxwTjRIyWSG2Z3S0e6myEiMqgGDAcAd38SeLJX2dcTXrcB1/Tz3sp+yquBk5KU1wNzU2nXUBDJDbNpd2u6myEiMqiG9IT0saBQE9IikoEUDocpPiGtm+BEJLMoHA5TYW6Ilg6tIy0imUXhcJgiuWHcobVDvQcRyRwKh8NUoKVCRSQDKRwOU2Gw4I/udRCRTKJwOEzdS4VqWElEMonC4TAVak0HEclACofDFNGcg4hkIIXDYdJqcCKSiRQOh6lwf89Bcw4ikjkUDocpktu9VKh6DiKSORQOh6kgR8NKIpJ5FA6HKZRl5GeH1HMQkYyicBgEkdwwLR0KBxHJHAqHQVCYG9KEtIhkFIXDINA60iKSaRQOgyCSG9aEtIhkFIXDICjUnIOIZJiUwsHMLjOz1WZWY2a3JNmfa2YPB/sXm1llwr5bg/LVZnZpUHaCmb2d8NVoZn8X7PuGmdUm7LticE71yNFqcCKSacIDVTCzEHAXcDGwBXjDzBa5+4qEatcDe9x9mpnNB24HPmFmM4H5wCxgHPCsmR3v7quB2QnHrwUeTzjene7+ncM/vaMjkhPSsJKIZJRUeg5zgBp3X+fuHcBDwLxedeYBC4PXjwJzzcyC8ofcvd3d1wM1wfESzQXWuvvGQz2JdNOEtIhkmlTCYTywOWF7S1CWtI67R4EGoDTF984HHuxVdrOZvWNmD5jZyGSNMrMbzKzazKrr6upSOI0jJ5IbprUjRleX1pEWkcyQ1glpM8sBrgR+lVB8N3Ac8WGnbcB3k73X3e9x9yp3ryovLz/ibT2Y7tXgWjvj8w6bd7cm7Un8cvEmvv2HVexsajuq7RMReb9SCYdaYGLC9oSgLGkdMwsDxUB9Cu+9HHjT3Xd0F7j7DnePuXsXcC99h6GGnMQ1HZraOrniBy/xvWfe61Pvh8+t4T9fXMv5t7/ANxYtV0iIyJCVSji8AUw3synBX/rzgUW96iwCFgSvrwaed3cPyucHVzNNAaYDrye871p6DSmZWUXC5keBZameTLokrga3aOlWmtqjvLVpT4869c3tbG9s47pzKpk3exw/f20jX35kaTqaKyIyoAGvVnL3qJndDDwNhIAH3H25md0GVLv7IuB+4GdmVgPsJh4gBPUeAVYAUeAmd48BmFmE+BVQf93rW95hZrMBBzYk2T/kdK8j3dIe5cHXNwGwclsTsS4nlGX7twEunjmGc6eVYRjPr96ZngaLiAxgwHAAcPcngSd7lX094XUbcE0/7/034N+SlLcQn7TuXf7pVNo0lHQPKy1et5tltY2cOrGEpZv3sn5XM9NGjwBg5bZGAGZUFAEwriSfuqZ22qMxcsOh9DRcRKQfukN6EHQv+PPTVzeQl53FV6+YAcDyrY3766zY1sjYojxGRXIAGFeSB8D2Bs07iMjQo3AYBN09h9q9+7ji5ApOm1RCTjirZzhsbWTmuKL92+NL8gHYulfhICJDj8JhEHRPSANcO2cS2aEsThgzguVbGwBo64xRU9fMzIoD4TBufzjsO7qNFRFJgcJhEHT3HKaNLqRqcvyevVnjili+tRF3p2ZnM7Eu79FzGFscH1ZSOIjIUKRwGAQF2SFOGl/E5y88jvhTQ+LhsLe1k60NbazY2nMyGiAvO0RZYS5bGxQOIjL0pHS1khxcVpbxu789v0fZzHHFACyvbWDFtkYKckJMHlXQo864kjxqNecgIkOQeg5HyIyKEZjFr1hasa2RGRVFZAX3PHQbV5yvYSURGZIUDkdIQU6YqWURlm9tYOXWxh6T0d3GleSzbe8+4jeTi4gMHQqHI2jWuGJertlFU3u0x3xDt3ElebR0xGjcp8d9i8jQonA4gmaNK6Ktswugx5VK3brvdajV0JKIDDEKhyNoVjApnWVwwpgRffbrXgcRGaoUDkfQrKC3MLW8kPycvs9PqggeoaHLWUVkqFE4HEEjIzlMLYtw2sSSpPvLIrnkhLI0rCQiQ47uczjCHrrhrKS9BojfH1FRksc23esgIkOMwuEIG12Ud9D9utdBRIYiDSul2bgShYOIDD0KhzQbX5LH9sY2orH4Ja/t0ZjWeBCRtFM4pFlFST5dDjua2gH4x0ff4YP/8QLLahvS3DIRGc4UDmmWeK/DurpmFi3dSnu0ixt/voQ9LR1pbp2IDFcphYOZXWZmq82sxsxuSbI/18weDvYvNrPKhH23BuWrzezShPINZvaumb1tZtUJ5aPM7BkzWxP8O/LwTnFoG19yYF2H/3xxLTmhLO77TBU7G9v5wkNvEevSc5dE5OgbMBzMLATcBVwOzASuNbOZvapdD+xx92nAncDtwXtnAvOBWcBlwI+D43X7kLvPdveqhLJbgOfcfTrwXLCdsSqK4z2H6g17eOzNWuafOZGLZo7htnmzeGnNLr77x9VpbqGIDEep9BzmADXuvs7dO4CHgHm96swDFgavHwXmWnzVm3nAQ+7e7u7rgZrgeAeTeKyFwFUptPGYFckNU1KQzS9f3wTAX10wFYD5cyYx/8yJ3P3iWt7b0ZTOJorIMJRKOIwHNidsbwnKktZx9yjQAJQO8F4H/mhmS8zshoQ6Y9x9W/B6OzAmWaPM7AYzqzaz6rq6uhROY+gaV5xPrMu56rTxTBh5YEGgf7rsRAqyQ/zwuTVpbJ2IDEfpnJA+z91PJz5cdZOZXdC7gscXOkg66O7u97h7lbtXlZeXH+GmHlnjSvIwg7+58Lge5SMjOVx3biW/f3ebeg8iclSlEg61wMSE7QlBWdI6ZhYGioH6g73X3bv/3Qk8zoHhph1mVhEcqwLYmfrpHJuuO2cK37xyFseVF/bZ97nzpqr3ICJHXSrh8AYw3cymmFkO8QnmRb3qLAIWBK+vBp4P/upfBMwPrmaaAkwHXjeziJmNADCzCHAJsCzJsRYAvz20Uzt2nDe9jM+cXZl038hIDgvOifce1qj3ICJHyYDhEMwh3Aw8DawEHnH35WZ2m5ldGVS7Hyg1sxrgSwRXGLn7cuARYAXwFHCTu8eIzyO8bGZLgdeB37v7U8Gxvg1cbGZrgIuC7WHtc+cHvYfna9LdFBEZJiwT1i+uqqry6urqgSsew+54ahV3v7iW//yLM7h01th0N0dEMoCZLel1K8F+ukP6GPG3H57OqRNK+MKDb7Fk4+50N0dEMpzC4RiRnxPi/gVVVBTncf3CatbWNae7SSKSwRQOx5DSwlwW/uUcQmYseOB1lm7em+4miUiGUjgcYyaXRvjJZ8+kI9rFVT9+hW8sWk5TW2e6myUiGUbhcAw6ZUIJz375g3zmrMks/N8NXPS9F3l6+fZ0N0tEMojC4RhVlJfNN+edxOOfP5eRBTn89c+W8PlfLGFnkxYKEpHDp3A4xs2eWMITf3seX7n0BJ5duZOLvvsib23ak+5micgxTuGQAbJDWdz0oWk89cXzKcrP5uZfvsXeVi0UJCKHTuGQQaaWF3LXJ09nZ1MbX35kKV1aKEhEDpHCIcOcOrGEr14xg+dW7eTel9aluzkicoxSOGSgBedUcsXJY7nj6dU8v2pHupsjIscghUMGMjO+/bFTOHHsCD63sJoHXl5PJjxDS0SOHoVDhirKy+ZXN57NxTPHcNvvVvDPjy+jI9qV7maJyDFC4ZDBCnLC3P2pM7jpQ8fx4OubmHfXK3rkhoikROGQ4bKyjK9ceiL3fPoMdre089Efv8JtT6ygtSOa7qaJyBCmcBgmLpk1lme+9EE++YFJPPDKeq695zXdCyEi/VI4DCNFedl866qTuefTZ7ByWxPX3ruYXc3t6W6WiAxBCodh6JJZY7lvQRXrdzXzif/6X3Y06nlMItJTSuFgZpeZ2WozqzGzW5LszzWzh4P9i82sMmHfrUH5ajO7NCibaGYvmNkKM1tuZl9MqP8NM6s1s7eDrysO/zSltwuOL+enn53D9oY2Pnb3q6zf1ZLuJonIEDJgOJhZCLgLuByYCVxrZjN7Vbse2OPu04A7gduD984E5gOzgMuAHwfHiwJfdveZwFnATb2Oeae7zw6+njysM5R+nTW1lAdvOIvWjhhX3/0q72zRlUwiEpdKz2EOUOPu69y9A3gImNerzjxgYfD6UWCumVlQ/pC7t7v7eqAGmOPu29z9TQB3bwJWAuMP/3Tk/TplQgmP3ng2edkh5t/zGi++V5fuJonIEJBKOIwHNidsb6HvL/L9ddw9CjQApam8NxiCOg1YnFB8s5m9Y2YPmNnIZI0ysxvMrNrMquvq9AvtcEwtL+Sxz5/DpFEFfPYnr3PfS+t0R7XIMJfWCWkzKwR+DfyduzcGxXcDxwGzgW3Ad5O9193vcfcqd68qLy8/Ku3NZGOK8nj0b87h4plj+NbvV/LlR5bS1hlLd7NEJE1SCYdaYGLC9oSgLGkdMwsDxUD9wd5rZtnEg+EX7v5YdwV33+HuMXfvAu4lPqwlR0FhbvyO6i9dfDyPvVXLJ+99jYZ9Wp9aZDhKJRzeAKab2RQzyyE+wbyoV51FwILg9dXA8x4fl1gEzA+uZpoCTAdeD+Yj7gdWuvv3Eg9kZhUJmx8Flr3fk5JDl5VlfGHudO7+1Om8W9vAJ+99jd0tullOZLgZMByCOYSbgaeJTxw/4u7Lzew2M7syqHY/UGpmNcCXgFuC9y4HHgFWAE8BN7l7DDgX+DTw4SSXrN5hZu+a2TvAh4C/H6yTldRdfnIF936mipqdzVx7z2tDem3qJRt3s2Tj7nQ3QySjWCZMPFZVVXl1dXW6m5GRXq3Zxef+u5pQlnHRjDFcdtJYzp9eRkFO+Ki2w935nzW7aGrrpGryKMYW51Gzs4lv/2EVz67cSSjL+Pafn8w1VRMHPpiIAGBmS9y9Ktm+o/t/uBxzzplWxq9uPJufvrKBP67YweNvxaebivLCjC7KY2RBNqEsI5RllBXm8vkLp3HC2BGD2oadjW38y2+W8ccVBxYuGlecx46mdgqyQ3zl0hN4bV09X3n0HXa3dPDXHzzuoMdr64yxraGNKWWRQW2nyGBZvrWBHzy7hmuqJnLRjNHER+KPLvUcJGWdsS5eW1fP0s172dnUzs7Gdvbu66CrC2LuvLejiZb2KPPnTOJLFx9PWWFuSsdt64zxxobdTC0vZHxJ/v7ylvYoj79Vyx1PraI92sWXLzmeOVNKWbJxD29u2kNFUR5/c+FxlBbm0h6N8aVHlvL7d7Zx/vQywllGY1uUnFAWH5g6ivOmlTEiL5uH39jMr9/cQsO+Ts6bVsZXLj2BUyeWHLR9b2/ey6+qN3P1GRM4bVLSK6sBeHnNLiaMzKcyA0PnjqdW8cvXN3Fm5SjOOa6UC08YrXDtpbk9yn+9uJa87BA3fvA4QlkHfqF3dTnv1jbw0po6/ue9XTS2dXJN1USuqZpAUV52j+Ns3buPq+56hZ1N8eeenT6phM9fOI36lnbe3LiXFdsaKc7PZnxJPuNK8pk7YzQnjS8+pDYfrOegcJBBs6elgx88t4afv7aRLnciuWEKckIU52dzZuUoPnh8OWcdVwpA475OtjW0sejtrSxaunX/VVGzJ5Zw8cwxrN7exDMrdrCvM0bV5JHccfUpTC0vPOj3j3U5dzy1ij+u2EFhbpii/DAN+zpZvrWR7h/z7JBx6ayxnDh2BA+8soHdLR1cPHMMHzmlggumlzMykgNAQ2snb27aw70vrePVtfUA5ISy+NZHT+LjvYau2jpj3Pa7Ffxy8SZGj8jlNzedy7iEkDvWPbVsOzf+fAmnTyqhvqWDjfWthLKMf/2zmXz6rMlp+av2aHB3Xl1bT+O+TvJzQuRlh4h1Ofs6YuzrjDEqksPU8ghjRuTxxDtb+bffr9z/C/3sqaX84NrZlBfm8qfVdfz7H1by3o5mAE4aX0Q4K4u3N+8lkhPimqqJ/OW5U5hUWkBTWyfX/Of/smXPPh664SzerW3g+8++x47G+HFLCrI5aVwxze1Ravfuo66pnds/djKfOHPSIZ2jwkGOqrV1zfz2rVqa2qO0tsfY0dTG6+t309rR976J3HAWl84ay0dOqWDNzmb+sGwby2rjfxl95JQKPnraeM6YPPKwfgHtaengtXX17Gpu5/KTK/b3aJrbo9z30joWvrqBPa2dmMH00YXsau7Yf4XWmKJcPnfeVC4/eSy3/PpdXq7ZxXXnVPKpD0wiJ5xFU1uUf/r1Oyzf2sgnPzCJJ97eyviR+fzqxrMZ0esvwi1JsxAAAAqUSURBVGPRxvoWPvL/XmZqWYRHbjyb3HCIzbtb+eYTy3l25U4++YFJfPPKWWSHel7b0tXlrNnZzPFjCo/J8KhvbueWx97lmRUDr8GeE86iI9rFKROK+eaVs6jZ2czXfruMwtxspo2O8Nq63VSWFnDTh6bx4RNHUxr8/L2zZS8/fWUDT7yzlViXc/lJFezd18Fr63bzk+vO5ILj4/dvtXXGeKVmF5VlEaaWRXr892yPxnCHvOzQIZ2nwkHSriPatX84KDecRVFeNsUF2Zw1tZTi/J6/RHc2tVGSn0NO+Ojcoxnrct7ZspcX36tj6ea9jC3OY0pZhGmjCzl3Whm54fj/eNFYF//+h1Xc//L6Hu8vzs/mex8/lbkzxvDSmjo++5M3OHdaGfcvqCKc8EuzPRpjWW0jrR1RZo0rZlTQS0mnZbUN3PLYOxTnZ3P3X5zRY4ijrTPGx+5+lc27W/n9F85n4qiC/ftiXc53/riau/+0ljMmj+T686bwoRNGk5edxTMrdvDdP77H6h1NfHHudP7+4uPTcWqHpK0zxovv1fHVx5fRuK+Tr1x6AudNL2NfZ4x9HTHCWUZBTpi87CzqmtpZu6uFdXXNzKgo4urTJ5AVDCW9t6OJz//iTeqb2/ni3Ol88gOT+/153tHYxk9e2cAvFm+kqS3Kv//5yVw759B6Au+XwkFkEL25aQ9b9+6jI9pFNOacf3wZFcUHhpEeen0Ttzz2LpWlBVQU5zMyks2upg7e3rK3xzre44rzOG96Gf902Yn7/5o8WjqiXfzohRp+/EINJQU57G3t4MSKESz87BxKC3PZWN/Cv/xmGS+t2cW9n6ni4pljkh7nt2/X8n9/t4JdzR3kZ4cYPzKfmp3NTCmLMKUswvOrdnLHx07h42cOzavIOmNdPLtiB799eyurtjeyaXcrXQ4njh3BnZ+YzYyKosM6dqzLU/6rvrk9yrq6Zk6ZcPA5sMGkcBA5yn65eBN/Wr2TPa3xIarCvGzOnDySqsqRjMjLZvnWBt7Z0sDTy7dTnB9fhOmyk8Ye9JixLqe5LUpxQc+elruztaGNsUV5PSZB+/P6+t187TfLWL2jiT8/bTz/+mezeHPTHm78+RImjMznklljuf+l9WSHjFuvmMFfnDV5wHYtXl/Pk+9uY8XWRj5x5kQ+dvoEHPjLn77Bq2vreeC6M5lTOYolG/ewYlsDl82qYFJpwUGPe6S4Oyu2NfLku9t4pHoLdU3tjC3K4/TJJUwfPYITxo7gwyeOPuShmmOJwkFkiFq1vZEvP7KU5VsbOXdaKaNH5JEdMrLM6Iw5nbEumtujbKhvYfPuVjpjzpwpo/jUByYxd8YY/rh8Oz95ZQPv1jYwtTzCTRdO48rZ4/rMAbg72xvb+I+nV/PYm7WML8nnm1fO4qKEHsHidfVcv7Ca5vYo82aP45+vmMGYorzDOr+mtk4+8V+vUVPXjLvTGYv/vinKC/P9+bP58InJeySDqavL2VDfwtIte3l9/R5eWLWT7Y1tZBl86ITRfOqsSXzw+NEpBWumUTiIDGGdsS7u/tNanli6lY5YFx3R+HBEdiiLnHAW+dkhJo0qoLIsQm44i8ffqmXT7lbMwB2mlkeYd+p4nlq+nZXbGpkwMp8pZRG63InGnF3N7WxraKO1I0Z2yLjhgqnc/KHp5Of0/ct4bV0zzW3RAS/vfT92NLbxjUXLmVRawFlTS6kozuNLDy9lxbbGYDx+EjnBuToQizmdXV1kh7KI5IR6zNskcne27NnH0i17Wbp5L01tUU6ZUMLpk0soysvmpTV1vLCqjlfX7qKxLQpAJCfE+dPL+fCM0Vx4QjmjRxxe+B3rFA4iGaSry3ll7S7+tLqO86eXccH0crKyDHfnuZU7+e/XNtK4rzN+c6IZoyI5jCvJZ1xJHnNnjBkS9ye0dcb46uPL+PWbWwasmxvOoiAnRG44RF52FjF3GvdFaW6PEuuK//7KCersbe35oMiK4jwumF7O6ZNLOHViCdPKC/sNm+FI4SAiQ073I1G27GmlIxrvMZlBOCuLcMjoiHbR0h6jpSPKvo4Y7dEYbZ1dhLKMEXlhRuSFGVucz+wJJZwwdgTZIWNjfStvbtrD7pYOzptexgljRhyTl9IeLXp8hogMOWbGB48f3LVYKssiGXmHejqofyUiIn0oHEREpA+Fg4iI9KFwEBGRPhQOIiLSh8JBRET6UDiIiEgfCgcREekjI+6QNrM6YOMhvr0M2DWIzTlWDMfzHo7nDMPzvIfjOcP7P+/J7p70TsSMCIfDYWbV/d0+nsmG43kPx3OG4Xnew/GcYXDPW8NKIiLSh8JBRET6UDjAPeluQJoMx/MejucMw/O8h+M5wyCe97CfcxARkb7UcxARkT4UDiIi0sewDgczu8zMVptZjZndku72HAlmNtHMXjCzFWa23My+GJSPMrNnzGxN8O/IdLd1sJlZyMzeMrPfBdtTzGxx8Hk/bGY56W7jYDOzEjN71MxWmdlKMzt7mHzWfx/8fC8zswfNLC/TPm8ze8DMdprZsoSypJ+txf0wOPd3zOz09/v9hm04mFkIuAu4HJgJXGtmM9PbqiMiCnzZ3WcCZwE3Bed5C/Ccu08Hngu2M80XgZUJ27cDd7r7NGAPcH1aWnVk/QB4yt1PBE4lfv4Z/Vmb2XjgC0CVu58EhID5ZN7n/VPgsl5l/X22lwPTg68bgLvf7zcbtuEAzAFq3H2du3cADwHz0tymQefu29z9zeB1E/FfFuOJn+vCoNpC4Kr0tPDIMLMJwP8B7gu2Dfgw8GhQJRPPuRi4ALgfwN073H0vGf5ZB8JAvpmFgQJgGxn2ebv7/wC7exX399nOA/7b414DSsys4v18v+EcDuOBzQnbW4KyjGVmlcBpwGJgjLtvC3ZtB8akqVlHyveBfwS6gu1SYK+7R4PtTPy8pwB1wE+C4bT7zCxChn/W7l4LfAfYRDwUGoAlZP7nDf1/tof9+204h8OwYmaFwK+Bv3P3xsR9Hr+eOWOuaTazjwA73X1JuttylIWB04G73f00oIVeQ0iZ9lkDBOPs84iH4zggQt/hl4w32J/tcA6HWmBiwvaEoCzjmFk28WD4hbs/FhTv6O5mBv/uTFf7joBzgSvNbAPx4cIPEx+LLwmGHSAzP+8twBZ3XxxsP0o8LDL5swa4CFjv7nXu3gk8RvxnINM/b+j/sz3s32/DORzeAKYHVzTkEJ/AWpTmNg26YKz9fmClu38vYdciYEHwegHw26PdtiPF3W919wnuXkn8c33e3T8FvABcHVTLqHMGcPftwGYzOyEomgusIIM/68Am4CwzKwh+3rvPO6M/70B/n+0i4DPBVUtnAQ0Jw08pGdZ3SJvZFcTHpkPAA+7+b2lu0qAzs/OAl4B3OTD+/s/E5x0eASYRf9z5x92992TXMc/MLgT+wd0/YmZTifckRgFvAX/h7u3pbN9gM7PZxCfhc4B1wGeJ/xGY0Z+1mX0T+ATxq/PeAj5HfIw9Yz5vM3sQuJD4Y7l3AP8K/IYkn20Qkj8iPrzWCnzW3avf1/cbzuEgIiLJDedhJRER6YfCQURE+lA4iIhIHwoHERHpQ+EgIiJ9KBxERKQPhYOIiPTx/wGS07QVTcFrggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.keras.backend.clear_session()\n",
    "#tf.compat.v1.reset_default_graph()\n",
    "#parameter list\n",
    "'''\n",
    "sess=tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(allow_soft_placement=True))\n",
    "name='lstm'\n",
    "timesize=20\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "#\n",
    "'''\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "sess=tf.compat.v1.Session()\n",
    "name='lstm'\n",
    "timesize=32\n",
    "timesize_for_calc_correlation=50\n",
    "positive_correlation_stock_num=10\n",
    "negative_correlation_sotck_num=10\n",
    "train_test_rate=0.7\n",
    "batch_size=512\n",
    "\n",
    "\n",
    "kospi=StockData(\n",
    "    'StockChart/SAMPLE',\n",
    "    'StockChart/KOSPI.csv',\n",
    "    timesize,timesize_for_calc_correlation,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num,\n",
    "    train_test_rate,\n",
    "    batch_size)\n",
    "\n",
    "\n",
    "lstmModel=LSTM_Model(\n",
    "    sess,\n",
    "    name,\n",
    "    timesize,\n",
    "    positive_correlation_stock_num,\n",
    "    negative_correlation_sotck_num\n",
    "    )\n",
    "\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    \n",
    "result_dic={}\n",
    "evalution_costplt2=[]    \n",
    "for i in range(100):\n",
    "    #epoch start\n",
    "    start_time = time.time()\n",
    "    training_cost=0\n",
    "    evalution_cost=0\n",
    "    \n",
    "    #training batch\n",
    "    \n",
    "    for batch in kospi.getBatch('training'):        \n",
    "        c,_=lstmModel.training(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        training_cost+=c\n",
    "       \n",
    "    #evaluation batch\n",
    "    \n",
    "    for batch in kospi.getBatch('evaluation'):\n",
    "        c=lstmModel.returnCost(batch['y'],batch['xp'],batch['xn'],batch['xi'],batch['target'])\n",
    "        evalution_cost+=c\n",
    "\n",
    "    print(training_cost)\n",
    "    print(evalution_cost)\n",
    "    \n",
    "    #epoch end\n",
    "    elapsed_time = time.time()-start_time\n",
    "    training_cost=training_cost/kospi.batchNum['training']\n",
    "    evalution_cost=evalution_cost/kospi.batchNum['evaluation']\n",
    "    result_dic[i]=[training_cost,evalution_cost]\n",
    "    evalution_costplt2.append(evalution_cost)\n",
    "\n",
    "    print('epoch : {}, t_cost : {:0.6f}, e_cost : {:0.6f}, elapsed time : {:0.2f}sec'.format(\n",
    "    i,training_cost,evalution_cost,elapsed_time))\n",
    "#\n",
    "\n",
    "sorted_result=sorted(result_dic,key=lambda k:result_dic[k][1])\n",
    "bestEpoch=sorted_result[0]\n",
    "print('\\n#Best result at epoch {}'.format(bestEpoch))\n",
    "print('t_cost : {:0.6f}, e_cost : {:0.6f}'.format(result_dic[bestEpoch][0],result_dic[bestEpoch][1]))\n",
    "print(plt.plot(evalution_costplt2))\n",
    "np.mean(evalution_costplt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eopch : 100 , batchsize : 256 , timesize : 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
